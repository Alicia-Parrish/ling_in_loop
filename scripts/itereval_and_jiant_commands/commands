# ================= individual sequence =================  #
sh create-task-configs.sh <test> true
sh tokenization-and-cache.sh <test> roberta-large true
sh train-models.sh <test> roberta-large <3000> true
sh get-best.sh <test>
sh tokenization-and-cache.sh eval_<test> roberta-large
sh eval-models.sh <run_name> <lr> <bs> <model>
sh cross-eval-models.sh <train_name> <val_name> <lr> <bs> <model>

# ================= all sequence =================  #

sh create-task-configs-all.sh <round>
sh tokenization-and-cache-all.sh <round> <model>
sh train-models-all.sh <round> <model> <iteration size>
sh get-best-all.sh <round> <model>
sh get_best_runscripts.sh <model>
sh <model>_run.sh
sh summarize-cross-evals.sh <model>
sh summarize-evals-all.sh <round> <model> <move bool> <corpus stats bool> <tables bool>

# ================= mnli sequence =================  #
sh get_mnli_runscripts.sh <model>
sh <model>_mnli_run.sh
sh summarize-mnli-evals.sh <model>

# ================= sampled cross_eval sequence =================  #
sh get-sampled-configs-all.sh <round> <sample>
sh tokenization-and-cache-all-cross_eval.sh <round> <model>

# ================= individual python commands =================  #

python corpus_stats.py --verbose --pushstats --round 2 --fname C:\Users\Willi\Documents\NYU\2020_Fall\semantics_seminar\lip\ling_in_loop\NLI_data\1_Baseline_protocol\train_round2_baseline.jsonl

python summarize_evals.py C:\Users\Willi\Documents\NYU\2020_Fall\semantics_seminar\lip\ling_in_loop\tasks\data\iterative_eval\val_itercombined.jsonl C:\Users\Willi\Documents\NYU\2020_Fall\semantics_seminar\lip\ling_in_loop\predictions\4_iterevals\1_Baseline_protocol\r1\combined\val_preds.p

python get_plots_tables.py
python get_plots_tables.py --combined