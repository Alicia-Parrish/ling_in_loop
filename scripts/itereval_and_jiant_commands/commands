sh create-task-configs.sh <test> true
sh tokenization-and-cache.sh <test> roberta-large true
sh train-models.sh <test> roberta-large <3000> true
sh get-best.sh <test>
sh tokenization-and-cache.sh eval_<test> roberta-large
sh eval-models.sh <test> <lr> <bs> roberta-large

python corpus_stats.py --verbose --pushstats --round 2 --fname C:\Users\Willi\Documents\NYU\2020_Fall\semantics_seminar\lip\ling_in_loop\NLI_data\1_Baseline_protocol\train_round2_baseline.jsonl

python summarize_evals.py C:\Users\Willi\Documents\NYU\2020_Fall\semantics_seminar\lip\ling_in_loop\tasks\data\iterative_eval\val_itercombined.jsonl C:\Users\Willi\Documents\NYU\2020_Fall\semantics_seminar\lip\ling_in_loop\predictions\4_iterevals\1_Baseline_protocol\r1\combined\val_preds.p

python get_plots_tables.py --combined