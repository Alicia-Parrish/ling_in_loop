{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.set_theme(style='whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_round_box(\n",
    "    plot_arrays, \n",
    "    plot_alltraining,\n",
    "    ylim=[0,1],\n",
    "    title=None,\n",
    "    xlabel=None,\n",
    "    ylabel=None,\n",
    "    tabletitle=None,\n",
    "    tableon=True,\n",
    "):\n",
    "    if tableon:\n",
    "        fig, ax = plt.subplots(2, 1)\n",
    "        sns.boxplot(x='treat', y='acc', data=plot_arrays, ax=ax[0])\n",
    "        ax[0].scatter(x=plot_alltraining['treat'], y=plot_alltraining['acc'], c='r', s=75)\n",
    "\n",
    "        ax[0].set_title(title)\n",
    "        ax[0].set_xlabel(xlabel)\n",
    "        ax[0].set_ylabel(ylabel)\n",
    "        ax[0].set_ylim(*ylim)\n",
    "\n",
    "        cell_text = []\n",
    "        order = ['baseline', 'LotS', 'LitL']\n",
    "        for treat in order:\n",
    "            display_text = f'{plot_alltraining.loc[plot_alltraining[\"treat\"] == treat,\"acc\"].values[0]*100:.2f}%'\n",
    "            cell_text.append(display_text)\n",
    "\n",
    "        table = ax[1].table(cellText=[cell_text], colLabels=plot_alltraining['treat'].values, loc='upper center')\n",
    "        table.scale(1, 2)\n",
    "        ax[1].axis('off')\n",
    "\n",
    "        ax[1].set_title(tabletitle)\n",
    "    else:\n",
    "        fig, ax = plt.subplots()\n",
    "        sns.boxplot(x='treat', y='acc', data=plot_arrays, ax=ax)\n",
    "        ax.scatter(x=plot_alltraining['treat'], y=plot_alltraining['acc'], c='r', s=75)\n",
    "\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel(xlabel)\n",
    "        ax.set_ylabel(ylabel)\n",
    "        ax.set_ylim(*ylim)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val_summary(modifier, iteration, eval_dir, ):\n",
    "    fname = os.path.join(eval_dir, f'r{iteration}', 'tables', f'configs.{modifier}.csv')\n",
    "    summary_table = pd.read_csv(fname, index_col = 0)\n",
    "    summary_table = summary_table[[str(n) for n in range(1, iteration+1)]]\n",
    "    \n",
    "    return summary_table\n",
    "\n",
    "\n",
    "def get_itereval_summary(sub_keys, iteration, eval_dir, combined, ):\n",
    "    rep = {\n",
    "        '/': '-',\n",
    "        ';': '--',\n",
    "    }\n",
    "    \n",
    "    fname_key = '.'.join(sub_keys.values())\n",
    "    for old_char, new_char in rep.items():\n",
    "        fname_key = fname_key.replace(old_char, new_char)\n",
    "    fname = os.path.join(eval_dir, f'r{iteration}', 'tables', combined, f'iterevals.{fname_key}.csv')\n",
    "    summary_table = pd.read_csv(fname, index_col = 0)\n",
    "    summary_table = summary_table[[str(n) for n in range(1, iteration+1)]]\n",
    "    \n",
    "    return summary_table\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnli_tables(mnli_summary, subsetting='genre'):\n",
    "    with open(mnli_summary, 'r') as f:\n",
    "        summary = pd.DataFrame([json.loads(line) for line in f])\n",
    "    \n",
    "    mnli_tables = {}\n",
    "    for comb in summary['comb'].unique():\n",
    "        comb_sum = summary.loc[summary['comb'] == comb, :]\n",
    "\n",
    "        for subset in summary[subsetting].unique():\n",
    "            subset_sum = comb_sum.loc[comb_sum[subsetting] == subset, :]\n",
    "\n",
    "            plot_tab = []\n",
    "            for treat in subset_sum['treat'].unique():\n",
    "                treat_sum = subset_sum.loc[subset_sum['treat'] == treat, :]\n",
    "                s = treat_sum[['iter','acc']].set_index('iter').rename({'acc': treat}, axis=1).transpose()            \n",
    "                plot_tab.append(s)\n",
    "            \n",
    "            mnli_tables[(model, comb, subset)] = pd.concat(plot_tab)\n",
    "    \n",
    "    return summary, mnli_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_run_name(run_name, split_by='_'):\n",
    "    name_list = run_name.split(split_by)\n",
    "    if len(name_list) == 2:\n",
    "        input_type = 'full'\n",
    "        comb = 'combined'\n",
    "    elif len(name_list) == 3:\n",
    "        if name_list[-1] == 'hyp':\n",
    "            input_type = name_list[-1]\n",
    "            comb = 'combined'\n",
    "        else:\n",
    "            input_type = 'full'\n",
    "            comb = name_list[-1]\n",
    "    else:\n",
    "        input_type = name_list[-1]\n",
    "        comb = name_list[-2]\n",
    "\n",
    "    return (name_list[0], name_list[1], input_type, comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sampled_results(sampled_base):\n",
    "    collected = pd.read_csv(os.path.join(sampled_base, 'collected.csv'))\n",
    "    itereval = pd.read_csv(os.path.join(sampled_base, 'itereval.csv'))\n",
    "    mnli = pd.read_csv(os.path.join(sampled_base, 'mnli.csv'))\n",
    "    \n",
    "    \n",
    "    # fill in keys\n",
    "    collected['treat'] = collected['run'].apply(lambda x: split_run_name(x)[0])\n",
    "    collected['iter'] = collected['run'].apply(lambda x: int(split_run_name(x)[1]))\n",
    "    collected['mod'] = collected['run'].apply(lambda x: split_run_name(x)[2])\n",
    "    collected['combined'] = collected['run'].apply(lambda x: split_run_name(x)[3])\n",
    "    \n",
    "    mnli['genre'] = mnli['genre'].fillna('combined')\n",
    "    \n",
    "    return collected, itereval, mnli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_sampled(sampled_base, upto=5):\n",
    "    loaded_keys = {'collected': 0, 'itereval':1 ,'mnli': 2}\n",
    "    results = {key: [] for key in loaded_keys.keys()}\n",
    "    \n",
    "    for r in range(1, upto + 1):\n",
    "        loaded = load_sampled_results(os.path.join(sampled_base, f'r{r}'))\n",
    "        for result_key, loaded_key in loaded_keys.items():\n",
    "            results[result_key].append(loaded[loaded_key])\n",
    "    \n",
    "    return {\n",
    "        key: pd.concat(result_list, ignore_index=True)\n",
    "        for key, result_list in results.items()\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ttest_pvals(dist_df, verbose=True):\n",
    "    pairs = [\n",
    "        ('baseline', 'LotS'),\n",
    "        ('baseline', 'LitL'),\n",
    "        ('LotS', 'LitL'),\n",
    "    ]\n",
    "    \n",
    "    ttest_dict = {}\n",
    "    for pair in pairs:\n",
    "        a = dist_df.loc[dist_df['treat'] == pair[0], 'acc']\n",
    "        b = dist_df.loc[dist_df['treat'] == pair[1], 'acc']\n",
    "        ttest_dict[pair] = ttest_ind(a, b)\n",
    "    \n",
    "    if verbose:\n",
    "        for pair, ttest_results in ttest_dict.items():\n",
    "            print('='*45)\n",
    "            print(f\"{pair}\\nt: {ttest_results[0]:.5f} | p: {ttest_results[1]/2:.5f}\")\n",
    "    \n",
    "    return ttest_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def err_line_plots(\n",
    "    plot_df,\n",
    "    ylim=[0,1],\n",
    "    title=None,\n",
    "    xlabel=None,\n",
    "    ylabel=None,\n",
    "    tabletitle=None,\n",
    "    tableon=True,\n",
    "    x='iter',\n",
    "    y='acc',\n",
    "    hue='treat',\n",
    "    err_style='bars',\n",
    "    ci=95,\n",
    "    estimator=lambda x: np.median(x),\n",
    "    markers=True,\n",
    "    hue_order=['baseline', 'LotS', 'LitL'],\n",
    "    iteration=5,\n",
    "#     bbox_to_anchor=(1.01, 1),\n",
    "    palette=None,    \n",
    "):\n",
    "    if tableon:\n",
    "        fig, ax = plt.subplots(2, 1)\n",
    "                \n",
    "        sns.lineplot(\n",
    "            data=plot_df, x=x, y=y, ax=ax[0],\n",
    "            hue=hue, err_style=err_style, ci=ci, markers=markers,\n",
    "            estimator=estimator, palette=palette\n",
    "        )\n",
    "        ax[0].set_xticks(np.arange(1,iteration + 1))\n",
    "        \n",
    "        ax[0].set_title(title)\n",
    "        ax[0].set_xlabel(xlabel)\n",
    "        ax[0].set_ylabel(ylabel)\n",
    "        ax[0].set_ylim(*ylim)\n",
    "#         ax[0].legend(bbox_to_anchor=bbox_to_anchor)\n",
    "\n",
    "        cell_text = []\n",
    "        for treat in hue_order:\n",
    "            treat_df = plot_df.loc[plot_df['treat'] == treat, :]\n",
    "            display_text = [\n",
    "                f'{treat_df.loc[treat_df[\"iter\"] == i, \"acc\"].median()*100:.2f}%'\n",
    "                for i in range(1, iteration + 1)\n",
    "            ]\n",
    "            cell_text.append(display_text)\n",
    "        \n",
    "        table = ax[1].table(cellText=cell_text, colLabels=list(range(1, iteration + 1)), rowLabels=hue_order, loc='upper center')\n",
    "        table.scale(1, 2)\n",
    "        ax[1].axis('off')\n",
    "\n",
    "        ax[1].set_title(tabletitle)\n",
    "    else:\n",
    "        fig, ax = plt.subplots()\n",
    "                \n",
    "        sns.lineplot(\n",
    "            data=plot_df, x=x, y=y,\n",
    "            hue=hue, err_style=err_style, ci=ci, markers=markers,\n",
    "        )\n",
    "\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel(xlabel)\n",
    "        ax.set_ylabel(ylabel)\n",
    "        ax.set_ylim(*ylim)\n",
    "        ax.legend(bbox_to_anchor=bbox_to_anchor)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model='roberta-large'\n",
    "repo = os.path.dirname(os.path.dirname(os.path.abspath('__file__')))\n",
    "eval_dir = os.path.join(repo, 'eval_summary', model)\n",
    "sample_type = 'cross_eval'\n",
    "iteration = 5\n",
    "\n",
    "mnli_summary = os.path.join(eval_dir, 'mnli_evals', 'eval_summaries.jsonl')\n",
    "\n",
    "plots_dir = os.path.join(eval_dir, 'sample', sample_type, f'final', 'plots')\n",
    "os.makedirs(plots_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_name = 'Performance'\n",
    "diff_name = 'Over Baseline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "distributions = load_all_sampled(\n",
    "    os.path.join(eval_dir, 'sample', sample_type), upto=iteration\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "select2mod = {\n",
    "    ('combined', 'full'): 'combined',\n",
    "    ('combined', 'hyp'): 'hyp',\n",
    "    ('separate', 'full'): 'separate',\n",
    "    ('separate', 'hyp'): 'separate_hyp',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = 'combined'\n",
    "input_type = 'hyp'\n",
    "\n",
    "mod = select2mod[(combined, input_type)]\n",
    "\n",
    "collected = get_val_summary(mod, iteration, eval_dir, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp = []\n",
    "for idx, row in collected.iterrows():\n",
    "    df = pd.DataFrame({\n",
    "        'acc': row,\n",
    "        'iter': [int(x) for x in row.index.values],\n",
    "        'treat':row.name,\n",
    "        'mod':input_type,\n",
    "        'combined':combined,\n",
    "    })\n",
    "    temp.append(df)\n",
    "collected_t = pd.concat(temp, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.concat([distributions['collected'], collected_t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_type_df = all_df.loc[all_df['mod'] == input_type, :]\n",
    "plot_df = input_type_df.loc[input_type_df['combined'] == combined, :]\n",
    "plot_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "keeps = ['acc', 'treat', 'iter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02bc81be3ca5403991a5ea515ce29820",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ylim=[0.3,0.7]\n",
    "title=f'{acc_name}\\ncollected | {combined} | {input_type} input'\n",
    "xlabel='Iteration'\n",
    "ylabel='Accuracy'\n",
    "tabletitle='Median'\n",
    "\n",
    "figtype='jpg'\n",
    "\n",
    "fig = err_line_plots(\n",
    "    plot_df[keeps],\n",
    "    ylim=ylim,\n",
    "    title=title,\n",
    "    xlabel=xlabel,\n",
    "    ylabel=ylabel,\n",
    "    tabletitle=tabletitle,\n",
    "    palette={\n",
    "        'baseline':'tab:blue',\n",
    "        'LotS':'tab:orange',\n",
    "        'LitL':'tab:green',\n",
    "    }\n",
    ")\n",
    "fig.savefig(os.path.join(plots_dir, f'acc-collected-{combined}-{input_type}.{figtype}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = []\n",
    "base_df = plot_df.loc[plot_df['treat'] == 'baseline', :]\n",
    "for treat in ['LotS', 'LitL']:\n",
    "    treat_df = plot_df.loc[plot_df['treat'] == treat, :]\n",
    "    \n",
    "    for iteration in plot_df['iter'].unique():\n",
    "        base_iter_df = base_df.loc[base_df['iter'] == iteration]\n",
    "        treat_iter_df = treat_df.loc[treat_df['iter'] == iteration]\n",
    "        \n",
    "        accs = []\n",
    "        for _, treat_row in treat_iter_df.iterrows():\n",
    "            for _, base_row in base_iter_df.iterrows():\n",
    "                accs.append(treat_row['acc'] - base_row['acc'])\n",
    "        \n",
    "        diff.append(pd.DataFrame({\n",
    "            'acc': accs,\n",
    "            'iter': int(iteration),\n",
    "            'treat': treat,\n",
    "        }))\n",
    "\n",
    "diff_df = pd.concat(diff, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "075f558f28214a5ab314a7fb18bfd099",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ylim=[-0.3, 0.05]\n",
    "title=f'{diff_name}\\ncollected | {combined} | {input_type} input'\n",
    "xlabel='Iteration'\n",
    "ylabel='Difference'\n",
    "tabletitle='Median'\n",
    "\n",
    "figtype='jpg'\n",
    "\n",
    "fig = err_line_plots(\n",
    "    diff_df,\n",
    "    ylim=ylim,\n",
    "    title=title,\n",
    "    xlabel=xlabel,\n",
    "    ylabel=ylabel,\n",
    "    tabletitle=tabletitle,\n",
    "    palette={\n",
    "        'LotS':'tab:orange',\n",
    "        'LitL':'tab:green',\n",
    "    },\n",
    "    hue_order=['LotS', 'LitL'],\n",
    ")\n",
    "fig.savefig(os.path.join(plots_dir, f'difference-collected-{combined}-{input_type}.{figtype}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = 'separate'\n",
    "input_type = 'hyp'\n",
    "\n",
    "mod = select2mod[(combined, input_type)]\n",
    "\n",
    "collected = get_val_summary(mod, iteration, eval_dir, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp = []\n",
    "for idx, row in collected.iterrows():\n",
    "    df = pd.DataFrame({\n",
    "        'acc': row,\n",
    "        'iter': [int(x) for x in row.index.values],\n",
    "        'treat':row.name,\n",
    "        'mod':input_type,\n",
    "        'combined':combined,\n",
    "    })\n",
    "    temp.append(df)\n",
    "collected_t = pd.concat(temp, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.concat([distributions['collected'], collected_t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_type_df = all_df.loc[all_df['mod'] == input_type, :]\n",
    "plot_df = input_type_df.loc[input_type_df['combined'] == combined, :]\n",
    "plot_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "keeps = ['acc', 'treat', 'iter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "add0b1599c5b4412a0308042cdaea909",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ylim=[0.3,0.7]\n",
    "title=f'{acc_name}\\ncollected | {combined} | {input_type} input'\n",
    "xlabel='Iteration'\n",
    "ylabel='Accuracy'\n",
    "tabletitle='Median'\n",
    "\n",
    "figtype='jpg'\n",
    "\n",
    "fig = err_line_plots(\n",
    "    plot_df[keeps],\n",
    "    ylim=ylim,\n",
    "    title=title,\n",
    "    xlabel=xlabel,\n",
    "    ylabel=ylabel,\n",
    "    tabletitle=tabletitle,\n",
    "    palette={\n",
    "        'baseline':'tab:blue',\n",
    "        'LotS':'tab:orange',\n",
    "        'LitL':'tab:green',\n",
    "    }\n",
    ")\n",
    "fig.savefig(os.path.join(plots_dir, f'acc-collected-{combined}-{input_type}.{figtype}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = []\n",
    "base_df = plot_df.loc[plot_df['treat'] == 'baseline', :]\n",
    "for treat in ['LotS', 'LitL']:\n",
    "    treat_df = plot_df.loc[plot_df['treat'] == treat, :]\n",
    "    \n",
    "    for iteration in plot_df['iter'].unique():\n",
    "        base_iter_df = base_df.loc[base_df['iter'] == iteration]\n",
    "        treat_iter_df = treat_df.loc[treat_df['iter'] == iteration]\n",
    "        \n",
    "        accs = []\n",
    "        for _, treat_row in treat_iter_df.iterrows():\n",
    "            for _, base_row in base_iter_df.iterrows():\n",
    "                accs.append(treat_row['acc'] - base_row['acc'])\n",
    "        \n",
    "        diff.append(pd.DataFrame({\n",
    "            'acc': accs,\n",
    "            'iter': int(iteration),\n",
    "            'treat': treat,\n",
    "        }))\n",
    "\n",
    "diff_df = pd.concat(diff, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "701bfbed2ad34eb08b06cea87b087021",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ylim=[-0.3, 0.05]\n",
    "title=f'{diff_name}\\ncollected | {combined} | {input_type} input'\n",
    "xlabel='Iteration'\n",
    "ylabel='Difference'\n",
    "tabletitle='Median'\n",
    "\n",
    "figtype='jpg'\n",
    "\n",
    "fig = err_line_plots(\n",
    "    diff_df,\n",
    "    ylim=ylim,\n",
    "    title=title,\n",
    "    xlabel=xlabel,\n",
    "    ylabel=ylabel,\n",
    "    tabletitle=tabletitle,\n",
    "    palette={\n",
    "        'LotS':'tab:orange',\n",
    "        'LitL':'tab:green',\n",
    "    },\n",
    "    hue_order=['LotS', 'LitL'],\n",
    ")\n",
    "fig.savefig(os.path.join(plots_dir, f'difference-collected-{combined}-{input_type}.{figtype}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HANS - combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_iterations = 'combined'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lexical_overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### non-entailment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_keys = {\n",
    "    'dataset': 'hans',     # either hans or glue\n",
    "    'case': 'lexical_overlap',    # combined or specific to respective itereval set\n",
    "    'subcase': 'combined', # combined or specific to respective itereval set\n",
    "    'label': 'non-entailment',   # combined or [entailment, neutral, contradiction] for glue, [entailment, non-entailment] for hans\n",
    "}\n",
    "\n",
    "\n",
    "hans = get_itereval_summary(sub_keys, iteration, eval_dir, combined_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp = []\n",
    "for idx, row in hans.iterrows():\n",
    "    df = pd.DataFrame({\n",
    "        'acc': row,\n",
    "        'iter': [int(x) for x in row.index.values],\n",
    "        'treat':row.name,\n",
    "        'case':sub_keys['case'],\n",
    "        'subcase':sub_keys['subcase'],\n",
    "        'label':sub_keys['label'],\n",
    "        'comb':combined_iterations\n",
    "    })\n",
    "    temp.append(df)\n",
    "hans_t = pd.concat(temp, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.concat([distributions['itereval'], hans_t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_errs = all_df.loc[all_df['dataset'] == sub_keys['dataset'], :]\n",
    "combo_errs = dataset_errs.loc[dataset_errs['comb'] == combined_iterations, :]\n",
    "case_errs = combo_errs.loc[combo_errs['case'] == sub_keys['case'], :]\n",
    "subcase_errs = case_errs.loc[case_errs['subcase'] == sub_keys['subcase'], :]\n",
    "plot_df = subcase_errs.loc[subcase_errs['label'] == sub_keys['label'], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "keeps = ['acc', 'treat', 'iter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6ab0843fdcb416789866125a03f265b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ylim=[0,1]\n",
    "title=f\"{acc_name}\\n{combined_iterations} | {sub_keys['dataset']} | {sub_keys['case']} | {sub_keys['label']}\"\n",
    "xlabel='Iteration'\n",
    "ylabel='Accuracy'\n",
    "tabletitle='median'\n",
    "\n",
    "figtype='jpg'\n",
    "\n",
    "fig = err_line_plots(\n",
    "    plot_df[keeps],\n",
    "    ylim=ylim,\n",
    "    title=title,\n",
    "    xlabel=xlabel,\n",
    "    ylabel=ylabel,\n",
    "    tabletitle=tabletitle,\n",
    "    palette={\n",
    "        'baseline':'tab:blue',\n",
    "        'LotS':'tab:orange',\n",
    "        'LitL':'tab:green',\n",
    "    }\n",
    ")\n",
    "fig.savefig(os.path.join(plots_dir, f\"acc-{sub_keys['dataset']}-{combined_iterations}-{sub_keys['case']}-{sub_keys['label']}.{figtype}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = []\n",
    "base_df = plot_df.loc[plot_df['treat'] == 'baseline', :]\n",
    "for treat in ['LotS', 'LitL']:\n",
    "    treat_df = plot_df.loc[plot_df['treat'] == treat, :]\n",
    "    \n",
    "    for iteration in plot_df['iter'].unique():\n",
    "        base_iter_df = base_df.loc[base_df['iter'] == iteration]\n",
    "        treat_iter_df = treat_df.loc[treat_df['iter'] == iteration]\n",
    "        \n",
    "        accs = []\n",
    "        for _, treat_row in treat_iter_df.iterrows():\n",
    "            for _, base_row in base_iter_df.iterrows():\n",
    "                accs.append(treat_row['acc'] - base_row['acc'])\n",
    "        \n",
    "        diff.append(pd.DataFrame({\n",
    "            'acc': accs,\n",
    "            'iter': int(iteration),\n",
    "            'treat': treat,\n",
    "        }))\n",
    "\n",
    "diff_df = pd.concat(diff, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc96a3aaed154f648bc1705a2c086210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ylim=[-0.15, 0.5]\n",
    "title=f\"{diff_name}\\n{combined_iterations} | {sub_keys['dataset']} | {sub_keys['case']} | {sub_keys['label']}\"\n",
    "xlabel='Iteration'\n",
    "ylabel='Difference'\n",
    "tabletitle='Median'\n",
    "\n",
    "figtype='jpg'\n",
    "\n",
    "fig = err_line_plots(\n",
    "    diff_df,\n",
    "    ylim=ylim,\n",
    "    title=title,\n",
    "    xlabel=xlabel,\n",
    "    ylabel=ylabel,\n",
    "    tabletitle=tabletitle,\n",
    "    palette={\n",
    "        'LotS':'tab:orange',\n",
    "        'LitL':'tab:green',\n",
    "    },\n",
    "    hue_order=['LotS', 'LitL'],\n",
    ")\n",
    "fig.savefig(os.path.join(plots_dir, f\"difference-{sub_keys['dataset']}-{combined_iterations}-{sub_keys['case']}-{sub_keys['label']}.{figtype}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### subsequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### non-entailment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_keys = {\n",
    "    'dataset': 'hans',     # either hans or glue\n",
    "    'case': 'subsequence',    # combined or specific to respective itereval set\n",
    "    'subcase': 'combined', # combined or specific to respective itereval set\n",
    "    'label': 'non-entailment',   # combined or [entailment, neutral, contradiction] for glue, [entailment, non-entailment] for hans\n",
    "}\n",
    "\n",
    "\n",
    "hans = get_itereval_summary(sub_keys, iteration, eval_dir, combined_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp = []\n",
    "for idx, row in hans.iterrows():\n",
    "    df = pd.DataFrame({\n",
    "        'acc': row,\n",
    "        'iter': [int(x) for x in row.index.values],\n",
    "        'treat':row.name,\n",
    "        'case':sub_keys['case'],\n",
    "        'subcase':sub_keys['subcase'],\n",
    "        'label':sub_keys['label'],\n",
    "        'comb':combined_iterations\n",
    "    })\n",
    "    temp.append(df)\n",
    "hans_t = pd.concat(temp, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.concat([distributions['itereval'], hans_t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_errs = all_df.loc[all_df['dataset'] == sub_keys['dataset'], :]\n",
    "combo_errs = dataset_errs.loc[dataset_errs['comb'] == combined_iterations, :]\n",
    "case_errs = combo_errs.loc[combo_errs['case'] == sub_keys['case'], :]\n",
    "subcase_errs = case_errs.loc[case_errs['subcase'] == sub_keys['subcase'], :]\n",
    "plot_df = subcase_errs.loc[subcase_errs['label'] == sub_keys['label'], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "keeps = ['acc', 'treat', 'iter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bc30aaf97c04d00b2ee8331b83413aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ylim=[0,1]\n",
    "title=f\"{acc_name}\\n{combined_iterations} | {sub_keys['dataset']} | {sub_keys['case']} | {sub_keys['label']}\"\n",
    "xlabel='Iteration'\n",
    "ylabel='Accuracy'\n",
    "tabletitle='Median'\n",
    "\n",
    "figtype='jpg'\n",
    "\n",
    "fig = err_line_plots(\n",
    "    plot_df[keeps],\n",
    "    ylim=ylim,\n",
    "    title=title,\n",
    "    xlabel=xlabel,\n",
    "    ylabel=ylabel,\n",
    "    tabletitle=tabletitle,\n",
    "    palette={\n",
    "        'baseline':'tab:blue',\n",
    "        'LotS':'tab:orange',\n",
    "        'LitL':'tab:green',\n",
    "    }\n",
    ")\n",
    "fig.savefig(os.path.join(plots_dir, f\"acc-{sub_keys['dataset']}-{combined_iterations}-{sub_keys['case']}-{sub_keys['label']}.{figtype}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = []\n",
    "base_df = plot_df.loc[plot_df['treat'] == 'baseline', :]\n",
    "for treat in ['LotS', 'LitL']:\n",
    "    treat_df = plot_df.loc[plot_df['treat'] == treat, :]\n",
    "    \n",
    "    for iteration in plot_df['iter'].unique():\n",
    "        base_iter_df = base_df.loc[base_df['iter'] == iteration]\n",
    "        treat_iter_df = treat_df.loc[treat_df['iter'] == iteration]\n",
    "        \n",
    "        accs = []\n",
    "        for _, treat_row in treat_iter_df.iterrows():\n",
    "            for _, base_row in base_iter_df.iterrows():\n",
    "                accs.append(treat_row['acc'] - base_row['acc'])\n",
    "        \n",
    "        diff.append(pd.DataFrame({\n",
    "            'acc': accs,\n",
    "            'iter': int(iteration),\n",
    "            'treat': treat,\n",
    "        }))\n",
    "\n",
    "diff_df = pd.concat(diff, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d7fe20a02a94c62b463e9e106cc2954",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ylim=[-0.15, 0.5]\n",
    "title=f\"{diff_name}\\n{combined_iterations} | {sub_keys['dataset']} | {sub_keys['case']} | {sub_keys['label']}\"\n",
    "xlabel='Iteration'\n",
    "ylabel='Difference'\n",
    "tabletitle='Median'\n",
    "\n",
    "figtype='jpg'\n",
    "\n",
    "fig = err_line_plots(\n",
    "    diff_df,\n",
    "    ylim=ylim,\n",
    "    title=title,\n",
    "    xlabel=xlabel,\n",
    "    ylabel=ylabel,\n",
    "    tabletitle=tabletitle,\n",
    "    palette={\n",
    "        'LotS':'tab:orange',\n",
    "        'LitL':'tab:green',\n",
    "    },\n",
    "    hue_order=['LotS', 'LitL'],\n",
    ")\n",
    "fig.savefig(os.path.join(plots_dir, f\"difference-{sub_keys['dataset']}-{combined_iterations}-{sub_keys['case']}-{sub_keys['label']}.{figtype}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### constituent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### non-entailment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_keys = {\n",
    "    'dataset': 'hans',     # either hans or glue\n",
    "    'case': 'constituent',    # combined or specific to respective itereval set\n",
    "    'subcase': 'combined', # combined or specific to respective itereval set\n",
    "    'label': 'non-entailment',   # combined or [entailment, neutral, contradiction] for glue, [entailment, non-entailment] for hans\n",
    "}\n",
    "\n",
    "\n",
    "hans = get_itereval_summary(sub_keys, iteration, eval_dir, combined_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp = []\n",
    "for idx, row in hans.iterrows():\n",
    "    df = pd.DataFrame({\n",
    "        'acc': row,\n",
    "        'iter': [int(x) for x in row.index.values],\n",
    "        'treat':row.name,\n",
    "        'case':sub_keys['case'],\n",
    "        'subcase':sub_keys['subcase'],\n",
    "        'label':sub_keys['label'],\n",
    "        'comb':combined_iterations\n",
    "    })\n",
    "    temp.append(df)\n",
    "hans_t = pd.concat(temp, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.concat([distributions['itereval'], hans_t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_errs = all_df.loc[all_df['dataset'] == sub_keys['dataset'], :]\n",
    "combo_errs = dataset_errs.loc[dataset_errs['comb'] == combined_iterations, :]\n",
    "case_errs = combo_errs.loc[combo_errs['case'] == sub_keys['case'], :]\n",
    "subcase_errs = case_errs.loc[case_errs['subcase'] == sub_keys['subcase'], :]\n",
    "plot_df = subcase_errs.loc[subcase_errs['label'] == sub_keys['label'], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "keeps = ['acc', 'treat', 'iter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd17cf5dc4744af39e27b9e7a91eb4f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ylim=[0,1]\n",
    "title=f\"{acc_name}\\n{combined_iterations} | {sub_keys['dataset']} | {sub_keys['case']} | {sub_keys['label']}\"\n",
    "xlabel='Iteration'\n",
    "ylabel='Accuracy'\n",
    "tabletitle='Median'\n",
    "\n",
    "figtype='jpg'\n",
    "\n",
    "fig = err_line_plots(\n",
    "    plot_df[keeps],\n",
    "    ylim=ylim,\n",
    "    title=title,\n",
    "    xlabel=xlabel,\n",
    "    ylabel=ylabel,\n",
    "    tabletitle=tabletitle,\n",
    "    palette={\n",
    "        'baseline':'tab:blue',\n",
    "        'LotS':'tab:orange',\n",
    "        'LitL':'tab:green',\n",
    "    }\n",
    ")\n",
    "fig.savefig(os.path.join(plots_dir, f\"acc-{sub_keys['dataset']}-{combined_iterations}-{sub_keys['case']}-{sub_keys['label']}.{figtype}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = []\n",
    "base_df = plot_df.loc[plot_df['treat'] == 'baseline', :]\n",
    "for treat in ['LotS', 'LitL']:\n",
    "    treat_df = plot_df.loc[plot_df['treat'] == treat, :]\n",
    "    \n",
    "    for iteration in plot_df['iter'].unique():\n",
    "        base_iter_df = base_df.loc[base_df['iter'] == iteration]\n",
    "        treat_iter_df = treat_df.loc[treat_df['iter'] == iteration]\n",
    "        \n",
    "        accs = []\n",
    "        for _, treat_row in treat_iter_df.iterrows():\n",
    "            for _, base_row in base_iter_df.iterrows():\n",
    "                accs.append(treat_row['acc'] - base_row['acc'])\n",
    "        \n",
    "        diff.append(pd.DataFrame({\n",
    "            'acc': accs,\n",
    "            'iter': int(iteration),\n",
    "            'treat': treat,\n",
    "        }))\n",
    "\n",
    "diff_df = pd.concat(diff, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "254831a3284c43ba8de3173e2401a777",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ylim=[-0.15, 0.5]\n",
    "title=f\"{diff_name}\\n{combined_iterations} | {sub_keys['dataset']} | {sub_keys['case']} | {sub_keys['label']}\"\n",
    "xlabel='Iteration'\n",
    "ylabel='Difference'\n",
    "tabletitle='Median'\n",
    "\n",
    "figtype='jpg'\n",
    "\n",
    "fig = err_line_plots(\n",
    "    diff_df,\n",
    "    ylim=ylim,\n",
    "    title=title,\n",
    "    xlabel=xlabel,\n",
    "    ylabel=ylabel,\n",
    "    tabletitle=tabletitle,\n",
    "    palette={\n",
    "        'LotS':'tab:orange',\n",
    "        'LitL':'tab:green',\n",
    "    },\n",
    "    hue_order=['LotS', 'LitL'],\n",
    ")\n",
    "fig.savefig(os.path.join(plots_dir, f\"difference-{sub_keys['dataset']}-{combined_iterations}-{sub_keys['case']}-{sub_keys['label']}.{figtype}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HANS - separate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_iterations = 'separate'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lexical_overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### non-entailment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_keys = {\n",
    "    'dataset': 'hans',     # either hans or glue\n",
    "    'case': 'lexical_overlap',    # combined or specific to respective itereval set\n",
    "    'subcase': 'combined', # combined or specific to respective itereval set\n",
    "    'label': 'non-entailment',   # combined or [entailment, neutral, contradiction] for glue, [entailment, non-entailment] for hans\n",
    "}\n",
    "\n",
    "\n",
    "hans = get_itereval_summary(sub_keys, iteration, eval_dir, combined_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp = []\n",
    "for idx, row in hans.iterrows():\n",
    "    df = pd.DataFrame({\n",
    "        'acc': row,\n",
    "        'iter': [int(x) for x in row.index.values],\n",
    "        'treat':row.name,\n",
    "        'case':sub_keys['case'],\n",
    "        'subcase':sub_keys['subcase'],\n",
    "        'label':sub_keys['label'],\n",
    "        'comb':combined_iterations\n",
    "    })\n",
    "    temp.append(df)\n",
    "hans_t = pd.concat(temp, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.concat([distributions['itereval'], hans_t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_errs = all_df.loc[all_df['dataset'] == sub_keys['dataset'], :]\n",
    "combo_errs = dataset_errs.loc[dataset_errs['comb'] == combined_iterations, :]\n",
    "case_errs = combo_errs.loc[combo_errs['case'] == sub_keys['case'], :]\n",
    "subcase_errs = case_errs.loc[case_errs['subcase'] == sub_keys['subcase'], :]\n",
    "plot_df = subcase_errs.loc[subcase_errs['label'] == sub_keys['label'], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "keeps = ['acc', 'treat', 'iter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9790efd5f2d422588408a9725143000",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ylim=[0,1]\n",
    "title=f\"{acc_name}\\n{combined_iterations} | {sub_keys['dataset']} | {sub_keys['case']} | {sub_keys['label']}\"\n",
    "xlabel='Iteration'\n",
    "ylabel='Accuracy'\n",
    "tabletitle='median'\n",
    "\n",
    "figtype='jpg'\n",
    "\n",
    "fig = err_line_plots(\n",
    "    plot_df[keeps],\n",
    "    ylim=ylim,\n",
    "    title=title,\n",
    "    xlabel=xlabel,\n",
    "    ylabel=ylabel,\n",
    "    tabletitle=tabletitle,\n",
    "    palette={\n",
    "        'baseline':'tab:blue',\n",
    "        'LotS':'tab:orange',\n",
    "        'LitL':'tab:green',\n",
    "    }\n",
    ")\n",
    "fig.savefig(os.path.join(plots_dir, f\"acc-{sub_keys['dataset']}-{combined_iterations}-{sub_keys['case']}-{sub_keys['label']}.{figtype}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = []\n",
    "base_df = plot_df.loc[plot_df['treat'] == 'baseline', :]\n",
    "for treat in ['LotS', 'LitL']:\n",
    "    treat_df = plot_df.loc[plot_df['treat'] == treat, :]\n",
    "    \n",
    "    for iteration in plot_df['iter'].unique():\n",
    "        base_iter_df = base_df.loc[base_df['iter'] == iteration]\n",
    "        treat_iter_df = treat_df.loc[treat_df['iter'] == iteration]\n",
    "        \n",
    "        accs = []\n",
    "        for _, treat_row in treat_iter_df.iterrows():\n",
    "            for _, base_row in base_iter_df.iterrows():\n",
    "                accs.append(treat_row['acc'] - base_row['acc'])\n",
    "        \n",
    "        diff.append(pd.DataFrame({\n",
    "            'acc': accs,\n",
    "            'iter': int(iteration),\n",
    "            'treat': treat,\n",
    "        }))\n",
    "\n",
    "diff_df = pd.concat(diff, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "434058dfdd9b42df9b8181a948d7cb5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ylim=[-0.15, 0.5]\n",
    "title=f\"{diff_name}\\n{combined_iterations} | {sub_keys['dataset']} | {sub_keys['case']} | {sub_keys['label']}\"\n",
    "xlabel='Iteration'\n",
    "ylabel='Difference'\n",
    "tabletitle='Median'\n",
    "\n",
    "figtype='jpg'\n",
    "\n",
    "fig = err_line_plots(\n",
    "    diff_df,\n",
    "    ylim=ylim,\n",
    "    title=title,\n",
    "    xlabel=xlabel,\n",
    "    ylabel=ylabel,\n",
    "    tabletitle=tabletitle,\n",
    "    palette={\n",
    "        'LotS':'tab:orange',\n",
    "        'LitL':'tab:green',\n",
    "    },\n",
    "    hue_order=['LotS', 'LitL'],\n",
    ")\n",
    "fig.savefig(os.path.join(plots_dir, f\"difference-{sub_keys['dataset']}-{combined_iterations}-{sub_keys['case']}-{sub_keys['label']}.{figtype}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### subsequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### non-entailment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_keys = {\n",
    "    'dataset': 'hans',     # either hans or glue\n",
    "    'case': 'subsequence',    # combined or specific to respective itereval set\n",
    "    'subcase': 'combined', # combined or specific to respective itereval set\n",
    "    'label': 'non-entailment',   # combined or [entailment, neutral, contradiction] for glue, [entailment, non-entailment] for hans\n",
    "}\n",
    "\n",
    "\n",
    "hans = get_itereval_summary(sub_keys, iteration, eval_dir, combined_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp = []\n",
    "for idx, row in hans.iterrows():\n",
    "    df = pd.DataFrame({\n",
    "        'acc': row,\n",
    "        'iter': [int(x) for x in row.index.values],\n",
    "        'treat':row.name,\n",
    "        'case':sub_keys['case'],\n",
    "        'subcase':sub_keys['subcase'],\n",
    "        'label':sub_keys['label'],\n",
    "        'comb':combined_iterations\n",
    "    })\n",
    "    temp.append(df)\n",
    "hans_t = pd.concat(temp, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.concat([distributions['itereval'], hans_t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_errs = all_df.loc[all_df['dataset'] == sub_keys['dataset'], :]\n",
    "combo_errs = dataset_errs.loc[dataset_errs['comb'] == combined_iterations, :]\n",
    "case_errs = combo_errs.loc[combo_errs['case'] == sub_keys['case'], :]\n",
    "subcase_errs = case_errs.loc[case_errs['subcase'] == sub_keys['subcase'], :]\n",
    "plot_df = subcase_errs.loc[subcase_errs['label'] == sub_keys['label'], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "keeps = ['acc', 'treat', 'iter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d9051a2c5bb4f238c2e7e348df99eb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ylim=[0,1]\n",
    "title=f\"{acc_name}\\n{combined_iterations} | {sub_keys['dataset']} | {sub_keys['case']} | {sub_keys['label']}\"\n",
    "xlabel='Iteration'\n",
    "ylabel='Accuracy'\n",
    "tabletitle='Median'\n",
    "\n",
    "figtype='jpg'\n",
    "\n",
    "fig = err_line_plots(\n",
    "    plot_df[keeps],\n",
    "    ylim=ylim,\n",
    "    title=title,\n",
    "    xlabel=xlabel,\n",
    "    ylabel=ylabel,\n",
    "    tabletitle=tabletitle,\n",
    "    palette={\n",
    "        'baseline':'tab:blue',\n",
    "        'LotS':'tab:orange',\n",
    "        'LitL':'tab:green',\n",
    "    }\n",
    ")\n",
    "fig.savefig(os.path.join(plots_dir, f\"acc-{sub_keys['dataset']}-{combined_iterations}-{sub_keys['case']}-{sub_keys['label']}.{figtype}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = []\n",
    "base_df = plot_df.loc[plot_df['treat'] == 'baseline', :]\n",
    "for treat in ['LotS', 'LitL']:\n",
    "    treat_df = plot_df.loc[plot_df['treat'] == treat, :]\n",
    "    \n",
    "    for iteration in plot_df['iter'].unique():\n",
    "        base_iter_df = base_df.loc[base_df['iter'] == iteration]\n",
    "        treat_iter_df = treat_df.loc[treat_df['iter'] == iteration]\n",
    "        \n",
    "        accs = []\n",
    "        for _, treat_row in treat_iter_df.iterrows():\n",
    "            for _, base_row in base_iter_df.iterrows():\n",
    "                accs.append(treat_row['acc'] - base_row['acc'])\n",
    "        \n",
    "        diff.append(pd.DataFrame({\n",
    "            'acc': accs,\n",
    "            'iter': int(iteration),\n",
    "            'treat': treat,\n",
    "        }))\n",
    "\n",
    "diff_df = pd.concat(diff, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c11615a12da405b9ac5996cf7f61c8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ylim=[-0.15, 0.5]\n",
    "title=f\"{diff_name}\\n{combined_iterations} | {sub_keys['dataset']} | {sub_keys['case']} | {sub_keys['label']}\"\n",
    "xlabel='Iteration'\n",
    "ylabel='Difference'\n",
    "tabletitle='Median'\n",
    "\n",
    "figtype='jpg'\n",
    "\n",
    "fig = err_line_plots(\n",
    "    diff_df,\n",
    "    ylim=ylim,\n",
    "    title=title,\n",
    "    xlabel=xlabel,\n",
    "    ylabel=ylabel,\n",
    "    tabletitle=tabletitle,\n",
    "    palette={\n",
    "        'LotS':'tab:orange',\n",
    "        'LitL':'tab:green',\n",
    "    },\n",
    "    hue_order=['LotS', 'LitL'],\n",
    ")\n",
    "fig.savefig(os.path.join(plots_dir, f\"difference-{sub_keys['dataset']}-{combined_iterations}-{sub_keys['case']}-{sub_keys['label']}.{figtype}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### constituent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### non-entailment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_keys = {\n",
    "    'dataset': 'hans',     # either hans or glue\n",
    "    'case': 'constituent',    # combined or specific to respective itereval set\n",
    "    'subcase': 'combined', # combined or specific to respective itereval set\n",
    "    'label': 'non-entailment',   # combined or [entailment, neutral, contradiction] for glue, [entailment, non-entailment] for hans\n",
    "}\n",
    "\n",
    "\n",
    "hans = get_itereval_summary(sub_keys, iteration, eval_dir, combined_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp = []\n",
    "for idx, row in hans.iterrows():\n",
    "    df = pd.DataFrame({\n",
    "        'acc': row,\n",
    "        'iter': [int(x) for x in row.index.values],\n",
    "        'treat':row.name,\n",
    "        'case':sub_keys['case'],\n",
    "        'subcase':sub_keys['subcase'],\n",
    "        'label':sub_keys['label'],\n",
    "        'comb':combined_iterations\n",
    "    })\n",
    "    temp.append(df)\n",
    "hans_t = pd.concat(temp, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.concat([distributions['itereval'], hans_t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_errs = all_df.loc[all_df['dataset'] == sub_keys['dataset'], :]\n",
    "combo_errs = dataset_errs.loc[dataset_errs['comb'] == combined_iterations, :]\n",
    "case_errs = combo_errs.loc[combo_errs['case'] == sub_keys['case'], :]\n",
    "subcase_errs = case_errs.loc[case_errs['subcase'] == sub_keys['subcase'], :]\n",
    "plot_df = subcase_errs.loc[subcase_errs['label'] == sub_keys['label'], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "keeps = ['acc', 'treat', 'iter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d78c0876dd0f49319ebd25e525943cb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ylim=[0,1]\n",
    "title=f\"{acc_name}\\n{combined_iterations} | {sub_keys['dataset']} | {sub_keys['case']} | {sub_keys['label']}\"\n",
    "xlabel='Iteration'\n",
    "ylabel='Accuracy'\n",
    "tabletitle='Median'\n",
    "\n",
    "figtype='jpg'\n",
    "\n",
    "fig = err_line_plots(\n",
    "    plot_df[keeps],\n",
    "    ylim=ylim,\n",
    "    title=title,\n",
    "    xlabel=xlabel,\n",
    "    ylabel=ylabel,\n",
    "    tabletitle=tabletitle,\n",
    "    palette={\n",
    "        'baseline':'tab:blue',\n",
    "        'LotS':'tab:orange',\n",
    "        'LitL':'tab:green',\n",
    "    }\n",
    ")\n",
    "fig.savefig(os.path.join(plots_dir, f\"acc-{sub_keys['dataset']}-{combined_iterations}-{sub_keys['case']}-{sub_keys['label']}.{figtype}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = []\n",
    "base_df = plot_df.loc[plot_df['treat'] == 'baseline', :]\n",
    "for treat in ['LotS', 'LitL']:\n",
    "    treat_df = plot_df.loc[plot_df['treat'] == treat, :]\n",
    "    \n",
    "    for iteration in plot_df['iter'].unique():\n",
    "        base_iter_df = base_df.loc[base_df['iter'] == iteration]\n",
    "        treat_iter_df = treat_df.loc[treat_df['iter'] == iteration]\n",
    "        \n",
    "        accs = []\n",
    "        for _, treat_row in treat_iter_df.iterrows():\n",
    "            for _, base_row in base_iter_df.iterrows():\n",
    "                accs.append(treat_row['acc'] - base_row['acc'])\n",
    "        \n",
    "        diff.append(pd.DataFrame({\n",
    "            'acc': accs,\n",
    "            'iter': int(iteration),\n",
    "            'treat': treat,\n",
    "        }))\n",
    "\n",
    "diff_df = pd.concat(diff, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ecfb3f93f6f43cab5b98963f036fe02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ylim=[-0.15, 0.5]\n",
    "title=f\"{diff_name}\\n{combined_iterations} | {sub_keys['dataset']} | {sub_keys['case']} | {sub_keys['label']}\"\n",
    "xlabel='Iteration'\n",
    "ylabel='Difference'\n",
    "tabletitle='Median'\n",
    "\n",
    "figtype='jpg'\n",
    "\n",
    "fig = err_line_plots(\n",
    "    diff_df,\n",
    "    ylim=ylim,\n",
    "    title=title,\n",
    "    xlabel=xlabel,\n",
    "    ylabel=ylabel,\n",
    "    tabletitle=tabletitle,\n",
    "    palette={\n",
    "        'LotS':'tab:orange',\n",
    "        'LitL':'tab:green',\n",
    "    },\n",
    "    hue_order=['LotS', 'LitL'],\n",
    ")\n",
    "fig.savefig(os.path.join(plots_dir, f\"difference-{sub_keys['dataset']}-{combined_iterations}-{sub_keys['case']}-{sub_keys['label']}.{figtype}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNLI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = 'combined'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre = 'combined'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with open(mnli_summary, 'r') as f:\n",
    "    summary = pd.DataFrame([json.loads(line) for line in f])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iter_summary = summary.loc[summary['iter'] == str(iteration), :]\n",
    "comb_summary = iter_summary.loc[iter_summary['comb'] == combined, :]\n",
    "genre_summary = comb_summary.loc[comb_summary['tag'] == genre, :] # <--- CHANGE 'tag' to 'genre'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_errs = distributions['mnli'].loc[distributions['mnli']['comb'] == combined, :]\n",
    "plot_df = comb_errs.loc[comb_errs['genre'] == genre, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "keeps = ['acc', 'treat', 'iter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f6fd032add24bd4885afbc209c0ae31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ylim=[0.7,1]\n",
    "title=f'{acc_name}\\nmnli | {combined} | {genre} genre'\n",
    "xlabel='Iteration'\n",
    "ylabel='Accuracy'\n",
    "tabletitle='Median'\n",
    "\n",
    "figtype='jpg'\n",
    "\n",
    "fig = err_line_plots(\n",
    "    plot_df[keeps],\n",
    "    ylim=ylim,\n",
    "    title=title,\n",
    "    xlabel=xlabel,\n",
    "    ylabel=ylabel,\n",
    "    tabletitle=tabletitle,\n",
    "    palette={\n",
    "        'baseline':'tab:blue',\n",
    "        'LotS':'tab:orange',\n",
    "        'LitL':'tab:green',\n",
    "    }\n",
    ")\n",
    "fig.savefig(os.path.join(plots_dir, f'acc-mnli-{combined}-{genre}.{figtype}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = []\n",
    "base_df = plot_df.loc[plot_df['treat'] == 'baseline', :]\n",
    "for treat in ['LotS', 'LitL']:\n",
    "    treat_df = plot_df.loc[plot_df['treat'] == treat, :]\n",
    "    \n",
    "    for iteration in plot_df['iter'].unique():\n",
    "        base_iter_df = base_df.loc[base_df['iter'] == iteration]\n",
    "        treat_iter_df = treat_df.loc[treat_df['iter'] == iteration]\n",
    "        \n",
    "        accs = []\n",
    "        for _, treat_row in treat_iter_df.iterrows():\n",
    "            for _, base_row in base_iter_df.iterrows():\n",
    "                accs.append(treat_row['acc'] - base_row['acc'])\n",
    "        \n",
    "        diff.append(pd.DataFrame({\n",
    "            'acc': accs,\n",
    "            'iter': int(iteration),\n",
    "            'treat': treat,\n",
    "        }))\n",
    "\n",
    "diff_df = pd.concat(diff, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b89aa6b058804d6ca4a6c15787fc2ca5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ylim=[-0.05, 0.05]\n",
    "title=f\"{diff_name}\\nmnli | {combined} | {genre} genre\"\n",
    "xlabel='Iteration'\n",
    "ylabel='Difference'\n",
    "tabletitle='Median'\n",
    "\n",
    "figtype='jpg'\n",
    "\n",
    "fig = err_line_plots(\n",
    "    diff_df,\n",
    "    ylim=ylim,\n",
    "    title=title,\n",
    "    xlabel=xlabel,\n",
    "    ylabel=ylabel,\n",
    "    tabletitle=tabletitle,\n",
    "    palette={\n",
    "        'LotS':'tab:orange',\n",
    "        'LitL':'tab:green',\n",
    "    },\n",
    "    hue_order=['LotS', 'LitL'],\n",
    ")\n",
    "fig.savefig(os.path.join(plots_dir, f\"difference-mnli-{combined}-{genre}.{figtype}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = 'separate'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre = 'combined'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with open(mnli_summary, 'r') as f:\n",
    "    summary = pd.DataFrame([json.loads(line) for line in f])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iter_summary = summary.loc[summary['iter'] == str(iteration), :]\n",
    "comb_summary = iter_summary.loc[iter_summary['comb'] == combined, :]\n",
    "genre_summary = comb_summary.loc[comb_summary['tag'] == genre, :] # <--- CHANGE 'tag' to 'genre'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_errs = distributions['mnli'].loc[distributions['mnli']['comb'] == combined, :]\n",
    "plot_df = comb_errs.loc[comb_errs['genre'] == genre, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "keeps = ['acc', 'treat', 'iter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05a29d2d7f6343349da16e1774b83070",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ylim=[0.7,1]\n",
    "title=f'{acc_name}\\nmnli | {combined} | {genre} genre'\n",
    "xlabel='Iteration'\n",
    "ylabel='Accuracy'\n",
    "tabletitle='Median'\n",
    "\n",
    "figtype='jpg'\n",
    "\n",
    "fig = err_line_plots(\n",
    "    plot_df[keeps],\n",
    "    ylim=ylim,\n",
    "    title=title,\n",
    "    xlabel=xlabel,\n",
    "    ylabel=ylabel,\n",
    "    tabletitle=tabletitle,\n",
    "    palette={\n",
    "        'baseline':'tab:blue',\n",
    "        'LotS':'tab:orange',\n",
    "        'LitL':'tab:green',\n",
    "    }\n",
    ")\n",
    "fig.savefig(os.path.join(plots_dir, f'acc-mnli-{combined}-{genre}.{figtype}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = []\n",
    "base_df = plot_df.loc[plot_df['treat'] == 'baseline', :]\n",
    "for treat in ['LotS', 'LitL']:\n",
    "    treat_df = plot_df.loc[plot_df['treat'] == treat, :]\n",
    "    \n",
    "    for iteration in plot_df['iter'].unique():\n",
    "        base_iter_df = base_df.loc[base_df['iter'] == iteration]\n",
    "        treat_iter_df = treat_df.loc[treat_df['iter'] == iteration]\n",
    "        \n",
    "        accs = []\n",
    "        for _, treat_row in treat_iter_df.iterrows():\n",
    "            for _, base_row in base_iter_df.iterrows():\n",
    "                accs.append(treat_row['acc'] - base_row['acc'])\n",
    "        \n",
    "        diff.append(pd.DataFrame({\n",
    "            'acc': accs,\n",
    "            'iter': int(iteration),\n",
    "            'treat': treat,\n",
    "        }))\n",
    "\n",
    "diff_df = pd.concat(diff, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "997793bf598e453c8770b851d7e7f823",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ylim=[-0.05, 0.05]\n",
    "title=f\"{diff_name}\\n mnli | {combined} | {genre} genre\"\n",
    "xlabel='Iteration'\n",
    "ylabel='Difference'\n",
    "tabletitle='Median'\n",
    "\n",
    "figtype='jpg'\n",
    "\n",
    "fig = err_line_plots(\n",
    "    diff_df,\n",
    "    ylim=ylim,\n",
    "    title=title,\n",
    "    xlabel=xlabel,\n",
    "    ylabel=ylabel,\n",
    "    tabletitle=tabletitle,\n",
    "    palette={\n",
    "        'LotS':'tab:orange',\n",
    "        'LitL':'tab:green',\n",
    "    },\n",
    "    hue_order=['LotS', 'LitL'],\n",
    ")\n",
    "fig.savefig(os.path.join(plots_dir, f\"difference-mnli-{combined}-{genre}.{figtype}\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
