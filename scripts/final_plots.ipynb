{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "_model = 'roberta-large' # roberta-large or roberta-large-mnli\n",
    "overwrite_plotting_data = False # Set to True if running for first time with new experiment data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import collections\n",
    "import copy\n",
    "import itertools\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import joblib\n",
    "import pickle\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.path as pth\n",
    "import seaborn as sns\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from scipy.stats import ttest_ind, f_oneway\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.set_theme(style='whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_val_summary(modifier, iteration, eval_dir, ):\n",
    "    fname = os.path.join(eval_dir, f'r{iteration}', 'tables', f'configs.{modifier}.csv')\n",
    "    summary_table = pd.read_csv(fname, index_col = 0)\n",
    "    summary_table = summary_table[[str(n) for n in range(1, iteration+1)]]\n",
    "    \n",
    "    return summary_table\n",
    "\n",
    "\n",
    "def get_itereval_summary(sub_keys, iteration, eval_dir, combined, ):\n",
    "    rep = {\n",
    "        '/': '-',\n",
    "        ';': '--',\n",
    "    }\n",
    "    \n",
    "    fname_key = '.'.join(sub_keys.values())\n",
    "    for old_char, new_char in rep.items():\n",
    "        fname_key = fname_key.replace(old_char, new_char)\n",
    "    fname = os.path.join(eval_dir, f'r{iteration}', 'tables', combined, f'iterevals.{fname_key}.csv')\n",
    "    summary_table = pd.read_csv(fname, index_col = 0)\n",
    "    summary_table = summary_table[[str(n) for n in range(1, iteration+1)]]\n",
    "    \n",
    "    return summary_table\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_mnli_tables(mnli_summary, subsetting='genre'):\n",
    "    with open(mnli_summary, 'r') as f:\n",
    "        summary = pd.DataFrame([json.loads(line) for line in f])\n",
    "    \n",
    "    mnli_tables = {}\n",
    "    for comb in summary['comb'].unique():\n",
    "        comb_sum = summary.loc[summary['comb'] == comb, :]\n",
    "\n",
    "        for subset in summary[subsetting].unique():\n",
    "            subset_sum = comb_sum.loc[comb_sum[subsetting] == subset, :]\n",
    "\n",
    "            plot_tab = []\n",
    "            for treat in subset_sum['treat'].unique():\n",
    "                treat_sum = subset_sum.loc[subset_sum['treat'] == treat, :]\n",
    "                s = treat_sum[['iter','acc']].set_index('iter').rename({'acc': treat}, axis=1).transpose()            \n",
    "                plot_tab.append(s)\n",
    "            \n",
    "            mnli_tables[(model, comb, subset)] = pd.concat(plot_tab)\n",
    "    \n",
    "    return summary, mnli_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def split_run_name(run_name, split_by='_'):\n",
    "    name_list = run_name.split(split_by)\n",
    "    if len(name_list) == 2:\n",
    "        input_type = 'full'\n",
    "        comb = 'combined'\n",
    "    elif len(name_list) == 3:\n",
    "        if name_list[-1] == 'hyp':\n",
    "            input_type = name_list[-1]\n",
    "            comb = 'combined'\n",
    "        else:\n",
    "            input_type = 'full'\n",
    "            comb = name_list[-1]\n",
    "    else:\n",
    "        input_type = name_list[-1]\n",
    "        comb = name_list[-2]\n",
    "\n",
    "    return (name_list[0], name_list[1], input_type, comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def unique_itereval(df, keys=['case', 'subcase', 'label', 'dataset', 'treat', 'iter', 'comb', 'sample_type', 'sample_partition']):\n",
    "    return df.drop_duplicates(subset=keys, ignore_index=True)\n",
    "\n",
    "def load_sampled_results(sampled_base):\n",
    "    collected = pd.read_csv(os.path.join(sampled_base, 'collected.csv'))\n",
    "    itereval = pd.read_csv(os.path.join(sampled_base, 'itereval.csv'))\n",
    "    mnli = pd.read_csv(os.path.join(sampled_base, 'mnli.csv'))\n",
    "    anli = pd.read_csv(os.path.join(sampled_base, 'anli.csv'))\n",
    "    \n",
    "    \n",
    "    # fill in keys\n",
    "    collected['treat'] = collected['run'].apply(lambda x: split_run_name(x)[0])\n",
    "    collected['iter'] = collected['run'].apply(lambda x: int(split_run_name(x)[1]))\n",
    "    collected['mod'] = collected['run'].apply(lambda x: split_run_name(x)[2])\n",
    "    collected['combined'] = collected['run'].apply(lambda x: split_run_name(x)[3])\n",
    "    \n",
    "    \n",
    "    mnli['breakdown'] = mnli['genre'].fillna('combined')\n",
    "    anli['breakdown'] = anli['tag'].fillna('combined')\n",
    "    \n",
    "    itereval = unique_itereval(itereval)\n",
    "    \n",
    "    return collected, itereval, mnli, anli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def load_all_sampled(sampled_base, upto=5):\n",
    "    loaded_keys = {'collected': 0, 'itereval':1 ,'mnli': 2, 'anli': 3}\n",
    "    results = {key: [] for key in loaded_keys.keys()}\n",
    "    \n",
    "    for r in range(1, upto + 1):\n",
    "        loaded = load_sampled_results(os.path.join(sampled_base, f'r{r}'))\n",
    "        for result_key, loaded_key in loaded_keys.items():\n",
    "            results[result_key].append(loaded[loaded_key])\n",
    "    \n",
    "    return {\n",
    "        key: pd.concat(result_list, ignore_index=True)\n",
    "        for key, result_list in results.items()\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_ttest_pvals(dist_df, verbose=True):\n",
    "    pairs = [\n",
    "        ('baseline', 'LotS'),\n",
    "        ('baseline', 'LitL'),\n",
    "        ('LotS', 'LitL'),\n",
    "    ]\n",
    "    \n",
    "    ttest_dict = {}\n",
    "    for pair in pairs:\n",
    "        a = dist_df.loc[dist_df['treat'] == pair[0], 'acc']\n",
    "        b = dist_df.loc[dist_df['treat'] == pair[1], 'acc']\n",
    "        ttest_dict[pair] = ttest_ind(a, b)\n",
    "    \n",
    "    if verbose:\n",
    "        for pair, ttest_results in ttest_dict.items():\n",
    "            print('='*45)\n",
    "            print(f\"{pair}\\nt: {ttest_results[0]:.5f} | p: {ttest_results[1]/2:.5f}\")\n",
    "    \n",
    "    return ttest_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def two_way_anova(df, f1='iter', f2='treat', acc='acc', formula=None):\n",
    "    keeps = [f1, f2, acc]\n",
    "    \n",
    "    if not formula:\n",
    "        formula = f'{acc} ~ C({f1}) + C({f2}) + C({f1}):C({f2})'\n",
    "        \n",
    "    print(formula)\n",
    "    model = ols(formula, data=df[keeps]).fit()\n",
    "    \n",
    "    return sm.stats.anova_lm(model, typ=2), model\n",
    "\n",
    "def one_way_anova(df, f='iter', acc='acc', formula=None):\n",
    "    keeps = [f, acc]\n",
    "    \n",
    "    if not formula:\n",
    "        formula = f'{acc} ~ C({f})'\n",
    "        \n",
    "    print(formula)\n",
    "    model = ols(formula, data=df[keeps]).fit()\n",
    "    \n",
    "    return sm.stats.anova_lm(model, typ=1), model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Combine Plotting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "repo = os.path.dirname(os.path.dirname(os.path.abspath('__file__')))\n",
    "sample_type = 'cross_eval'\n",
    "iteration = 5\n",
    "plot_data = os.path.join(repo, 'eval_summary', 'plot_data')\n",
    "os.makedirs(plot_data, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "models = ['roberta-large', 'roberta-large-mnli']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "distributions = {}\n",
    "\n",
    "for model in models:\n",
    "    eval_dir = os.path.join(repo, 'eval_summary', model)\n",
    "    distributions[model] = load_all_sampled(\n",
    "        os.path.join(eval_dir, 'sample', sample_type), upto=iteration\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## MNLI Only Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pred_base = os.path.join(repo, 'predictions', 'roberta-large-mnli_only')\n",
    "data_base = os.path.join(repo, 'tasks', 'data')\n",
    "best_data = os.path.join(pred_base, 'best')\n",
    "\n",
    "pred_dirs = [\n",
    "    'baseline_5',\n",
    "    'LotS_5',\n",
    "    'LitL_5',\n",
    "    'mnlieval_baseline_1',\n",
    "    'anlieval_baseline_1',\n",
    "    'eval_baseline_1',\n",
    "]\n",
    "\n",
    "data_dirs = [\n",
    "    os.path.join('baseline_5', 'val_round5_base_combined.jsonl'),\n",
    "    os.path.join('LotS_5', 'val_round5_LotS_combined.jsonl'),\n",
    "    os.path.join('LitL_5', 'val_round5_LitL_combined.jsonl'),\n",
    "    os.path.join('mnli_mismatched', 'val_mismatched_mnli.jsonl'),\n",
    "    os.path.join('anli_combined', 'val_anli.jsonl'),\n",
    "    os.path.join('iterative_eval', 'val_itercombined.jsonl'),\n",
    "]\n",
    "\n",
    "lrs = ['0.00001', '0.00002', '0.00003']\n",
    "batches = ['16', '32']\n",
    "\n",
    "n_trials = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def read_jsonl(file):\n",
    "    with open(file, 'r') as f:\n",
    "        return [json.loads(line) for line in f.readlines()]\n",
    "    \n",
    "def get_acc(\n",
    "    preds,\n",
    "    data,\n",
    "    int2pred={0:'contradiction', 1:'entailment', 2:'neutral'}\n",
    "):\n",
    "    df = pd.DataFrame(data)\n",
    "    df['preds'] = pd.Series(preds).apply(lambda x: int2pred[x])\n",
    "    df['correct'] = df['label'].eq(df['preds'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if overwrite_plotting_data:\n",
    "    preds_and_data = {}\n",
    "\n",
    "    for pred, data in zip(pred_dirs, data_dirs):\n",
    "        temp_pred = torch.load(os.path.join(pred_base, pred, 'val_preds.p'))\n",
    "        temp_data = read_jsonl(os.path.join(data_base, data))\n",
    "        preds_and_data[pred.split('_')[0]] = {'pred': temp_pred, 'data':temp_data}\n",
    "\n",
    "    accs = {\n",
    "        key: get_acc(val['pred']['mnli']['preds'], val['data']) for key, val in preds_and_data.items()\n",
    "    }\n",
    "    \n",
    "    accs['glue'] = accs['eval'].loc[accs['eval']['dataset'] == 'glue']\n",
    "    \n",
    "    hans = accs['eval'].loc[accs['eval']['dataset'] == 'hans', :]\n",
    "    tempdict = {'contradiction':'contradiction', 'neutral':'contradiction', 'entailment':'entailment'}\n",
    "    hans['preds'] = hans['preds'].apply(lambda x: tempdict[x])\n",
    "    hans['case'] = hans['case'].apply(lambda x: x[0])\n",
    "    hans['correct'] = hans['label'].eq(hans['preds'])\n",
    "    \n",
    "    accs['hans'] = hans\n",
    "    \n",
    "    with open(os.path.join(plot_data, 'mnli-only-training_accs.p'), 'wb') as f:\n",
    "        pickle.dump(accs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if overwrite_plotting_data:\n",
    "    for trial in range(1, n_trials+1):\n",
    "        preds_and_data = {}\n",
    "\n",
    "        for pred, data in zip(pred_dirs, data_dirs):\n",
    "            temp_pred = torch.load(os.path.join(best_data, pred, f'{trial}', 'val_preds.p'))\n",
    "            temp_data = read_jsonl(os.path.join(data_base, data))\n",
    "            preds_and_data[pred.split('_')[0]] = {'pred': temp_pred, 'data':temp_data}\n",
    "\n",
    "        accs = {\n",
    "            key: get_acc(val['pred']['mnli']['preds'], val['data']) for key, val in preds_and_data.items()\n",
    "        }\n",
    "\n",
    "        accs['glue'] = accs['eval'].loc[accs['eval']['dataset'] == 'glue']\n",
    "\n",
    "        hans = accs['eval'].loc[accs['eval']['dataset'] == 'hans', :]\n",
    "        tempdict = {'contradiction':'contradiction', 'neutral':'contradiction', 'entailment':'entailment'}\n",
    "        hans['preds'] = hans['preds'].apply(lambda x: tempdict[x])\n",
    "        hans['case'] = hans['case'].apply(lambda x: x[0])\n",
    "        hans['correct'] = hans['label'].eq(hans['preds'])\n",
    "\n",
    "        accs['hans'] = hans\n",
    "\n",
    "        mnli_out_dir = os.path.join(plot_data, 'mnli_restarts', 'best', f'{trial}')\n",
    "        os.makedirs(mnli_out_dir, exist_ok = True)\n",
    "        with open(os.path.join(mnli_out_dir, 'mnli-only-training_accs.p'), 'wb') as f:\n",
    "            pickle.dump(accs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Collected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "select2mod = {\n",
    "    ('combined', 'full'): 'combined',\n",
    "    ('combined', 'hyp'): 'hyp',\n",
    "    ('separate', 'full'): 'separate',\n",
    "    ('separate', 'hyp'): 'separate_hyp',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_df = []\n",
    "\n",
    "if overwrite_plotting_data:\n",
    "    for model in models:\n",
    "        collected = []\n",
    "        eval_dir = os.path.join(repo, 'eval_summary', model)\n",
    "\n",
    "        for combined, input_type in select2mod.keys():\n",
    "            mod = select2mod[(combined, input_type)]\n",
    "            temp = get_val_summary(mod, iteration, eval_dir, )\n",
    "            for idx, row in temp.iterrows():\n",
    "                df = pd.DataFrame({\n",
    "                    'acc': row,\n",
    "                    'iter': [int(x) for x in row.index.values],\n",
    "                    'treat':row.name,\n",
    "                    'mod':input_type,\n",
    "                    'combined':combined,\n",
    "                    'model':model,\n",
    "                })\n",
    "                collected.append(df)\n",
    "        collected_t = pd.concat(collected, ignore_index = True)\n",
    "        distributions[model]['collected']['model'] = model\n",
    "        all_df.append(pd.concat([distributions[model]['collected'], collected_t], ignore_index = True))\n",
    "    df = pd.concat(all_df, ignore_index = True)\n",
    "    df.to_csv(os.path.join(plot_data, 'collected.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## GLUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            case                                subcase\n",
      "0                       combined                               combined\n",
      "1                      Knowledge                               combined\n",
      "2                      Knowledge                           Common sense\n",
      "3                      Knowledge                        World knowledge\n",
      "4              Lexical Semantics                               combined\n",
      "..                           ...                                    ...\n",
      "64  Predicate-Argument Structure  Relative clauses;Anaphora/Coreference\n",
      "65  Predicate-Argument Structure         Relative clauses;Restrictivity\n",
      "66  Predicate-Argument Structure                          Restrictivity\n",
      "67  Predicate-Argument Structure     Restrictivity;Anaphora/Coreference\n",
      "68  Predicate-Argument Structure         Restrictivity;Relative clauses\n",
      "\n",
      "[69 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "glue_keys = pd.read_csv('glue_case_keys.csv')\n",
    "print(glue_keys)\n",
    "glue_labels = ['combined', 'entailment', 'neutral', 'contradiction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset = 'glue'\n",
    "\n",
    "combineds = ['combined', 'separate']\n",
    "all_df = []\n",
    "\n",
    "if overwrite_plotting_data:\n",
    "    for model in models:\n",
    "        collected = []\n",
    "        eval_dir = os.path.join(repo, 'eval_summary', model)\n",
    "\n",
    "        for idx, caserow in glue_keys.iterrows():\n",
    "            for label in glue_labels:\n",
    "                for combined in combineds:\n",
    "                    sub_keys = {\n",
    "                        'dataset': dataset,     # either hans or glue\n",
    "                        'case': caserow['case'],    # combined or specific to respective itereval set\n",
    "                        'subcase': caserow['subcase'], # combined or specific to respective itereval set\n",
    "                        'label': label,   # combined or [entailment, neutral, contradiction] for glue, [entailment, non-entailment] for hans\n",
    "                    }\n",
    "\n",
    "                    temp = get_itereval_summary(sub_keys, iteration, eval_dir, combined)\n",
    "                    for idx, row in temp.iterrows():\n",
    "                        df = pd.DataFrame({\n",
    "                            'acc': row,\n",
    "                            'iter': [int(x) for x in row.index.values],\n",
    "                            'treat':row.name,\n",
    "                            'case':sub_keys['case'],\n",
    "                            'subcase':sub_keys['subcase'],\n",
    "                            'label':sub_keys['label'],\n",
    "                            'comb':combined,\n",
    "                            'model':model,\n",
    "                        })\n",
    "                        collected.append(df)\n",
    "                collected_t = pd.concat(collected, ignore_index = True)\n",
    "\n",
    "        temp_sampled = distributions[model]['itereval']\n",
    "        temp_sampled = temp_sampled.loc[temp_sampled['dataset'] == dataset, :]\n",
    "        temp_sampled['model'] = model\n",
    "        all_df.append(pd.concat([temp_sampled, collected_t], ignore_index=True))\n",
    "    df = pd.concat(all_df, ignore_index = True)\n",
    "    df.to_csv(os.path.join(plot_data, 'glue.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## HANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               case                         subcase\n",
      "0          combined                        combined\n",
      "1       constituent                       ce_adverb\n",
      "2       constituent           ce_after_since_clause\n",
      "3       constituent                  ce_conjunction\n",
      "4       constituent         ce_embedded_under_since\n",
      "5       constituent          ce_embedded_under_verb\n",
      "6       constituent                       cn_adverb\n",
      "7       constituent              cn_after_if_clause\n",
      "8       constituent                  cn_disjunction\n",
      "9       constituent            cn_embedded_under_if\n",
      "10      constituent          cn_embedded_under_verb\n",
      "11      constituent                        combined\n",
      "12  lexical_overlap                        combined\n",
      "13  lexical_overlap  le_around_prepositional_phrase\n",
      "14  lexical_overlap       le_around_relative_clause\n",
      "15  lexical_overlap                  le_conjunction\n",
      "16  lexical_overlap                      le_passive\n",
      "17  lexical_overlap              le_relative_clause\n",
      "18  lexical_overlap                  ln_conjunction\n",
      "19  lexical_overlap                      ln_passive\n",
      "20  lexical_overlap                  ln_preposition\n",
      "21  lexical_overlap              ln_relative_clause\n",
      "22  lexical_overlap          ln_subject/object_swap\n",
      "23      subsequence                        combined\n",
      "24      subsequence                    se_adjective\n",
      "25      subsequence                  se_conjunction\n",
      "26      subsequence                    se_PP_on_obj\n",
      "27      subsequence       se_relative_clause_on_obj\n",
      "28      subsequence            se_understood_object\n",
      "29      subsequence                         sn_NP/S\n",
      "30      subsequence                         sn_NP/Z\n",
      "31      subsequence              sn_past_participle\n",
      "32      subsequence                sn_PP_on_subject\n",
      "33      subsequence   sn_relative_clause_on_subject\n"
     ]
    }
   ],
   "source": [
    "hans_keys = pd.read_csv('hans_case_keys.csv')\n",
    "print(hans_keys)\n",
    "hans_labels = ['combined', 'entailment', 'non-entailment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset = 'hans'\n",
    "\n",
    "combineds = ['combined', 'separate']\n",
    "all_df = []\n",
    "\n",
    "if overwrite_plotting_data:\n",
    "    for model in models:\n",
    "        collected = []\n",
    "        eval_dir = os.path.join(repo, 'eval_summary', model)\n",
    "\n",
    "        for idx, caserow in hans_keys.iterrows():\n",
    "            for label in hans_labels:\n",
    "                for combined in combineds:\n",
    "                    sub_keys = {\n",
    "                        'dataset': dataset,     # either glue or hans\n",
    "                        'case': caserow['case'],    # combined or specific to respective itereval set\n",
    "                        'subcase': caserow['subcase'], # combined or specific to respective itereval set\n",
    "                        'label': label,   # combined or [entailment, neutral, contradiction] for glue, [entailment, non-entailment] for hans\n",
    "                    }\n",
    "\n",
    "                    temp = get_itereval_summary(sub_keys, iteration, eval_dir, combined)\n",
    "                    for idx, row in temp.iterrows():\n",
    "                        df = pd.DataFrame({\n",
    "                            'acc': row,\n",
    "                            'iter': [int(x) for x in row.index.values],\n",
    "                            'treat':row.name,\n",
    "                            'case':sub_keys['case'],\n",
    "                            'subcase':sub_keys['subcase'],\n",
    "                            'label':sub_keys['label'],\n",
    "                            'comb':combined,\n",
    "                            'model':model,\n",
    "                        })\n",
    "                        collected.append(df)\n",
    "                collected_t = pd.concat(collected, ignore_index = True)\n",
    "\n",
    "        temp_sampled = distributions[model]['itereval']\n",
    "        temp_sampled = temp_sampled.loc[temp_sampled['dataset'] == dataset, :]\n",
    "        temp_sampled['model'] = model\n",
    "        all_df.append(pd.concat([temp_sampled, collected_t], ignore_index=True))\n",
    "    df = pd.concat(all_df, ignore_index = True)\n",
    "    df.to_csv(os.path.join(plot_data, 'hans.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## MNLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_df = []\n",
    "\n",
    "if overwrite_plotting_data:\n",
    "    for model in models:\n",
    "        eval_dir = os.path.join(repo, 'eval_summary', model)\n",
    "        mnli_summary = os.path.join(eval_dir, 'mnli_evals', 'eval_summaries.jsonl')\n",
    "\n",
    "        with open(mnli_summary, 'r') as f:\n",
    "            summary = pd.DataFrame([json.loads(line) for line in f])\n",
    "        summary['breakdown'] = summary['genre'].fillna('combined')\n",
    "        summary['iter'] = summary['iter'].apply(lambda x: int(x))\n",
    "\n",
    "        temp = pd.concat([distributions[model]['mnli'], summary], ignore_index=True)\n",
    "        temp['model'] = model\n",
    "\n",
    "        all_df.append(temp)\n",
    "    df = pd.concat(all_df, ignore_index = True)\n",
    "    df.to_csv(os.path.join(plot_data, 'mnli.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## ANLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_df = []\n",
    "\n",
    "if overwrite_plotting_data:\n",
    "    for model in models:\n",
    "        eval_dir = os.path.join(repo, 'eval_summary', model)\n",
    "        df = pd.read_csv(os.path.join(eval_dir, 'sample', sample_type, 'final', 'anli_by_annotation.csv'))\n",
    "        df['model'] = model\n",
    "\n",
    "        all_df.append(df)\n",
    "    df = pd.concat(all_df, ignore_index = True)\n",
    "    df.to_csv(os.path.join(plot_data, 'anli.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Plot Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "combined = 'combined'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "repo = os.path.dirname(os.path.dirname(os.path.abspath('__file__')))\n",
    "plot_dir = os.path.join(repo, 'eval_summary', 'plot_data')\n",
    "plot_out = os.path.join(repo, 'eval_summary', 'plots', _model)\n",
    "os.makedirs(plot_out, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "acc_name = 'Performance'\n",
    "diff_name = 'Over Baseline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "save_figs = True\n",
    "figtype='pdf'\n",
    "\n",
    "err_style='bars' # band or bars\n",
    "err_kws={'elinewidth': 2, 'capsize': 3}\n",
    "\n",
    "title_fontsize=18\n",
    "label_fontsize=16\n",
    "legend_fontsize=14\n",
    "\n",
    "err_line_offset = 4 if _model == 'roberta-large' else 5\n",
    "err_cap_offset = 0.05\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cols2plot = {'treat':'Protocol', 'model':'Model'}\n",
    "treat2plot = {'baseline':'Baseline', 'LotS':'LitL', 'LitL':'LitL Chat'}\n",
    "model2plot = {'roberta-large': r'RoBERTa$_{\\rm{Lg}}$', 'roberta-large-mnli': r'RoBERTa$_{\\rm{Lg+MNLI}}$'}\n",
    "\n",
    "hue='Protocol'\n",
    "hue_order=['Baseline', 'LitL', 'LitL Chat']\n",
    "style_key='Model'\n",
    "style_order=[\n",
    "    model2plot[_model]\n",
    "]\n",
    "boxplots=False\n",
    "saveappend = \"-box\" if boxplots else \"\"\n",
    "\n",
    "palette={\n",
    "        'baseline':'tab:blue',\n",
    "        'LitL':'tab:orange',\n",
    "        'LitL Chat':'tab:green',\n",
    "    }\n",
    "resid_palette={\n",
    "        'baseline':'tab:blue',\n",
    "        'Baseline':'tab:blue',\n",
    "        'LitL':'tab:orange',\n",
    "        'LotS':'tab:green',\n",
    "        'LitL Chat':'tab:green',\n",
    "    }\n",
    "symbols = {\n",
    "    1:\"D\", \n",
    "    5:\"^\",\n",
    "}\n",
    "\n",
    "xlim = [0.8, 5.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(plot_dir, 'mnli-only-training_accs.p'), 'rb') as f:\n",
    "    mnli_accs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Def plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def err_line_plots(\n",
    "    plot_df,\n",
    "    ylim=[0,1],\n",
    "    ystep=0.1,\n",
    "    xlim=[1,5],\n",
    "    title=None,\n",
    "    xlabel=None,\n",
    "    ylabel=None,\n",
    "    tabletitle=None,\n",
    "    tableon=True,\n",
    "    x='iter',\n",
    "    y='acc',\n",
    "    err_style='bars',\n",
    "    ci=95,\n",
    "    estimator='mean',\n",
    "    markers=True,\n",
    "    hue='treat',\n",
    "    hue_order=['baseline', 'LotS', 'LitL'],\n",
    "    iteration=5,\n",
    "    bbox_to_anchor=(1.01, 1),\n",
    "    palette=None,\n",
    "    style_key='combined',\n",
    "    style_order=['combined', 'separate'],\n",
    "    yaxis_visible = True,\n",
    "    xaxis_visible = True,\n",
    "    ylabel_visible = True,\n",
    "    xlabel_visible = True,\n",
    "    legend_visible = True,\n",
    "    ax=None,\n",
    "    figsize=(6.4, 4.8),\n",
    "    err_kws={'elinewidth': 1, 'capsize': 2},\n",
    "    err_alpha=0.6,\n",
    "    linewidth=2,\n",
    "    markersize=7,\n",
    "    loc='best',\n",
    "    ncol=1,\n",
    "    error_offsets = [\n",
    "        {\n",
    "            'line':-err_line_offset,\n",
    "            'cap':-err_cap_offset,\n",
    "        },\n",
    "        {\n",
    "            'line':0,\n",
    "            'cap':0,\n",
    "        },\n",
    "        {\n",
    "            'line':+err_line_offset,\n",
    "            'cap':+err_cap_offset,\n",
    "        }\n",
    "    ],\n",
    "    boxplots = False,\n",
    "):\n",
    "    kwargs = {}\n",
    "    no_ax = not ax\n",
    "    if not ax:\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "        \n",
    "    if len(style_order) == 1:\n",
    "        plot_df = plot_df.loc[plot_df[style_key] == style_order[0], :]\n",
    "        style_key, style_order = hue, hue_order\n",
    "        \n",
    "    if boxplots:\n",
    "        # Boxplots\n",
    "        sns.boxplot(\n",
    "            data=plot_df, x=x, y=y,\n",
    "            hue=hue, hue_order=hue_order,\n",
    "            ax=ax, **kwargs,\n",
    "            width=0.4, saturation=1,\n",
    "        )\n",
    "    else:\n",
    "        # Lineplot\n",
    "        g = sns.lineplot(\n",
    "            data=plot_df, x=x, y=y,\n",
    "            hue=hue, hue_order=hue_order,\n",
    "            style = style_key, style_order = style_order,\n",
    "            err_style=err_style, err_kws=err_kws,\n",
    "            ci=ci, markers=markers,\n",
    "            ax=ax, **kwargs,\n",
    "            linewidth=linewidth, markersize=markersize,\n",
    "        )\n",
    "\n",
    "        if error_offsets:\n",
    "            assert len(g.containers) == len(error_offsets), f'{len(g.collections)}, error_offsets {len(error_offsets)}'\n",
    "\n",
    "            for container, offsets in zip(g.containers, error_offsets):\n",
    "                # offset line\n",
    "                plt.setp(container[2][0], offsets = [offsets['line'], 0.])\n",
    "\n",
    "                # offset caps\n",
    "                for cap in container[1]:\n",
    "                    temp = cap._xy\n",
    "                    temp[:, 0] = temp[:, 0] + offsets['cap']\n",
    "                    cap._path = pth.Path(temp)\n",
    "\n",
    "        plt.setp(g.containers, alpha=err_alpha)\n",
    "    \n",
    "    ax.set_title(title, fontsize=title_fontsize)\n",
    "    \n",
    "    ax.set_xlabel(xlabel if xaxis_visible and xlabel_visible else '', fontsize=label_fontsize)\n",
    "    if boxplots:\n",
    "        ax.set_xticklabels(['1', '2', '3', '4', '5'])\n",
    "    else:\n",
    "        ax.set_xlim(*xlim)\n",
    "        ax.set_xticks(np.arange(1, 6, 1))\n",
    "        \n",
    "    if not xaxis_visible:\n",
    "        ax.xaxis.set_ticklabels([])\n",
    "    \n",
    "    \n",
    "    ax.set_ylabel(ylabel if yaxis_visible and ylabel_visible else '', fontsize=label_fontsize)\n",
    "    ax.set_yticks(np.arange(ylim[0], ylim[1]+ystep, ystep))\n",
    "    ax.set_ylim(*ylim)\n",
    "    if not yaxis_visible:\n",
    "        ax.yaxis.set_ticklabels([])\n",
    "    \n",
    "    ax.legend(\n",
    "        bbox_to_anchor=bbox_to_anchor,\n",
    "        loc=loc,\n",
    "        ncol=ncol,\n",
    "        fontsize=legend_fontsize,\n",
    "    ).set_visible(legend_visible)\n",
    "    \n",
    "    if no_ax:\n",
    "        fig.tight_layout()\n",
    "        return fig\n",
    "\n",
    "def display_resid(\n",
    "    iter_df, anova_lm, \n",
    "    treat_name=\"treat\", iter_name=\"iter\", ppalette=resid_palette\n",
    "):\n",
    "    factor_groups = iter_df.groupby([treat_name, iter_name])\n",
    "    resid = anova_lm.resid\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    for group_num, (values, group) in enumerate(factor_groups):\n",
    "        i, j = values\n",
    "        x = [group_num] * len(group)\n",
    "        plt.scatter(\n",
    "            x,\n",
    "            resid[group.index],\n",
    "            marker=symbols[j],\n",
    "            color=ppalette[i],\n",
    "            s=144,\n",
    "            edgecolors=\"black\",\n",
    "        )\n",
    "    plt.xlabel(\"Group\")\n",
    "    plt.ylabel(\"Residuals\")\n",
    "\n",
    "    color_legend = ['Baseline', 'LitL', 'LitL Chat']\n",
    "    marker_legend = [1, 5]\n",
    "    colors = [mpatches.Patch(color=resid_palette[treat]) for treat in color_legend]\n",
    "    markers = [plt.plot([], [], symbols[r], markerfacecolor='w',\n",
    "                        markeredgecolor='k')[0] for r in marker_legend]\n",
    "    plt.legend(\n",
    "        colors + markers,\n",
    "        color_legend + [f'Round {r}' for r in marker_legend],\n",
    "        loc='best'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Combined In-Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "indomain_l_offset = 0 if _model == 'roberta-large' else -1\n",
    "indomain_c_offset = 0\n",
    "\n",
    "error_offsets = [\n",
    "        {\n",
    "            'line':-(err_line_offset+indomain_l_offset),\n",
    "            'cap':-(err_cap_offset+indomain_c_offset),\n",
    "        },\n",
    "        {\n",
    "            'line':0,\n",
    "            'cap':0,\n",
    "        },\n",
    "        {\n",
    "            'line':+(err_line_offset+indomain_l_offset),\n",
    "            'cap':+(err_cap_offset+indomain_c_offset),\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf278ad43fb74ca0b4796ac7628e8b67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figsize=(7, 5)\n",
    "fig, ax = plt.subplots(2, 1, figsize=figsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### In-domain MNLI Only Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mnli_collected = []\n",
    "n_trials = 10\n",
    "\n",
    "for trial in range(1, n_trials+1):\n",
    "    with open(os.path.join(plot_dir, 'mnli_restarts', 'best', f'{trial}', 'mnli-only-training_accs.p'), 'rb') as f:\n",
    "        temp_mnli_accs = pickle.load(f)\n",
    "\n",
    "    for treat in ['baseline', 'LotS', 'LitL']:\n",
    "        temp_df = temp_mnli_accs[treat]\n",
    "        temp_df['iter'] = temp_df['round'].apply(lambda x: int(x[-1]))\n",
    "\n",
    "        for iteration in temp_df['iter'].unique():\n",
    "            temp_acc = temp_df.loc[temp_df['iter'] <= iteration, :]\n",
    "            mnli_collected.append(\n",
    "                {\n",
    "                    'treat': treat,\n",
    "                    'iter': iteration,\n",
    "                    'model': 'mnli-only',\n",
    "                    'mod': 'full',\n",
    "                    'combined': 'combined',\n",
    "                    'trial': trial,\n",
    "                    'acc': temp_acc['correct'].sum()/temp_acc.shape[0]\n",
    "                }\n",
    "            )\n",
    "\n",
    "            temp_acc = temp_df.loc[temp_df['iter'] == iteration, :]\n",
    "            mnli_collected.append(\n",
    "                {\n",
    "                    'treat': treat,\n",
    "                    'iter': iteration,\n",
    "                    'model': 'mnli-only',\n",
    "                    'mod': 'full',\n",
    "                    'combined': 'separate',\n",
    "                    'trial': trial,\n",
    "                    'acc': temp_acc['correct'].sum()/temp_acc.shape[0]\n",
    "                }\n",
    "            )\n",
    "\n",
    "mnli_df = pd.DataFrame(mnli_collected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline 1 acc mean: 0.841 acc std: 0.012\n",
      "baseline 2 acc mean: 0.854 acc std: 0.006\n",
      "baseline 3 acc mean: 0.860 acc std: 0.007\n",
      "baseline 4 acc mean: 0.862 acc std: 0.008\n",
      "baseline 5 acc mean: 0.866 acc std: 0.005\n",
      "LotS 1 acc mean: 0.817 acc std: 0.011\n",
      "LotS 2 acc mean: 0.812 acc std: 0.010\n",
      "LotS 3 acc mean: 0.821 acc std: 0.008\n",
      "LotS 4 acc mean: 0.827 acc std: 0.007\n",
      "LotS 5 acc mean: 0.823 acc std: 0.006\n",
      "LitL 1 acc mean: 0.860 acc std: 0.011\n",
      "LitL 2 acc mean: 0.845 acc std: 0.009\n",
      "LitL 3 acc mean: 0.838 acc std: 0.009\n",
      "LitL 4 acc mean: 0.839 acc std: 0.010\n",
      "LitL 5 acc mean: 0.836 acc std: 0.009\n"
     ]
    }
   ],
   "source": [
    "mnli_df = mnli_df.loc[mnli_df['combined'] == 'combined', :]\n",
    "\n",
    "for treat in mnli_df['treat'].unique():\n",
    "    for iteration in mnli_df['iter'].unique():\n",
    "        temp_df = mnli_df.loc[mnli_df['treat'] == treat, :]\n",
    "        temp_df = temp_df.loc[temp_df['iter'] == iteration, :]\n",
    "        \n",
    "        print(treat, iteration, f\"acc mean: {temp_df['acc'].mean():.3f}\", f\"acc std: {temp_df['acc'].std():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_df = copy.deepcopy(mnli_df)\n",
    "plot_df['model'] = model2plot[_model]\n",
    "plot_df['treat'] = plot_df['treat'].apply(lambda x: treat2plot[x])\n",
    "plot_df.rename(columns=cols2plot, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "397b18f606914c508d795148f503d1c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnlifigsize=(5, 2)\n",
    "figmnli, axmnli = plt.subplots(figsize=mnlifigsize)\n",
    "\n",
    "ylims={\n",
    "    'roberta-large': [0.8, 0.9],\n",
    "    'roberta-large-mnli': [0.8, 0.9],\n",
    "}\n",
    "title=f'MNLI-only Trained'\n",
    "xlabel='Round'\n",
    "ylabel='Accuracy'\n",
    "tabletitle='Median'\n",
    "tableon=False\n",
    "\n",
    "mnli_l_offset = 1.5\n",
    "mnlierror_offsets = [\n",
    "        {\n",
    "            'line':-(err_line_offset+mnli_l_offset),\n",
    "            'cap':-(err_cap_offset+0),\n",
    "        },\n",
    "        {\n",
    "            'line':0,\n",
    "            'cap':0,\n",
    "        },\n",
    "        {\n",
    "            'line':+(err_line_offset+mnli_l_offset),\n",
    "            'cap':+(err_cap_offset+0),\n",
    "        }\n",
    "    ]\n",
    "\n",
    "bbox_to_anchor = (1.25, 1)\n",
    "\n",
    "err_line_plots(\n",
    "    plot_df,\n",
    "    err_style=err_style,\n",
    "    ylim=ylims[_model],\n",
    "    title=title,\n",
    "    xlabel=xlabel,\n",
    "    ylabel=ylabel,\n",
    "    tabletitle=tabletitle,\n",
    "    palette=palette,\n",
    "    tableon=tableon,\n",
    "    style_key=style_key,\n",
    "    style_order=style_order,\n",
    "    figsize=mnlifigsize,\n",
    "    hue=hue,\n",
    "    hue_order=hue_order,\n",
    "    xlim=xlim,\n",
    "    err_kws=err_kws,\n",
    "    ax=axmnli,\n",
    "    ystep=0.02,\n",
    "    legend_visible=True,\n",
    "    xlabel_visible=True,\n",
    "    error_offsets=mnlierror_offsets,\n",
    "    boxplots=boxplots,\n",
    "    bbox_to_anchor=bbox_to_anchor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc ~ C(iter) + C(treat) + C(iter):C(treat)\n",
      "roberta-large-mnli\n",
      "                    sum_sq    df          F        PR(>F)\n",
      "C(iter)           0.000083   1.0   0.926261  3.401266e-01\n",
      "C(treat)          0.013026   2.0  72.745731  4.749797e-16\n",
      "C(iter):C(treat)  0.006278   2.0  35.060489  1.741050e-10\n",
      "Residual          0.004835  54.0        NaN           NaN\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bfca76b57bd45a5a13348912e88b4c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2-way ANOVA\n",
    "\n",
    "iterations = [1, 5]\n",
    "\n",
    "iter_df = mnli_df.loc[mnli_df['iter'].isin(iterations), :]\n",
    "anova_table, anova_lm = two_way_anova(iter_df)\n",
    "\n",
    "print(model)\n",
    "print(anova_table)\n",
    "print('-'*90)\n",
    "\n",
    "display_resid(iter_df, anova_lm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### In Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_df = pd.read_csv(os.path.join(plot_dir, 'collected.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "input_type = 'full'\n",
    "\n",
    "plot_df = plot_df.loc[plot_df['combined'] == combined, :]\n",
    "plot_df = plot_df.loc[plot_df['mod'] == input_type, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0  Unnamed: 0.1         run hyperparams sample_type  \\\n",
      "0              0           0.0  baseline_1  0.00003_32  cross_eval   \n",
      "1              1           1.0  baseline_1  0.00003_32  cross_eval   \n",
      "2              2           2.0  baseline_1  0.00003_32  cross_eval   \n",
      "3              3           3.0  baseline_1  0.00003_32  cross_eval   \n",
      "4              4           4.0  baseline_1  0.00003_32  cross_eval   \n",
      "...          ...           ...         ...         ...         ...   \n",
      "1270        1270           NaN         NaN         NaN         NaN   \n",
      "1271        1271           NaN         NaN         NaN         NaN   \n",
      "1272        1272           NaN         NaN         NaN         NaN   \n",
      "1273        1273           NaN         NaN         NaN         NaN   \n",
      "1274        1274           NaN         NaN         NaN         NaN   \n",
      "\n",
      "      sample_partition       acc     treat  iter   mod  combined  \\\n",
      "0                  0.1  0.778905  baseline     1  full  combined   \n",
      "1                  0.2  0.825558  baseline     1  full  combined   \n",
      "2                  0.3  0.361055  baseline     1  full  combined   \n",
      "3                  0.4  0.821501  baseline     1  full  combined   \n",
      "4                  0.5  0.813387  baseline     1  full  combined   \n",
      "...                ...       ...       ...   ...   ...       ...   \n",
      "1270               NaN  0.896480      LitL     1  full  combined   \n",
      "1271               NaN  0.879132      LitL     2  full  combined   \n",
      "1272               NaN  0.875772      LitL     3  full  combined   \n",
      "1273               NaN  0.867662      LitL     4  full  combined   \n",
      "1274               NaN  0.868454      LitL     5  full  combined   \n",
      "\n",
      "                   model  \n",
      "0          roberta-large  \n",
      "1          roberta-large  \n",
      "2          roberta-large  \n",
      "3          roberta-large  \n",
      "4          roberta-large  \n",
      "...                  ...  \n",
      "1270  roberta-large-mnli  \n",
      "1271  roberta-large-mnli  \n",
      "1272  roberta-large-mnli  \n",
      "1273  roberta-large-mnli  \n",
      "1274  roberta-large-mnli  \n",
      "\n",
      "[330 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "print(plot_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc ~ C(iter) + C(treat) + C(iter):C(treat)\n",
      "roberta-large\n",
      "                    sum_sq    df         F    PR(>F)\n",
      "C(iter)           0.009287   1.0  0.631617  0.429895\n",
      "C(treat)          0.038552   2.0  1.310954  0.277172\n",
      "C(iter):C(treat)  0.117642   2.0  4.000362  0.023395\n",
      "Residual          0.882239  60.0       NaN       NaN\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "923d9df03aa041f0912cec8aa5cac15b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc ~ C(iter) + C(treat) + C(iter):C(treat)\n",
      "roberta-large-mnli\n",
      "                    sum_sq    df           F        PR(>F)\n",
      "C(iter)           0.000037   1.0    0.988386  3.241299e-01\n",
      "C(treat)          0.018550   2.0  245.427812  1.298386e-29\n",
      "C(iter):C(treat)  0.007667   2.0  101.446507  5.638533e-20\n",
      "Residual          0.002267  60.0         NaN           NaN\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b6ce0d82bed498683ef4a2dfad12372",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2-way ANOVA\n",
    "\n",
    "iterations = [1, 5]\n",
    "models = ['roberta-large', 'roberta-large-mnli']\n",
    "\n",
    "for model in models:\n",
    "    iter_df = plot_df.loc[plot_df['iter'].isin(iterations), :]\n",
    "    iter_df = iter_df.loc[iter_df['model'] == model, :]\n",
    "    anova_table, anova_lm = two_way_anova(iter_df)\n",
    "    \n",
    "    print(model)\n",
    "    print(anova_table)\n",
    "    print('-'*90)\n",
    "\n",
    "    display_resid(iter_df, anova_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_df['model'] = plot_df['model'].apply(lambda x: model2plot[x])\n",
    "plot_df['treat'] = plot_df['treat'].apply(lambda x: treat2plot[x])\n",
    "plot_df = plot_df.rename(columns=cols2plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ylims={\n",
    "    'roberta-large': [0.6, 0.9],\n",
    "    'roberta-large-mnli': [0.8, 1.0],\n",
    "}\n",
    "\n",
    "if boxplots:\n",
    "    ylims={\n",
    "        'roberta-large': [0.3, 0.9],\n",
    "        'roberta-large-mnli': [0.3, 0.9],\n",
    "    }\n",
    "title=f'In-domain Validation'\n",
    "xlabel='Round'\n",
    "ylabel='Accuracy'\n",
    "tabletitle='Median'\n",
    "tableon=False\n",
    "\n",
    "err_line_plots(\n",
    "    plot_df,\n",
    "    err_style=err_style,\n",
    "    ylim=ylims[_model],\n",
    "    title=title,\n",
    "    xlabel=xlabel,\n",
    "    ylabel=ylabel,\n",
    "    tabletitle=tabletitle,\n",
    "    palette=palette,\n",
    "    tableon=tableon,\n",
    "    style_key=style_key,\n",
    "    style_order=style_order,\n",
    "    figsize=figsize,\n",
    "    hue=hue,\n",
    "    hue_order=hue_order,\n",
    "    xlim=xlim,\n",
    "    err_kws=err_kws,\n",
    "    ax=ax[0],\n",
    "    ystep=0.05 if _model == 'roberta-large-mnli' else 0.1,\n",
    "    legend_visible=True,\n",
    "    xlabel_visible=False,\n",
    "    error_offsets=error_offsets,\n",
    "    boxplots=boxplots,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Hyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_df = pd.read_csv(os.path.join(plot_dir, 'collected.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "input_type = 'hyp'\n",
    "\n",
    "plot_df = plot_df.loc[plot_df['combined'] == combined, :]\n",
    "plot_df = plot_df.loc[plot_df['mod'] == input_type, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc ~ C(iter) + C(treat) + C(iter):C(treat)\n",
      "roberta-large\n",
      "                    sum_sq    df          F    PR(>F)\n",
      "C(iter)           0.023914   1.0  10.343665  0.002095\n",
      "C(treat)          0.075884   2.0  16.410916  0.000002\n",
      "C(iter):C(treat)  0.014604   2.0   3.158400  0.049640\n",
      "Residual          0.138719  60.0        NaN       NaN\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b6f64895bb0426aa224792ce6a6ed16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc ~ C(iter) + C(treat) + C(iter):C(treat)\n",
      "roberta-large-mnli\n",
      "                    sum_sq    df           F        PR(>F)\n",
      "C(iter)           0.000900   1.0    7.935376  6.553143e-03\n",
      "C(treat)          0.039800   2.0  175.528151  8.462490e-26\n",
      "C(iter):C(treat)  0.004758   2.0   20.986339  1.230333e-07\n",
      "Residual          0.006802  60.0         NaN           NaN\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88bf7421458e4961b74072f463a52e82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2-way ANOVA\n",
    "\n",
    "iterations = [1, 5]\n",
    "models = ['roberta-large', 'roberta-large-mnli']\n",
    "\n",
    "for model in models:\n",
    "    iter_df = plot_df.loc[plot_df['iter'].isin(iterations), :]\n",
    "    iter_df = iter_df.loc[iter_df['model'] == model, :]\n",
    "    anova_table, anova_lm = two_way_anova(iter_df)\n",
    "    \n",
    "    print(model)\n",
    "    print(anova_table)\n",
    "    print('-'*90)\n",
    "\n",
    "    display_resid(iter_df, anova_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_df['model'] = plot_df['model'].apply(lambda x: model2plot[x])\n",
    "plot_df['treat'] = plot_df['treat'].apply(lambda x: treat2plot[x])\n",
    "plot_df = plot_df.rename(columns=cols2plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ylims={\n",
    "    'roberta-large': [0.3,0.7],\n",
    "    'roberta-large-mnli': [0.3, 0.7],\n",
    "}\n",
    "title=f'Hypothesis-only Input'\n",
    "xlabel='Round'\n",
    "ylabel='Accuracy'\n",
    "tabletitle='Median'\n",
    "tableon=False\n",
    "\n",
    "bbox_to_anchor = (0.5, -1.2)\n",
    "\n",
    "err_line_plots(\n",
    "    plot_df,\n",
    "    err_style=err_style,\n",
    "    ylim=ylims[_model],\n",
    "    title=title,\n",
    "    xlabel=xlabel,\n",
    "    ylabel=ylabel,\n",
    "    tabletitle=tabletitle,\n",
    "    palette=palette,\n",
    "    tableon=tableon,\n",
    "    style_key=style_key,\n",
    "    style_order=style_order,\n",
    "    figsize=figsize,\n",
    "    err_kws=err_kws,\n",
    "    hue=hue,\n",
    "    hue_order=hue_order,\n",
    "    xlim=xlim,\n",
    "    xlabel_visible=True,\n",
    "    legend_visible=False,\n",
    "    ax=ax[1],\n",
    "    error_offsets=error_offsets,\n",
    "    boxplots=boxplots,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get majority class baseline per protocol and round\n",
    "append = '_combined' if combined == 'combined' else ''\n",
    "nli_data = os.path.join(repo, 'NLI_data')\n",
    "protocol2dir = {\n",
    "    'base':'1_Baseline_protocol',\n",
    "    'LotS':'2_Ling_on_side_protocol',\n",
    "    'LitL':'3_Ling_in_loop_protocol',\n",
    "}\n",
    "rounds = range(1,6)\n",
    "\n",
    "majority_class = []\n",
    "\n",
    "file2plot = {'base':'Baseline', 'LotS':'LitL', 'LitL':'LitL Chat'}\n",
    "\n",
    "for protocol, protocol_dir in protocol2dir.items():\n",
    "    for r in rounds:\n",
    "        val_name = f'val_round{r}_{protocol}{append}.jsonl'\n",
    "        val_path = os.path.join(nli_data, protocol_dir, val_name)\n",
    "        \n",
    "        labels2count = collections.defaultdict(int)\n",
    "        with open(val_path, 'r') as f:\n",
    "            for example in f.readlines():\n",
    "                label = json.loads(example)['label']\n",
    "                labels2count[label] += 1\n",
    "        majority_class.append({\n",
    "            'Protocol':file2plot[protocol],\n",
    "            'Iteration':r,\n",
    "            'Majority Class':max(labels2count.values())/sum(labels2count.values())\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "majority_class_df = pd.DataFrame(majority_class)\n",
    "avg_majority = majority_class_df.groupby(by='Iteration').mean()\n",
    "\n",
    "xvals = avg_majority.index.values\n",
    "if boxplots:\n",
    "    xvals = xvals - 1\n",
    "    \n",
    "ax[1].plot(\n",
    "    xvals, avg_majority['Majority Class'],\n",
    "    c='k', ls='--'\n",
    ")\n",
    "ax[1].legend().set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig.tight_layout()\n",
    "if save_figs:\n",
    "    fig.savefig(os.path.join(plot_out, f'{combined}_indomain{saveappend}.{figtype}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "figmnli.tight_layout()\n",
    "if save_figs:\n",
    "    figmnli.savefig(os.path.join(os.path.dirname(plot_out), f'{combined}_mnlionly{saveappend}.{figtype}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Diagnostic Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "iterations = [1, 5]\n",
    "models = style_order\n",
    "iter_l_offset = -0.75 if _model == 'roberta-large' else -1.75\n",
    "iter_c_offset = +0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "error_offsets = [\n",
    "        {\n",
    "            'line':-(err_line_offset+iter_l_offset),\n",
    "            'cap':-(err_cap_offset+iter_c_offset),\n",
    "        },\n",
    "        {\n",
    "            'line':0,\n",
    "            'cap':0,\n",
    "        },\n",
    "        {\n",
    "            'line':+(err_line_offset+iter_l_offset),\n",
    "            'cap':+(err_cap_offset+iter_c_offset),\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figsize = (15, 5)\n",
    "fig, ax = plt.subplots(2, 4, figsize=figsize) # top is GLUE bottom is HANS\n",
    "ax[1, 3].set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### GLUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_df = pd.read_csv(os.path.join(plot_dir, 'glue.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mnli_collected = []\n",
    "temp_df = mnli_accs['glue']\n",
    "temp_df['case_text'] = temp_df['case'].apply(lambda x: x[0] if len(x) > 0 else '')\n",
    "\n",
    "for case in temp_df['case_text'].unique():\n",
    "    temp_acc = temp_df.loc[temp_df['case_text'] == case, :]\n",
    "    mnli_collected.append({\n",
    "        'acc': temp_acc['correct'].sum()/temp_acc.shape[0],\n",
    "        'subcase': 'combined',\n",
    "        'label': 'combined',\n",
    "        'model': 'mnli-only',\n",
    "        'case': case,\n",
    "    })\n",
    "    \n",
    "    for label in temp_acc['label'].unique():\n",
    "        temptemp_acc = temp_acc.loc[temp_acc['label'] == label, :]\n",
    "        mnli_collected.append({\n",
    "            'acc': temptemp_acc['correct'].sum()/temptemp_acc.shape[0],\n",
    "            'subcase': 'combined',\n",
    "            'label': label,\n",
    "            'model': 'mnli-only',\n",
    "            'case': case,\n",
    "        })\n",
    "mnli_df = pd.DataFrame(mnli_collected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "label = 'combined'\n",
    "\n",
    "plot_df = plot_df.loc[plot_df['comb'] == combined, :]\n",
    "plot_df = plot_df.loc[plot_df['label'] == label, :]\n",
    "plot_df = plot_df.loc[plot_df['subcase'] == 'combined', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mnli_df = mnli_df.loc[mnli_df['label'] == label, :]\n",
    "mnli_df = mnli_df.loc[mnli_df['subcase'] == 'combined', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_df['model'] = plot_df['model'].apply(lambda x: model2plot[x])\n",
    "plot_df['treat'] = plot_df['treat'].apply(lambda x: treat2plot[x])\n",
    "plot_df = plot_df.rename(columns=cols2plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc ~ C(iter) + C(Protocol) + C(iter):C(Protocol)\n",
      "RoBERTa$_{\\rm{Lg}}$ Knowledge\n",
      "                       sum_sq    df         F    PR(>F)\n",
      "C(iter)              0.024076   1.0  7.718398  0.007286\n",
      "C(Protocol)          0.002086   2.0  0.334297  0.717166\n",
      "C(iter):C(Protocol)  0.036334   2.0  5.824089  0.004880\n",
      "Residual             0.187158  60.0       NaN       NaN\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc ~ C(iter) + C(Protocol) + C(iter):C(Protocol)\n",
      "RoBERTa$_{\\rm{Lg}}$ Lexical Semantics\n",
      "                       sum_sq    df         F    PR(>F)\n",
      "C(iter)              0.014581   1.0  2.795388  0.099744\n",
      "C(Protocol)          0.000287   2.0  0.027477  0.972909\n",
      "C(iter):C(Protocol)  0.040338   2.0  3.866817  0.026327\n",
      "Residual             0.312956  60.0       NaN       NaN\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc ~ C(iter) + C(Protocol) + C(iter):C(Protocol)\n",
      "RoBERTa$_{\\rm{Lg}}$ Logic\n",
      "                       sum_sq    df         F    PR(>F)\n",
      "C(iter)              0.025046   1.0  8.978601  0.003968\n",
      "C(Protocol)          0.003934   2.0  0.705050  0.498131\n",
      "C(iter):C(Protocol)  0.016440   2.0  2.946749  0.060153\n",
      "Residual             0.167374  60.0       NaN       NaN\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc ~ C(iter) + C(Protocol) + C(iter):C(Protocol)\n",
      "RoBERTa$_{\\rm{Lg}}$ Predicate-Argument Structure\n",
      "                       sum_sq    df         F    PR(>F)\n",
      "C(iter)              0.034306   1.0  8.866052  0.004186\n",
      "C(Protocol)          0.010377   2.0  1.340938  0.269326\n",
      "C(iter):C(Protocol)  0.031917   2.0  4.124316  0.020976\n",
      "Residual             0.232160  60.0       NaN       NaN\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ylims={\n",
    "    'roberta-large':{\n",
    "        'Knowledge':[0.4,0.7],\n",
    "        'Lexical Semantics':[0.5, 0.8],\n",
    "        'Logic': [0.4,0.7],\n",
    "        'Predicate-Argument Structure':[0.5,0.8],\n",
    "    },\n",
    "    'roberta-large-mnli':{\n",
    "        'Knowledge':[0.4,0.7],\n",
    "        'Lexical Semantics':[0.5, 0.8],\n",
    "        'Logic': [0.4,0.7],\n",
    "        'Predicate-Argument Structure':[0.5,0.8],\n",
    "    },\n",
    "}\n",
    "title=f\"\"\n",
    "xlabel='Round'\n",
    "ylabel='GLUE'\n",
    "tabletitle='median'\n",
    "tableon=False\n",
    "\n",
    "glue_keys = pd.read_csv('glue_case_keys.csv')\n",
    "\n",
    "i = 0\n",
    "for case in glue_keys['case'].unique():\n",
    "    if case == 'combined':\n",
    "        continue\n",
    "    \n",
    "    temp_df = plot_df.loc[plot_df['case'] == case, :]\n",
    "    err_line_plots(\n",
    "        temp_df,\n",
    "        err_style=err_style,\n",
    "        ylim=ylims[_model][case],\n",
    "        title=f\"{case}\",\n",
    "        xlabel=xlabel if i == len(glue_keys['case'].unique()) - 2 else None,\n",
    "        ylabel=ylabel,\n",
    "        tabletitle=tabletitle,\n",
    "        palette=palette,\n",
    "        tableon=tableon,\n",
    "        style_key=style_key,\n",
    "        style_order=style_order,\n",
    "        ax=ax[0, i],\n",
    "        ylabel_visible = i == 0,\n",
    "        legend_visible = False,\n",
    "        err_kws=err_kws,\n",
    "        hue=hue,\n",
    "        hue_order=hue_order,\n",
    "        xlim=xlim,\n",
    "        error_offsets=error_offsets,\n",
    "        boxplots=boxplots,\n",
    "    )\n",
    "    \n",
    "    if _model == 'roberta-large-mnli':\n",
    "        temp_mnli = mnli_df.loc[mnli_df['case'] == case, :]\n",
    "        ax[0, i].hlines(temp_mnli['acc'], xlim[0], xlim[1], label='mnli-only', zorder=10)\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "    for model in models:\n",
    "        iter_df = temp_df.loc[temp_df['iter'].isin(iterations), :]\n",
    "        iter_df = iter_df.loc[iter_df['Model'] == model, :]\n",
    "        anova_table, anova_lm = two_way_anova(iter_df, f2='Protocol')\n",
    "\n",
    "        print(model, case)\n",
    "        print(anova_table)\n",
    "        print('-'*90)\n",
    "        \n",
    "        display_resid(iter_df, anova_lm, treat_name=\"Protocol\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### HANS non-entailment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Willi\\Anaconda3\\envs\\DL\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (6,10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "plot_df = pd.read_csv(os.path.join(plot_dir, 'hans.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mnli_collected = []\n",
    "temp_df = mnli_accs['hans']\n",
    "temp_df['case_text'] = temp_df['case']\n",
    "\n",
    "for case in temp_df['case_text'].unique():\n",
    "    temp_acc = temp_df.loc[temp_df['case_text'] == case, :]\n",
    "    mnli_collected.append({\n",
    "        'acc': temp_acc['correct'].sum()/temp_acc.shape[0],\n",
    "        'subcase': 'combined',\n",
    "        'label': 'combined',\n",
    "        'model': 'mnli-only',\n",
    "        'case': case,\n",
    "    })\n",
    "    \n",
    "    for label in temp_acc['label'].unique():\n",
    "        temptemp_acc = temp_acc.loc[temp_acc['label'] == label, :]\n",
    "        mnli_collected.append({\n",
    "            'acc': temptemp_acc['correct'].sum()/temptemp_acc.shape[0],\n",
    "            'subcase': 'combined',\n",
    "            'label': 'non-entailment' if label == 'contradiction' else label,\n",
    "            'model': 'mnli-only',\n",
    "            'case': case,\n",
    "        })\n",
    "mnli_df = pd.DataFrame(mnli_collected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "label = 'non-entailment'\n",
    "\n",
    "plot_df = plot_df.loc[plot_df['comb'] == combined, :]\n",
    "plot_df = plot_df.loc[plot_df['label'] == label, :]\n",
    "plot_df = plot_df.loc[plot_df['subcase'] == 'combined', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mnli_df = mnli_df.loc[mnli_df['label'] == label, :]\n",
    "mnli_df = mnli_df.loc[mnli_df['subcase'] == 'combined', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_df['model'] = plot_df['model'].apply(lambda x: model2plot[x])\n",
    "plot_df['treat'] = plot_df['treat'].apply(lambda x: treat2plot[x])\n",
    "plot_df = plot_df.rename(columns=cols2plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc ~ C(iter) + C(Protocol) + C(iter):C(Protocol)\n",
      "RoBERTa$_{\\rm{Lg}}$ constituent\n",
      "                       sum_sq    df         F    PR(>F)\n",
      "C(iter)              0.000099   1.0  0.002805  0.957941\n",
      "C(Protocol)          0.126587   2.0  1.785701  0.176475\n",
      "C(iter):C(Protocol)  0.003211   2.0  0.045291  0.955752\n",
      "Residual             2.126678  60.0       NaN       NaN\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc ~ C(iter) + C(Protocol) + C(iter):C(Protocol)\n",
      "RoBERTa$_{\\rm{Lg}}$ lexical_overlap\n",
      "                       sum_sq    df          F    PR(>F)\n",
      "C(iter)              1.169550   1.0  20.783012  0.000026\n",
      "C(Protocol)          0.462926   2.0   4.113124  0.021183\n",
      "C(iter):C(Protocol)  0.161721   2.0   1.436899  0.245723\n",
      "Residual             3.376459  60.0        NaN       NaN\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc ~ C(iter) + C(Protocol) + C(iter):C(Protocol)\n",
      "RoBERTa$_{\\rm{Lg}}$ subsequence\n",
      "                       sum_sq    df         F    PR(>F)\n",
      "C(iter)              0.121056   1.0  3.532371  0.065040\n",
      "C(Protocol)          0.068691   2.0  1.002187  0.373136\n",
      "C(iter):C(Protocol)  0.051253   2.0  0.747773  0.477780\n",
      "Residual             2.056221  60.0       NaN       NaN\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ylims={\n",
    "    'roberta-large':{\n",
    "        'constituent': [0.0, 0.6],\n",
    "        'lexical_overlap': [0.0, 0.8],\n",
    "        'subsequence': [0.0, 0.6],\n",
    "    },\n",
    "    'roberta-large-mnli':{\n",
    "        'constituent': [0.1, 0.5],\n",
    "        'lexical_overlap': [0.6, 1.0],\n",
    "        'subsequence': [0.1, 0.5],\n",
    "    },\n",
    "}\n",
    "title=f\"\"\n",
    "xlabel='Round'\n",
    "ylabel='HANS Non-Entailment'\n",
    "tabletitle='median'\n",
    "tableon=False\n",
    "\n",
    "bbox_to_anchor = (1.15, 1)\n",
    "\n",
    "hans_keys = pd.read_csv('hans_case_keys.csv')\n",
    "\n",
    "case2title = {\n",
    "    'constituent': 'Constituent',\n",
    "    'lexical_overlap': 'Lexical Overlap',\n",
    "    'subsequence': 'Subsequence',\n",
    "}\n",
    "\n",
    "i = 0\n",
    "for case in hans_keys['case'].unique():\n",
    "    if case == 'combined':\n",
    "        continue\n",
    "    \n",
    "    temp_df = plot_df.loc[plot_df['case'] == case, :]\n",
    "    err_line_plots(\n",
    "        temp_df,\n",
    "        err_style=err_style,\n",
    "        ylim=ylims[_model][case],\n",
    "        title=f\"{case2title[case]}\",\n",
    "        xlabel=xlabel,\n",
    "        ylabel=ylabel,\n",
    "        tabletitle=tabletitle,\n",
    "        palette=palette,\n",
    "        tableon=tableon,\n",
    "        style_key=style_key,\n",
    "        style_order=style_order,\n",
    "        ax=ax[1, i],\n",
    "        ylabel_visible = i == 0,\n",
    "        legend_visible = i == len(hans_keys['case'].unique()) - 2,\n",
    "        bbox_to_anchor=bbox_to_anchor,\n",
    "        err_kws=err_kws,\n",
    "        hue=hue,\n",
    "        hue_order=hue_order,\n",
    "        xlim=xlim,\n",
    "        ystep=0.2,\n",
    "        error_offsets=error_offsets,\n",
    "        boxplots=boxplots,\n",
    "    )\n",
    "    \n",
    "    if _model == 'roberta-large-mnli':\n",
    "        temp_mnli = mnli_df.loc[mnli_df['case'] == case, :]\n",
    "        ax[1, i].hlines(temp_mnli['acc'], xlim[0], xlim[1], label='mnli-only', zorder=10)\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "    for model in models:\n",
    "        iter_df = temp_df.loc[temp_df['iter'].isin(iterations), :]\n",
    "        iter_df = iter_df.loc[iter_df['Model'] == model, :]\n",
    "        anova_table, anova_lm = two_way_anova(iter_df, f2='Protocol')\n",
    "\n",
    "        print(model, case)\n",
    "        print(anova_table)\n",
    "        print('-'*90)\n",
    "        \n",
    "        display_resid(iter_df, anova_lm, treat_name=\"Protocol\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig.tight_layout()\n",
    "fig.subplots_adjust(wspace=2.5e-1)\n",
    "if save_figs:\n",
    "    fig.savefig(os.path.join(plot_out, f'{combined}_itereval{saveappend}.{figtype}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Combined Held-out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figsize=(7, 5)\n",
    "fig, ax = plt.subplots(2, 1, figsize=figsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "iterations = [1, 5]\n",
    "models = style_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mnli_df = mnli_accs['mnlieval']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc ~ C(iter) + C(Protocol) + C(iter):C(Protocol)\n",
      "RoBERTa$_{\\rm{Lg}}$ mnli\n",
      "                       sum_sq    df         F    PR(>F)\n",
      "C(iter)              0.025885   1.0  1.654439  0.203297\n",
      "C(Protocol)          0.006798   2.0  0.217236  0.805370\n",
      "C(iter):C(Protocol)  0.106554   2.0  3.405210  0.039739\n",
      "Residual             0.938743  60.0       NaN       NaN\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc ~ C(iter) + C(Protocol) + C(iter):C(Protocol)\n",
      "RoBERTa$_{\\rm{Lg}}$ anli\n",
      "                       sum_sq    df          F        PR(>F)\n",
      "C(iter)              0.003980   1.0  30.828636  6.773534e-07\n",
      "C(Protocol)          0.000229   2.0   0.886923  4.172518e-01\n",
      "C(iter):C(Protocol)  0.001047   2.0   4.055168  2.229188e-02\n",
      "Residual             0.007746  60.0        NaN           NaN\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ylims={\n",
    "    'roberta-large':{\n",
    "        'mnli':[0.6,0.9],\n",
    "        'anli':[0.2,0.5]\n",
    "    },\n",
    "    'roberta-large-mnli':{\n",
    "        'mnli':[0.8, 1.0],\n",
    "        'anli':[0.3, 0.4]\n",
    "    },\n",
    "}\n",
    "title=f\"\"\n",
    "xlabel='Round'\n",
    "ylabel='Accuracy'\n",
    "tabletitle='median'\n",
    "tableon=False\n",
    "\n",
    "bbox_to_anchor = (1.01, 1)\n",
    "\n",
    "case2title = {\n",
    "    'mnli': 'MNLI-mismatched',\n",
    "    'anli': 'ANLI',\n",
    "}\n",
    "\n",
    "i = 0\n",
    "for case, title_name in case2title.items():\n",
    "    plot_df = pd.read_csv(os.path.join(plot_dir, f'{case}.csv'))\n",
    "    plot_df = plot_df.loc[plot_df['comb'] == combined, :]\n",
    "    plot_df = plot_df.loc[plot_df['breakdown'] == 'combined', :]\n",
    "    mnli_df = mnli_accs[f'{case}eval']\n",
    "    \n",
    "    plot_df['model'] = plot_df['model'].apply(lambda x: model2plot[x])\n",
    "    plot_df['treat'] = plot_df['treat'].apply(lambda x: treat2plot[x])\n",
    "    plot_df = plot_df.rename(columns=cols2plot)\n",
    "    \n",
    "    err_line_plots(\n",
    "        plot_df,\n",
    "        err_style=err_style,\n",
    "        ylim=ylims[_model][case],\n",
    "        title=f\"{title_name}\",\n",
    "        xlabel=xlabel,\n",
    "        ylabel=ylabel,\n",
    "        tabletitle=tabletitle,\n",
    "        palette=palette,\n",
    "        tableon=tableon,\n",
    "        style_key=style_key,\n",
    "        style_order=style_order,\n",
    "        ax=ax[i],\n",
    "        xlabel_visible = i == 1,\n",
    "        legend_visible = i == 0,\n",
    "        bbox_to_anchor=bbox_to_anchor,\n",
    "        err_kws=err_kws,\n",
    "        hue=hue,\n",
    "        hue_order=hue_order,\n",
    "        xlim=xlim,\n",
    "        ystep=0.05 if _model == 'roberta-large-mnli' else 0.1,\n",
    "        boxplots=boxplots,\n",
    "    )\n",
    "    \n",
    "    if _model == 'roberta-large-mnli':\n",
    "        ax[i].hlines(mnli_df['correct'].sum()/mnli_df.shape[0], xlim[0], xlim[1], label='mnli-only', zorder=10)\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "    for model in models:\n",
    "        iter_df = plot_df.loc[plot_df['iter'].isin(iterations), :]\n",
    "        iter_df = iter_df.loc[iter_df['Model'] == model, :]\n",
    "        anova_table, anova_lm = two_way_anova(iter_df, f2='Protocol')\n",
    "\n",
    "        print(model, case)\n",
    "        print(anova_table)\n",
    "        print('-'*90)\n",
    "        \n",
    "        display_resid(iter_df, anova_lm, treat_name=\"Protocol\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig.tight_layout()\n",
    "if save_figs:\n",
    "    fig.savefig(os.path.join(plot_out, f'{combined}_val{saveappend}.{figtype}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## ANLI Breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "anli_l_offset = -0\n",
    "anli_c_offset = +0.075"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "error_offsets = [\n",
    "    {\n",
    "        'line':-(err_line_offset+anli_l_offset),\n",
    "        'cap':-(err_cap_offset+anli_c_offset),\n",
    "    },\n",
    "    {\n",
    "        'line':0,\n",
    "        'cap':0,\n",
    "    },\n",
    "    {\n",
    "        'line':+(err_line_offset+anli_l_offset),\n",
    "        'cap':+(err_cap_offset+anli_c_offset),\n",
    "    },\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "anli_plot_out = os.path.join(repo, 'eval_summary', 'plots')\n",
    "anli_style_order=[\n",
    "    r'RoBERTa$_{\\rm{Lg}}$', \n",
    "    r'RoBERTa$_{\\rm{Lg+MNLI}}$'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_df = pd.read_csv(os.path.join(plot_dir, 'anli.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "breakdowns = [\n",
    "        'combined',\n",
    "        'Basic',\n",
    "#         'EventCoref',\n",
    "        'Imperfection',\n",
    "        'Numerical',\n",
    "        'Reasoning',\n",
    "        'Reference',\n",
    "        'Tricky',\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mnli_df = mnli_accs['anlieval']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "repo_up = os.path.dirname(repo)\n",
    "anli_annot_fname = os.path.join(repo_up, 'anli_annot_v0.2_combined_A1A2')\n",
    "anli_annot = joblib.load(anli_annot_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_anli_breakdown_acc(pred_df, anli_annot, breakdown):\n",
    "    temp1 = anli_annot[['uid', breakdown]]\n",
    "    temp2 = pred_df[['uid', 'correct']]  \n",
    "    temp = temp1.merge(temp2, on='uid')\n",
    "    temp = temp.loc[temp[breakdown].ne('none'), :]\n",
    "    return temp['correct'].sum()/temp.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_df = plot_df.loc[plot_df['comb'] == combined, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_df['model'] = plot_df['model'].apply(lambda x: model2plot[x])\n",
    "plot_df['treat'] = plot_df['treat'].apply(lambda x: treat2plot[x])\n",
    "plot_df = plot_df.rename(columns=cols2plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "0 1\n",
      "0 2\n",
      "0 3\n",
      "0 4\n",
      "0 5\n",
      "1 0\n",
      "1 1\n",
      "1 2\n",
      "1 3\n",
      "1 4\n",
      "1 5\n",
      "C:\\Users\\Willi\\Documents\\NYU\\2020_Fall\\semantics_seminar\\lip\\ling_in_loop\\eval_summary\\plots\n"
     ]
    }
   ],
   "source": [
    "if _model == 'roberta-large':\n",
    "    ylim=[0.25,0.4]\n",
    "    title=f\"\"\n",
    "    xlabel='Round'\n",
    "    ylabel='Accuracy'\n",
    "    tabletitle='median'\n",
    "    tableon=False\n",
    "\n",
    "    bbox_to_anchor = (1.01, 1)\n",
    "    figsize=(15, 6)\n",
    "\n",
    "    fig, ax = plt.subplots(2, len(breakdowns) - 1, figsize=figsize)\n",
    "\n",
    "    i = 0\n",
    "    for anli_model in anli_style_order:\n",
    "        temp_df = plot_df.loc[plot_df['Model'] == anli_model, :]\n",
    "        for case in breakdowns:\n",
    "            if case == 'combined':\n",
    "                continue\n",
    "            \n",
    "            print(i // (len(breakdowns) - 1), i % (len(breakdowns) - 1))\n",
    "            temp_ax = ax[i // (len(breakdowns) - 1), i%(len(breakdowns) - 1)]\n",
    "            temptemp_df = temp_df.loc[temp_df['breakdown'] == case, :]\n",
    "            err_line_plots(\n",
    "                temptemp_df,\n",
    "                err_style=err_style,\n",
    "                ylim=ylim,\n",
    "                title=f\"{case}\",\n",
    "                xlabel=xlabel,\n",
    "                ylabel=anli_model,\n",
    "                tabletitle=tabletitle,\n",
    "                palette=palette,\n",
    "                tableon=tableon,\n",
    "                style_key=style_key,\n",
    "                style_order=[anli_model],\n",
    "                ax=temp_ax,\n",
    "                yaxis_visible = i % (len(breakdowns) - 1) == 0,\n",
    "                legend_visible = i == len(breakdowns) - 2,\n",
    "                xlabel_visible = i // (len(breakdowns) - 1) == 1,\n",
    "                bbox_to_anchor=bbox_to_anchor,\n",
    "                err_kws=err_kws,\n",
    "                hue=hue,\n",
    "                hue_order=hue_order,\n",
    "                xlim=xlim,\n",
    "                error_offsets=error_offsets,\n",
    "                ystep=0.05,\n",
    "                boxplots=boxplots,\n",
    "            )\n",
    "\n",
    "            temp_ax.hlines(get_anli_breakdown_acc(mnli_df, anli_annot, case), xlim[0], xlim[1], label='mnli-only', zorder=10)    \n",
    "\n",
    "            i += 1\n",
    "\n",
    "    fig.tight_layout()\n",
    "    if save_figs:\n",
    "        print(os.path.dirname(plot_out))\n",
    "        fig.savefig(os.path.join(os.path.dirname(plot_out), f'{combined}_anli_breakdown{saveappend}.{figtype}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## HANS Entailment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "iterations = [1, 5]\n",
    "models = style_order\n",
    "iter_l_offset = -0.75 if _model == 'roberta-large' else -1.75\n",
    "iter_c_offset = +0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "error_offsets = [\n",
    "        {\n",
    "            'line':-(err_line_offset+iter_l_offset),\n",
    "            'cap':-(err_cap_offset+iter_c_offset),\n",
    "        },\n",
    "        {\n",
    "            'line':0,\n",
    "            'cap':0,\n",
    "        },\n",
    "        {\n",
    "            'line':+(err_line_offset+iter_l_offset),\n",
    "            'cap':+(err_cap_offset+iter_c_offset),\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "title_fontsize=16\n",
    "label_fontsize=14\n",
    "legend_fontsize=12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figsize = (15, 5)\n",
    "fig, ax = plt.subplots(2, 3, figsize=figsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### RoBERTa HANS Entailment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "combined = 'combined'\n",
    "_model = 'roberta-large'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "repo = os.path.dirname(os.path.dirname(os.path.abspath('__file__')))\n",
    "plot_dir = os.path.join(repo, 'eval_summary', 'plot_data')\n",
    "plot_out = os.path.join(repo, 'eval_summary', 'plots', _model)\n",
    "os.makedirs(plot_out, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "acc_name = 'Performance'\n",
    "diff_name = 'Over Baseline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "save_figs = True\n",
    "figtype='pdf'\n",
    "\n",
    "err_style='bars' # band or bars\n",
    "err_kws={'elinewidth': 2, 'capsize': 3}\n",
    "\n",
    "err_line_offset = 4 if _model == 'roberta-large' else 5\n",
    "err_cap_offset = 0.05\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cols2plot = {'treat':'Protocol', 'model':'Model'}\n",
    "treat2plot = {'baseline':'Baseline', 'LotS':'LitL', 'LitL':'LitL Chat'}\n",
    "model2plot = {'roberta-large': r'RoBERTa$_{\\rm{Lg}}$', 'roberta-large-mnli': r'RoBERTa$_{\\rm{Lg+MNLI}}$'}\n",
    "\n",
    "hue='Protocol'\n",
    "hue_order=['Baseline', 'LitL', 'LitL Chat']\n",
    "style_key='Model'\n",
    "style_order=[\n",
    "    model2plot[_model]\n",
    "]\n",
    "\n",
    "palette={\n",
    "        'baseline':'tab:blue',\n",
    "        'LitL':'tab:orange',\n",
    "        'LitL Chat':'tab:green',\n",
    "    }\n",
    "\n",
    "xlim = [0.8, 5.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(plot_dir, 'mnli-only-training_accs.p'), 'rb') as f:\n",
    "    mnli_accs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "iterations = [1, 5]\n",
    "models = style_order\n",
    "iter_l_offset = -0.75 if _model == 'roberta-large' else -1.75\n",
    "iter_c_offset = +0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "error_offsets = [\n",
    "        {\n",
    "            'line':-(err_line_offset+iter_l_offset),\n",
    "            'cap':-(err_cap_offset+iter_c_offset),\n",
    "        },\n",
    "        {\n",
    "            'line':0,\n",
    "            'cap':0,\n",
    "        },\n",
    "        {\n",
    "            'line':+(err_line_offset+iter_l_offset),\n",
    "            'cap':+(err_cap_offset+iter_c_offset),\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Willi\\Anaconda3\\envs\\DL\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (6,10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "plot_df = pd.read_csv(os.path.join(plot_dir, 'hans.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mnli_collected = []\n",
    "temp_df = mnli_accs['hans']\n",
    "temp_df['case_text'] = temp_df['case']\n",
    "\n",
    "for case in temp_df['case_text'].unique():\n",
    "    temp_acc = temp_df.loc[temp_df['case_text'] == case, :]\n",
    "    mnli_collected.append({\n",
    "        'acc': temp_acc['correct'].sum()/temp_acc.shape[0],\n",
    "        'subcase': 'combined',\n",
    "        'label': 'combined',\n",
    "        'model': 'mnli-only',\n",
    "        'case': case,\n",
    "    })\n",
    "    \n",
    "    for label in temp_acc['label'].unique():\n",
    "        temptemp_acc = temp_acc.loc[temp_acc['label'] == label, :]\n",
    "        mnli_collected.append({\n",
    "            'acc': temptemp_acc['correct'].sum()/temptemp_acc.shape[0],\n",
    "            'subcase': 'combined',\n",
    "            'label': 'non-entailment' if label == 'contradiction' else label,\n",
    "            'model': 'mnli-only',\n",
    "            'case': case,\n",
    "        })\n",
    "mnli_df = pd.DataFrame(mnli_collected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "label = 'entailment'\n",
    "\n",
    "plot_dff = plot_df.loc[plot_df['comb'] == combined, :]\n",
    "plot_dff = plot_dff.loc[plot_dff['label'] == label, :]\n",
    "plot_dff = plot_dff.loc[plot_dff['subcase'] == 'combined', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mnli_df = mnli_df.loc[mnli_df['label'] == label, :]\n",
    "mnli_df = mnli_df.loc[mnli_df['subcase'] == 'combined', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_dff['model'] = plot_dff['model'].apply(lambda x: model2plot[x])\n",
    "plot_dff['treat'] = plot_dff['treat'].apply(lambda x: treat2plot[x])\n",
    "plot_dff = plot_dff.rename(columns=cols2plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc ~ C(iter) + C(Protocol) + C(iter):C(Protocol)\n",
      "RoBERTa$_{\\rm{Lg}}$ constituent\n",
      "                       sum_sq    df         F    PR(>F)\n",
      "C(iter)              0.063998   1.0  2.175201  0.145479\n",
      "C(Protocol)          0.020829   2.0  0.353979  0.703346\n",
      "C(iter):C(Protocol)  0.020775   2.0  0.353062  0.703983\n",
      "Residual             1.765290  60.0       NaN       NaN\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Willi\\Anaconda3\\envs\\DL\\lib\\site-packages\\ipykernel_launcher.py:133: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc ~ C(iter) + C(Protocol) + C(iter):C(Protocol)\n",
      "RoBERTa$_{\\rm{Lg}}$ lexical_overlap\n",
      "                       sum_sq    df         F    PR(>F)\n",
      "C(iter)              0.052475   1.0  1.745497  0.191460\n",
      "C(Protocol)          0.020630   2.0  0.343109  0.710944\n",
      "C(iter):C(Protocol)  0.026087   2.0  0.433871  0.650013\n",
      "Residual             1.803769  60.0       NaN       NaN\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Willi\\Anaconda3\\envs\\DL\\lib\\site-packages\\ipykernel_launcher.py:133: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc ~ C(iter) + C(Protocol) + C(iter):C(Protocol)\n",
      "RoBERTa$_{\\rm{Lg}}$ subsequence\n",
      "                       sum_sq    df         F    PR(>F)\n",
      "C(iter)              0.044387   1.0  1.471280  0.229898\n",
      "C(Protocol)          0.033026   2.0  0.547337  0.581349\n",
      "C(iter):C(Protocol)  0.016709   2.0  0.276925  0.759075\n",
      "Residual             1.810158  60.0       NaN       NaN\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Willi\\Anaconda3\\envs\\DL\\lib\\site-packages\\ipykernel_launcher.py:133: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ylims={\n",
    "    'roberta-large':{\n",
    "        'constituent': [0.6, 1.05],\n",
    "        'lexical_overlap': [0.6, 1.05],\n",
    "        'subsequence': [0.6, 1.05],\n",
    "    },\n",
    "    'roberta-large-mnli':{\n",
    "        'constituent': [0.6, 1.05],\n",
    "        'lexical_overlap': [0.6, 1.05],\n",
    "        'subsequence': [0.6, 1.05],\n",
    "    },\n",
    "}\n",
    "title=f\"\"\n",
    "xlabel='Round'\n",
    "ylabel= r'RoBERTa$_{\\rm{Lg}}$'\n",
    "tabletitle='median'\n",
    "tableon=False\n",
    "\n",
    "bbox_to_anchor = (1.055, 1)\n",
    "\n",
    "hans_keys = pd.read_csv('hans_case_keys.csv')\n",
    "\n",
    "case2title = {\n",
    "    'constituent': 'Constituent',\n",
    "    'lexical_overlap': 'Lexical Overlap',\n",
    "    'subsequence': 'Subsequence',\n",
    "}\n",
    "\n",
    "i = 0\n",
    "for case in hans_keys['case'].unique():\n",
    "    if case == 'combined':\n",
    "        continue\n",
    "    \n",
    "    temp_df = plot_dff.loc[plot_dff['case'] == case, :]\n",
    "    err_line_plots(\n",
    "        temp_df,\n",
    "        err_style=err_style,\n",
    "        ylim=ylims[_model][case],\n",
    "        title=f\"{case2title[case]}\",\n",
    "        xlabel=xlabel,\n",
    "        ylabel=ylabel,\n",
    "        tabletitle=tabletitle,\n",
    "        palette=palette,\n",
    "        tableon=tableon,\n",
    "        style_key=style_key,\n",
    "        style_order=style_order,\n",
    "        ax=ax[0, i],\n",
    "        ylabel_visible = i == 0,\n",
    "        legend_visible = False,\n",
    "        bbox_to_anchor=bbox_to_anchor,\n",
    "        err_kws=err_kws,\n",
    "        hue=hue,\n",
    "        hue_order=hue_order,\n",
    "        xlim=xlim,\n",
    "        ystep=0.2,\n",
    "        error_offsets=error_offsets,\n",
    "        boxplots=boxplots,\n",
    "    )\n",
    "    \n",
    "    if _model == 'roberta-large-mnli':\n",
    "        temp_mnli = mnli_df.loc[mnli_df['case'] == case, :]\n",
    "        ax[1, i].hlines(temp_mnli['acc'], xlim[0], xlim[1], label='mnli-only', zorder=10)\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "    for model in models:\n",
    "        iter_df = temp_df.loc[temp_df['iter'].isin(iterations), :]\n",
    "        iter_df = iter_df.loc[iter_df['Model'] == model, :]\n",
    "        anova_table, anova_lm = two_way_anova(iter_df, f2='Protocol')\n",
    "\n",
    "        print(model, case)\n",
    "        print(anova_table)\n",
    "        print('-'*90)\n",
    "        \n",
    "        display_resid(iter_df, anova_lm, treat_name=\"Protocol\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### RoBERTa MNLI HANS Entailment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "combined = 'combined'\n",
    "_model = 'roberta-large-mnli'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "repo = os.path.dirname(os.path.dirname(os.path.abspath('__file__')))\n",
    "plot_dir = os.path.join(repo, 'eval_summary', 'plot_data')\n",
    "plot_out = os.path.join(repo, 'eval_summary', 'plots', _model)\n",
    "os.makedirs(plot_out, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "acc_name = 'Performance'\n",
    "diff_name = 'Over Baseline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "save_figs = True\n",
    "figtype='pdf'\n",
    "\n",
    "err_style='bars' # band or bars\n",
    "err_kws={'elinewidth': 2, 'capsize': 3}\n",
    "\n",
    "err_line_offset = 4 if _model == 'roberta-large' else 5\n",
    "err_cap_offset = 0.05\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cols2plot = {'treat':'Protocol', 'model':'Model'}\n",
    "treat2plot = {'baseline':'Baseline', 'LotS':'LitL', 'LitL':'LitL Chat'}\n",
    "model2plot = {'roberta-large': r'RoBERTa$_{\\rm{Lg}}$', 'roberta-large-mnli': r'RoBERTa$_{\\rm{Lg+MNLI}}$'}\n",
    "\n",
    "hue='Protocol'\n",
    "hue_order=['Baseline', 'LitL', 'LitL Chat']\n",
    "style_key='Model'\n",
    "style_order=[\n",
    "    model2plot[_model]\n",
    "]\n",
    "\n",
    "palette={\n",
    "        'baseline':'tab:blue',\n",
    "        'LitL':'tab:orange',\n",
    "        'LitL Chat':'tab:green',\n",
    "    }\n",
    "\n",
    "xlim = [0.8, 5.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(plot_dir, 'mnli-only-training_accs.p'), 'rb') as f:\n",
    "    mnli_accs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "iterations = [1, 5]\n",
    "models = style_order\n",
    "iter_l_offset = -0.75 if _model == 'roberta-large' else -1.75\n",
    "iter_c_offset = +0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "error_offsets = [\n",
    "        {\n",
    "            'line':-(err_line_offset+iter_l_offset),\n",
    "            'cap':-(err_cap_offset+iter_c_offset),\n",
    "        },\n",
    "        {\n",
    "            'line':0,\n",
    "            'cap':0,\n",
    "        },\n",
    "        {\n",
    "            'line':+(err_line_offset+iter_l_offset),\n",
    "            'cap':+(err_cap_offset+iter_c_offset),\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Willi\\Anaconda3\\envs\\DL\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (6,10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "plot_df = pd.read_csv(os.path.join(plot_dir, 'hans.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mnli_collected = []\n",
    "temp_df = mnli_accs['hans']\n",
    "temp_df['case_text'] = temp_df['case']\n",
    "\n",
    "for case in temp_df['case_text'].unique():\n",
    "    temp_acc = temp_df.loc[temp_df['case_text'] == case, :]\n",
    "    mnli_collected.append({\n",
    "        'acc': temp_acc['correct'].sum()/temp_acc.shape[0],\n",
    "        'subcase': 'combined',\n",
    "        'label': 'combined',\n",
    "        'model': 'mnli-only',\n",
    "        'case': case,\n",
    "    })\n",
    "    \n",
    "    for label in temp_acc['label'].unique():\n",
    "        temptemp_acc = temp_acc.loc[temp_acc['label'] == label, :]\n",
    "        mnli_collected.append({\n",
    "            'acc': temptemp_acc['correct'].sum()/temptemp_acc.shape[0],\n",
    "            'subcase': 'combined',\n",
    "            'label': 'non-entailment' if label == 'contradiction' else label,\n",
    "            'model': 'mnli-only',\n",
    "            'case': case,\n",
    "        })\n",
    "mnli_df = pd.DataFrame(mnli_collected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "label = 'entailment'\n",
    "\n",
    "plot_dff = plot_df.loc[plot_df['comb'] == combined, :]\n",
    "plot_dff = plot_dff.loc[plot_dff['label'] == label, :]\n",
    "plot_dff = plot_dff.loc[plot_dff['subcase'] == 'combined', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mnli_df = mnli_df.loc[mnli_df['label'] == label, :]\n",
    "mnli_df = mnli_df.loc[mnli_df['subcase'] == 'combined', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_dff['model'] = plot_dff['model'].apply(lambda x: model2plot[x])\n",
    "plot_dff['treat'] = plot_dff['treat'].apply(lambda x: treat2plot[x])\n",
    "plot_dff = plot_dff.rename(columns=cols2plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc ~ C(iter) + C(Protocol) + C(iter):C(Protocol)\n",
      "RoBERTa$_{\\rm{Lg+MNLI}}$ constituent\n",
      "                           sum_sq    df          F        PR(>F)\n",
      "C(iter)              7.333333e-08   1.0   0.007216  9.325869e-01\n",
      "C(Protocol)          3.824085e-04   2.0  18.814153  4.542187e-07\n",
      "C(iter):C(Protocol)  1.688885e-04   2.0   8.309161  6.524667e-04\n",
      "Residual             6.097673e-04  60.0        NaN           NaN\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Willi\\Anaconda3\\envs\\DL\\lib\\site-packages\\ipykernel_launcher.py:133: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc ~ C(iter) + C(Protocol) + C(iter):C(Protocol)\n",
      "RoBERTa$_{\\rm{Lg+MNLI}}$ lexical_overlap\n",
      "                       sum_sq    df         F    PR(>F)\n",
      "C(iter)              0.000053   1.0  2.268828  0.137247\n",
      "C(Protocol)          0.000109   2.0  2.342036  0.104862\n",
      "C(iter):C(Protocol)  0.000007   2.0  0.142687  0.867319\n",
      "Residual             0.001395  60.0       NaN       NaN\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Willi\\Anaconda3\\envs\\DL\\lib\\site-packages\\ipykernel_launcher.py:133: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc ~ C(iter) + C(Protocol) + C(iter):C(Protocol)\n",
      "RoBERTa$_{\\rm{Lg+MNLI}}$ subsequence\n",
      "                       sum_sq    df         F    PR(>F)\n",
      "C(iter)              0.000005   1.0  0.770350  0.383610\n",
      "C(Protocol)          0.000023   2.0  1.941397  0.152412\n",
      "C(iter):C(Protocol)  0.000006   2.0  0.463798  0.631126\n",
      "Residual             0.000357  60.0       NaN       NaN\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Willi\\Anaconda3\\envs\\DL\\lib\\site-packages\\ipykernel_launcher.py:133: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ylims={\n",
    "    'roberta-large':{\n",
    "        'constituent': [0.6, 1.05],\n",
    "        'lexical_overlap': [0.6, 1.05],\n",
    "        'subsequence': [0.6, 1.05],\n",
    "    },\n",
    "    'roberta-large-mnli':{\n",
    "        'constituent': [0.6, 1.05],\n",
    "        'lexical_overlap': [0.6, 1.05],\n",
    "        'subsequence': [0.6, 1.05],\n",
    "    },\n",
    "}\n",
    "title=f\"\"\n",
    "xlabel='Round'\n",
    "ylabel=r'RoBERTa$_{\\rm{Lg+MNLI}}$'\n",
    "tabletitle='median'\n",
    "tableon=False\n",
    "\n",
    "bbox_to_anchor = (-.75, -1)\n",
    "\n",
    "hans_keys = pd.read_csv('hans_case_keys.csv')\n",
    "\n",
    "case2title = {\n",
    "    'constituent': 'Constituent',\n",
    "    'lexical_overlap': 'Lexical Overlap',\n",
    "    'subsequence': 'Subsequence',\n",
    "}\n",
    "\n",
    "i = 0\n",
    "for case in hans_keys['case'].unique():\n",
    "    if case == 'combined':\n",
    "        continue\n",
    "    \n",
    "    temp_df = plot_dff.loc[plot_dff['case'] == case, :]\n",
    "    err_line_plots(\n",
    "        temp_df,\n",
    "        err_style=err_style,\n",
    "        ylim=ylims[_model][case],\n",
    "        title=f\"{case2title[case]}\",\n",
    "        xlabel=xlabel,\n",
    "        ylabel=ylabel,\n",
    "        tabletitle=tabletitle,\n",
    "        palette=palette,\n",
    "        tableon=tableon,\n",
    "        style_key=style_key,\n",
    "        style_order=style_order,\n",
    "        ax=ax[1, i],\n",
    "        ylabel_visible = i == 0,\n",
    "        legend_visible = i == len(hans_keys['case'].unique())-2,\n",
    "        loc='lower center',\n",
    "        ncol=len(hans_keys['case'].unique()),\n",
    "        bbox_to_anchor=bbox_to_anchor,\n",
    "        err_kws=err_kws,\n",
    "        hue=hue,\n",
    "        hue_order=hue_order,\n",
    "        xlim=xlim,\n",
    "        ystep=0.2,\n",
    "        error_offsets=error_offsets,\n",
    "        boxplots=boxplots,\n",
    "    )\n",
    "    \n",
    "    if _model == 'roberta-large-mnli':\n",
    "        temp_mnli = mnli_df.loc[mnli_df['case'] == case, :]\n",
    "        ax[1, i].hlines(temp_mnli['acc'], xlim[0], xlim[1], label='mnli-only', zorder=10)\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "    for model in models:\n",
    "        iter_df = temp_df.loc[temp_df['iter'].isin(iterations), :]\n",
    "        iter_df = iter_df.loc[iter_df['Model'] == model, :]\n",
    "        anova_table, anova_lm = two_way_anova(iter_df, f2='Protocol')\n",
    "\n",
    "        print(model, case)\n",
    "        print(anova_table)\n",
    "        print('-'*90)\n",
    "        \n",
    "        display_resid(iter_df, anova_lm, treat_name=\"Protocol\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_out = os.path.join(repo, 'eval_summary', 'plots', 'HANS_entailment')\n",
    "os.makedirs(plot_out, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig.tight_layout()\n",
    "fig.subplots_adjust(wspace=2e-1)\n",
    "if save_figs:\n",
    "    fig.savefig(os.path.join(plot_out, f'{combined}_HANS_entailment{saveappend}.pdf'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
