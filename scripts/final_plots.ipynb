{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import joblib\n",
    "import pickle\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.set_theme(style='whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_val_summary(modifier, iteration, eval_dir, ):\n",
    "    fname = os.path.join(eval_dir, f'r{iteration}', 'tables', f'configs.{modifier}.csv')\n",
    "    summary_table = pd.read_csv(fname, index_col = 0)\n",
    "    summary_table = summary_table[[str(n) for n in range(1, iteration+1)]]\n",
    "    \n",
    "    return summary_table\n",
    "\n",
    "\n",
    "def get_itereval_summary(sub_keys, iteration, eval_dir, combined, ):\n",
    "    rep = {\n",
    "        '/': '-',\n",
    "        ';': '--',\n",
    "    }\n",
    "    \n",
    "    fname_key = '.'.join(sub_keys.values())\n",
    "    for old_char, new_char in rep.items():\n",
    "        fname_key = fname_key.replace(old_char, new_char)\n",
    "    fname = os.path.join(eval_dir, f'r{iteration}', 'tables', combined, f'iterevals.{fname_key}.csv')\n",
    "    summary_table = pd.read_csv(fname, index_col = 0)\n",
    "    summary_table = summary_table[[str(n) for n in range(1, iteration+1)]]\n",
    "    \n",
    "    return summary_table\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_mnli_tables(mnli_summary, subsetting='genre'):\n",
    "    with open(mnli_summary, 'r') as f:\n",
    "        summary = pd.DataFrame([json.loads(line) for line in f])\n",
    "    \n",
    "    mnli_tables = {}\n",
    "    for comb in summary['comb'].unique():\n",
    "        comb_sum = summary.loc[summary['comb'] == comb, :]\n",
    "\n",
    "        for subset in summary[subsetting].unique():\n",
    "            subset_sum = comb_sum.loc[comb_sum[subsetting] == subset, :]\n",
    "\n",
    "            plot_tab = []\n",
    "            for treat in subset_sum['treat'].unique():\n",
    "                treat_sum = subset_sum.loc[subset_sum['treat'] == treat, :]\n",
    "                s = treat_sum[['iter','acc']].set_index('iter').rename({'acc': treat}, axis=1).transpose()            \n",
    "                plot_tab.append(s)\n",
    "            \n",
    "            mnli_tables[(model, comb, subset)] = pd.concat(plot_tab)\n",
    "    \n",
    "    return summary, mnli_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def split_run_name(run_name, split_by='_'):\n",
    "    name_list = run_name.split(split_by)\n",
    "    if len(name_list) == 2:\n",
    "        input_type = 'full'\n",
    "        comb = 'combined'\n",
    "    elif len(name_list) == 3:\n",
    "        if name_list[-1] == 'hyp':\n",
    "            input_type = name_list[-1]\n",
    "            comb = 'combined'\n",
    "        else:\n",
    "            input_type = 'full'\n",
    "            comb = name_list[-1]\n",
    "    else:\n",
    "        input_type = name_list[-1]\n",
    "        comb = name_list[-2]\n",
    "\n",
    "    return (name_list[0], name_list[1], input_type, comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def load_sampled_results(sampled_base):\n",
    "    collected = pd.read_csv(os.path.join(sampled_base, 'collected.csv'))\n",
    "    itereval = pd.read_csv(os.path.join(sampled_base, 'itereval.csv'))\n",
    "    mnli = pd.read_csv(os.path.join(sampled_base, 'mnli.csv'))\n",
    "    anli = pd.read_csv(os.path.join(sampled_base, 'anli.csv'))\n",
    "    \n",
    "    \n",
    "    # fill in keys\n",
    "    collected['treat'] = collected['run'].apply(lambda x: split_run_name(x)[0])\n",
    "    collected['iter'] = collected['run'].apply(lambda x: int(split_run_name(x)[1]))\n",
    "    collected['mod'] = collected['run'].apply(lambda x: split_run_name(x)[2])\n",
    "    collected['combined'] = collected['run'].apply(lambda x: split_run_name(x)[3])\n",
    "    \n",
    "    mnli['breakdown'] = mnli['genre'].fillna('combined')\n",
    "    anli['breakdown'] = anli['tag'].fillna('combined')\n",
    "    \n",
    "    return collected, itereval, mnli, anli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def load_all_sampled(sampled_base, upto=5):\n",
    "    loaded_keys = {'collected': 0, 'itereval':1 ,'mnli': 2, 'anli': 3}\n",
    "    results = {key: [] for key in loaded_keys.keys()}\n",
    "    \n",
    "    for r in range(1, upto + 1):\n",
    "        loaded = load_sampled_results(os.path.join(sampled_base, f'r{r}'))\n",
    "        for result_key, loaded_key in loaded_keys.items():\n",
    "            results[result_key].append(loaded[loaded_key])\n",
    "    \n",
    "    return {\n",
    "        key: pd.concat(result_list, ignore_index=True)\n",
    "        for key, result_list in results.items()\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_ttest_pvals(dist_df, verbose=True):\n",
    "    pairs = [\n",
    "        ('baseline', 'LotS'),\n",
    "        ('baseline', 'LitL'),\n",
    "        ('LotS', 'LitL'),\n",
    "    ]\n",
    "    \n",
    "    ttest_dict = {}\n",
    "    for pair in pairs:\n",
    "        a = dist_df.loc[dist_df['treat'] == pair[0], 'acc']\n",
    "        b = dist_df.loc[dist_df['treat'] == pair[1], 'acc']\n",
    "        ttest_dict[pair] = ttest_ind(a, b)\n",
    "    \n",
    "    if verbose:\n",
    "        for pair, ttest_results in ttest_dict.items():\n",
    "            print('='*45)\n",
    "            print(f\"{pair}\\nt: {ttest_results[0]:.5f} | p: {ttest_results[1]/2:.5f}\")\n",
    "    \n",
    "    return ttest_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Combine Plotting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "overwrite_plotting_data = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "repo = os.path.dirname(os.path.dirname(os.path.abspath('__file__')))\n",
    "sample_type = 'cross_eval'\n",
    "iteration = 5\n",
    "plot_data = os.path.join(repo, 'eval_summary', 'plot_data')\n",
    "os.makedirs(plot_data, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "models = ['roberta-large', 'roberta-large-mnli']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "distributions = {}\n",
    "\n",
    "for model in models:\n",
    "    eval_dir = os.path.join(repo, 'eval_summary', model)\n",
    "    distributions[model] = load_all_sampled(\n",
    "        os.path.join(eval_dir, 'sample', sample_type), upto=iteration\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Collected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "select2mod = {\n",
    "    ('combined', 'full'): 'combined',\n",
    "    ('combined', 'hyp'): 'hyp',\n",
    "    ('separate', 'full'): 'separate',\n",
    "    ('separate', 'hyp'): 'separate_hyp',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_df = []\n",
    "\n",
    "if overwrite_plotting_data:\n",
    "    for model in models:\n",
    "        collected = []\n",
    "        eval_dir = os.path.join(repo, 'eval_summary', model)\n",
    "\n",
    "        for combined, input_type in select2mod.keys():\n",
    "            mod = select2mod[(combined, input_type)]\n",
    "            temp = get_val_summary(mod, iteration, eval_dir, )\n",
    "            for idx, row in temp.iterrows():\n",
    "                df = pd.DataFrame({\n",
    "                    'acc': row,\n",
    "                    'iter': [int(x) for x in row.index.values],\n",
    "                    'treat':row.name,\n",
    "                    'mod':input_type,\n",
    "                    'combined':combined,\n",
    "                    'model':model,\n",
    "                })\n",
    "                collected.append(df)\n",
    "        collected_t = pd.concat(collected, ignore_index = True)\n",
    "        distributions[model]['collected']['model'] = model\n",
    "        all_df.append(pd.concat([distributions[model]['collected'], collected_t], ignore_index = True))\n",
    "    df = pd.concat(all_df, ignore_index = True)\n",
    "    df.to_csv(os.path.join(plot_data, 'collected.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## GLUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            case                                subcase\n",
      "0                       combined                               combined\n",
      "1                      Knowledge                               combined\n",
      "2                      Knowledge                           Common sense\n",
      "3                      Knowledge                        World knowledge\n",
      "4              Lexical Semantics                               combined\n",
      "..                           ...                                    ...\n",
      "64  Predicate-Argument Structure  Relative clauses;Anaphora/Coreference\n",
      "65  Predicate-Argument Structure         Relative clauses;Restrictivity\n",
      "66  Predicate-Argument Structure                          Restrictivity\n",
      "67  Predicate-Argument Structure     Restrictivity;Anaphora/Coreference\n",
      "68  Predicate-Argument Structure         Restrictivity;Relative clauses\n",
      "\n",
      "[69 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "glue_keys = pd.read_csv('glue_case_keys.csv')\n",
    "print(glue_keys)\n",
    "glue_labels = ['combined', 'entailment', 'neutral', 'contradiction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset = 'glue'\n",
    "\n",
    "combineds = ['combined', 'separate']\n",
    "all_df = []\n",
    "\n",
    "if overwrite_plotting_data:\n",
    "    for model in models:\n",
    "        collected = []\n",
    "        eval_dir = os.path.join(repo, 'eval_summary', model)\n",
    "\n",
    "        for idx, caserow in glue_keys.iterrows():\n",
    "            for label in glue_labels:\n",
    "                for combined in combineds:\n",
    "                    sub_keys = {\n",
    "                        'dataset': dataset,     # either hans or glue\n",
    "                        'case': caserow['case'],    # combined or specific to respective itereval set\n",
    "                        'subcase': caserow['subcase'], # combined or specific to respective itereval set\n",
    "                        'label': label,   # combined or [entailment, neutral, contradiction] for glue, [entailment, non-entailment] for hans\n",
    "                    }\n",
    "\n",
    "                    temp = get_itereval_summary(sub_keys, iteration, eval_dir, combined)\n",
    "                    for idx, row in temp.iterrows():\n",
    "                        df = pd.DataFrame({\n",
    "                            'acc': row,\n",
    "                            'iter': [int(x) for x in row.index.values],\n",
    "                            'treat':row.name,\n",
    "                            'case':sub_keys['case'],\n",
    "                            'subcase':sub_keys['subcase'],\n",
    "                            'label':sub_keys['label'],\n",
    "                            'comb':combined,\n",
    "                            'model':model,\n",
    "                        })\n",
    "                        collected.append(df)\n",
    "                collected_t = pd.concat(collected, ignore_index = True)\n",
    "\n",
    "        temp_sampled = distributions[model]['itereval']\n",
    "        temp_sampled = temp_sampled.loc[temp_sampled['dataset'] == dataset, :]\n",
    "        temp_sampled['model'] = model\n",
    "        all_df.append(pd.concat([temp_sampled, collected_t], ignore_index=True))\n",
    "    df = pd.concat(all_df, ignore_index = True)\n",
    "    df.to_csv(os.path.join(plot_data, 'glue.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## HANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               case                         subcase\n",
      "0          combined                        combined\n",
      "1       constituent                       ce_adverb\n",
      "2       constituent           ce_after_since_clause\n",
      "3       constituent                  ce_conjunction\n",
      "4       constituent         ce_embedded_under_since\n",
      "5       constituent          ce_embedded_under_verb\n",
      "6       constituent                       cn_adverb\n",
      "7       constituent              cn_after_if_clause\n",
      "8       constituent                  cn_disjunction\n",
      "9       constituent            cn_embedded_under_if\n",
      "10      constituent          cn_embedded_under_verb\n",
      "11      constituent                        combined\n",
      "12  lexical_overlap                        combined\n",
      "13  lexical_overlap  le_around_prepositional_phrase\n",
      "14  lexical_overlap       le_around_relative_clause\n",
      "15  lexical_overlap                  le_conjunction\n",
      "16  lexical_overlap                      le_passive\n",
      "17  lexical_overlap              le_relative_clause\n",
      "18  lexical_overlap                  ln_conjunction\n",
      "19  lexical_overlap                      ln_passive\n",
      "20  lexical_overlap                  ln_preposition\n",
      "21  lexical_overlap              ln_relative_clause\n",
      "22  lexical_overlap          ln_subject/object_swap\n",
      "23      subsequence                        combined\n",
      "24      subsequence                    se_adjective\n",
      "25      subsequence                  se_conjunction\n",
      "26      subsequence                    se_PP_on_obj\n",
      "27      subsequence       se_relative_clause_on_obj\n",
      "28      subsequence            se_understood_object\n",
      "29      subsequence                         sn_NP/S\n",
      "30      subsequence                         sn_NP/Z\n",
      "31      subsequence              sn_past_participle\n",
      "32      subsequence                sn_PP_on_subject\n",
      "33      subsequence   sn_relative_clause_on_subject\n"
     ]
    }
   ],
   "source": [
    "hans_keys = pd.read_csv('hans_case_keys.csv')\n",
    "print(hans_keys)\n",
    "hans_labels = ['combined', 'entailment', 'non-entailment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset = 'hans'\n",
    "\n",
    "combineds = ['combined', 'separate']\n",
    "all_df = []\n",
    "\n",
    "if overwrite_plotting_data:\n",
    "    for model in models:\n",
    "        collected = []\n",
    "        eval_dir = os.path.join(repo, 'eval_summary', model)\n",
    "\n",
    "        for idx, caserow in hans_keys.iterrows():\n",
    "            for label in hans_labels:\n",
    "                for combined in combineds:\n",
    "                    sub_keys = {\n",
    "                        'dataset': dataset,     # either glue or hans\n",
    "                        'case': caserow['case'],    # combined or specific to respective itereval set\n",
    "                        'subcase': caserow['subcase'], # combined or specific to respective itereval set\n",
    "                        'label': label,   # combined or [entailment, neutral, contradiction] for glue, [entailment, non-entailment] for hans\n",
    "                    }\n",
    "\n",
    "                    temp = get_itereval_summary(sub_keys, iteration, eval_dir, combined)\n",
    "                    for idx, row in temp.iterrows():\n",
    "                        df = pd.DataFrame({\n",
    "                            'acc': row,\n",
    "                            'iter': [int(x) for x in row.index.values],\n",
    "                            'treat':row.name,\n",
    "                            'case':sub_keys['case'],\n",
    "                            'subcase':sub_keys['subcase'],\n",
    "                            'label':sub_keys['label'],\n",
    "                            'comb':combined,\n",
    "                            'model':model,\n",
    "                        })\n",
    "                        collected.append(df)\n",
    "                collected_t = pd.concat(collected, ignore_index = True)\n",
    "\n",
    "        temp_sampled = distributions[model]['itereval']\n",
    "        temp_sampled = temp_sampled.loc[temp_sampled['dataset'] == dataset, :]\n",
    "        temp_sampled['model'] = model\n",
    "        all_df.append(pd.concat([temp_sampled, collected_t], ignore_index=True))\n",
    "    df = pd.concat(all_df, ignore_index = True)\n",
    "    df.to_csv(os.path.join(plot_data, 'hans.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## MNLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_df = []\n",
    "\n",
    "if overwrite_plotting_data:\n",
    "    for model in models:\n",
    "        eval_dir = os.path.join(repo, 'eval_summary', model)\n",
    "        mnli_summary = os.path.join(eval_dir, 'mnli_evals', 'eval_summaries.jsonl')\n",
    "\n",
    "        with open(mnli_summary, 'r') as f:\n",
    "            summary = pd.DataFrame([json.loads(line) for line in f])\n",
    "        summary['breakdown'] = summary['genre'].fillna('combined')\n",
    "        summary['iter'] = summary['iter'].apply(lambda x: int(x))\n",
    "\n",
    "        temp = pd.concat([distributions[model]['mnli'], summary], ignore_index=True)\n",
    "        temp['model'] = model\n",
    "\n",
    "        all_df.append(temp)\n",
    "    df = pd.concat(all_df, ignore_index = True)\n",
    "    df.to_csv(os.path.join(plot_data, 'mnli.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## ANLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_df = []\n",
    "\n",
    "if overwrite_plotting_data:\n",
    "    for model in models:\n",
    "        eval_dir = os.path.join(repo, 'eval_summary', model)\n",
    "        df = pd.read_csv(os.path.join(eval_dir, 'sample', sample_type, 'final', 'anli_by_annotation.csv'))\n",
    "        df['model'] = model\n",
    "\n",
    "        all_df.append(df)\n",
    "    df = pd.concat(all_df, ignore_index = True)\n",
    "    df.to_csv(os.path.join(plot_data, 'anli.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Def plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def err_line_plots(\n",
    "    plot_df,\n",
    "    ylim=[0,1],\n",
    "    title=None,\n",
    "    xlabel=None,\n",
    "    ylabel=None,\n",
    "    tabletitle=None,\n",
    "    tableon=True,\n",
    "    x='iter',\n",
    "    y='acc',\n",
    "    hue='treat',\n",
    "    err_style='bars',\n",
    "    ci=95,\n",
    "    estimator=lambda x: np.median(x),\n",
    "    markers=True,\n",
    "    hue_order=['baseline', 'LotS', 'LitL'],\n",
    "    iteration=5,\n",
    "    bbox_to_anchor=(1.01, 1),\n",
    "    palette=None,\n",
    "    style_key='combined',\n",
    "    style_order=['combined', 'separate'],\n",
    "    yaxis_visible = True,\n",
    "    xaxis_visible = True,\n",
    "    legend_visible = True,\n",
    "    ax=None,\n",
    "):\n",
    "    no_ax = not ax\n",
    "    if not ax:\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "    sns.lineplot(\n",
    "        data=plot_df, x=x, y=y,\n",
    "        hue=hue, err_style=err_style, ci=ci, markers=markers,\n",
    "        style = style_key, style_order = style_order,\n",
    "        ax=ax\n",
    "    )\n",
    "\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    ax.set_xlabel(xlabel if xaxis_visible else '')\n",
    "    ax.set_xticks(np.arange(1, 6, 1))\n",
    "    if not xaxis_visible:\n",
    "        ax.xaxis.set_ticklabels([])\n",
    "    \n",
    "    ax.set_ylabel(ylabel if yaxis_visible else '')\n",
    "    ax.set_ylim(*ylim)\n",
    "    if not yaxis_visible:\n",
    "        ax.yaxis.set_ticklabels([])\n",
    "    \n",
    "    ax.legend(bbox_to_anchor=bbox_to_anchor).set_visible(legend_visible)\n",
    "    \n",
    "    if no_ax:\n",
    "        fig.tight_layout()\n",
    "        return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = 'separate'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = os.path.dirname(os.path.dirname(os.path.abspath('__file__')))\n",
    "plot_dir = os.path.join(repo, 'eval_summary', 'plot_data')\n",
    "plot_out = os.path.join(repo, 'eval_summary', 'plots')\n",
    "os.makedirs(plot_out, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_name = 'Performance'\n",
    "diff_name = 'Over Baseline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs = True\n",
    "figtype='jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In-domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = pd.read_csv(os.path.join(plot_dir, 'collected.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_type = 'full'\n",
    "\n",
    "plot_df = plot_df.loc[plot_df['combined'] == combined, :]\n",
    "plot_df = plot_df.loc[plot_df['mod'] == input_type, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66d95bbf11e242579acfedc412f67a64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ylim=[0,1]\n",
    "title=f'In-domain Validation'\n",
    "xlabel='Iteration'\n",
    "ylabel='Accuracy'\n",
    "tabletitle='Median'\n",
    "err_style='bars'\n",
    "tableon=False\n",
    "\n",
    "style_key='model'\n",
    "style_order=['roberta-large', 'roberta-large-mnli']\n",
    "\n",
    "fig = err_line_plots(\n",
    "    plot_df,\n",
    "    err_style=err_style,\n",
    "    ylim=ylim,\n",
    "    title=title,\n",
    "    xlabel=xlabel,\n",
    "    ylabel=ylabel,\n",
    "    tabletitle=tabletitle,\n",
    "    palette={\n",
    "        'baseline':'tab:blue',\n",
    "        'LotS':'tab:orange',\n",
    "        'LitL':'tab:green',\n",
    "    },\n",
    "    tableon=tableon,\n",
    "    style_key=style_key,\n",
    "    style_order=style_order,\n",
    ")\n",
    "if save_figs:\n",
    "    fig.savefig(os.path.join(plot_out, f'{combined}_indomain_val.{figtype}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = pd.read_csv(os.path.join(plot_dir, 'collected.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_type = 'hyp'\n",
    "\n",
    "plot_df = plot_df.loc[plot_df['combined'] == combined, :]\n",
    "plot_df = plot_df.loc[plot_df['mod'] == input_type, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23b25c9efa164768abfa37ae3d5bd1e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ylim=[0,1]\n",
    "title=f'Hypothesis-only Input'\n",
    "xlabel='Iteration'\n",
    "ylabel='Accuracy'\n",
    "tabletitle='Median'\n",
    "err_style='bars'\n",
    "tableon=False\n",
    "\n",
    "style_key='model'\n",
    "style_order=['roberta-large', 'roberta-large-mnli']\n",
    "\n",
    "fig = err_line_plots(\n",
    "    plot_df,\n",
    "    err_style=err_style,\n",
    "    ylim=ylim,\n",
    "    title=title,\n",
    "    xlabel=xlabel,\n",
    "    ylabel=ylabel,\n",
    "    tabletitle=tabletitle,\n",
    "    palette={\n",
    "        'baseline':'tab:blue',\n",
    "        'LotS':'tab:orange',\n",
    "        'LitL':'tab:green',\n",
    "    },\n",
    "    tableon=tableon,\n",
    "    style_key=style_key,\n",
    "    style_order=style_order,\n",
    ")\n",
    "if save_figs:\n",
    "    fig.savefig(os.path.join(plot_out, f'{combined}_hypothesis_only.{figtype}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GLUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Willi\\Anaconda3\\envs\\DL\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (6,10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "plot_df = pd.read_csv(os.path.join(plot_dir, 'glue.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'combined'\n",
    "\n",
    "plot_df = plot_df.loc[plot_df['comb'] == combined, :]\n",
    "plot_df = plot_df.loc[plot_df['label'] == label, :]\n",
    "plot_df = plot_df.loc[plot_df['subcase'] == 'combined', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "355bf7573dc846719e610241f2bbd774",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ylim=[0,1]\n",
    "title=f\"\"\n",
    "xlabel='Iteration'\n",
    "ylabel='Accuracy'\n",
    "tabletitle='median'\n",
    "err_style='bars'\n",
    "tableon=False\n",
    "\n",
    "bbox_to_anchor = (1.05, 1)\n",
    "figsize=(15, 5)\n",
    "\n",
    "style_key='model'\n",
    "style_order=['roberta-large', 'roberta-large-mnli']\n",
    "\n",
    "glue_keys = pd.read_csv('glue_case_keys.csv')\n",
    "fig, ax = plt.subplots(1, len(glue_keys['case'].unique()) - 1, figsize=figsize)\n",
    "\n",
    "i = 0\n",
    "for case in glue_keys['case'].unique():\n",
    "    if case == 'combined':\n",
    "        continue\n",
    "    \n",
    "    temp_df = plot_df.loc[plot_df['case'] == case, :]\n",
    "    err_line_plots(\n",
    "        temp_df,\n",
    "        err_style=err_style,\n",
    "        ylim=ylim,\n",
    "        title=f\"{case}\",\n",
    "        xlabel=xlabel,\n",
    "        ylabel=ylabel,\n",
    "        tabletitle=tabletitle,\n",
    "        palette={\n",
    "            'baseline':'tab:blue',\n",
    "            'LotS':'tab:orange',\n",
    "            'LitL':'tab:green',\n",
    "        },\n",
    "        tableon=tableon,\n",
    "        style_key=style_key,\n",
    "        style_order=style_order,\n",
    "        ax=ax[i],\n",
    "        yaxis_visible = i == 0,\n",
    "        legend_visible = i == len(glue_keys['case'].unique()) - 2,\n",
    "        bbox_to_anchor=bbox_to_anchor,\n",
    "    )\n",
    "    i += 1\n",
    "\n",
    "fig.tight_layout()\n",
    "if save_figs:\n",
    "    fig.savefig(os.path.join(plot_out, f'{combined}_glue.{figtype}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HANS non-entailment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_df = pd.read_csv(os.path.join(plot_dir, 'hans.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'non-entailment'\n",
    "\n",
    "plot_df = plot_df.loc[plot_df['comb'] == combined, :]\n",
    "plot_df = plot_df.loc[plot_df['label'] == label, :]\n",
    "plot_df = plot_df.loc[plot_df['subcase'] == 'combined', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0626f5d5c10c4f1e889458ccfd4c7c79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ylim=[0,1]\n",
    "title=f\"\"\n",
    "xlabel='Iteration'\n",
    "ylabel='Accuracy'\n",
    "tabletitle='median'\n",
    "err_style='bars'\n",
    "tableon=False\n",
    "\n",
    "bbox_to_anchor = (1.9, 1)\n",
    "figsize=(10, 5)\n",
    "\n",
    "style_key='model'\n",
    "style_order=['roberta-large', 'roberta-large-mnli']\n",
    "\n",
    "hans_keys = pd.read_csv('hans_case_keys.csv')\n",
    "fig, ax = plt.subplots(1, len(hans_keys['case'].unique()) - 1, figsize=figsize)\n",
    "\n",
    "i = 0\n",
    "for case in hans_keys['case'].unique():\n",
    "    if case == 'combined':\n",
    "        continue\n",
    "    \n",
    "    temp_df = plot_df.loc[plot_df['case'] == case, :]\n",
    "    err_line_plots(\n",
    "        temp_df,\n",
    "        err_style=err_style,\n",
    "        ylim=ylim,\n",
    "        title=f\"{case}\",\n",
    "        xlabel=xlabel,\n",
    "        ylabel=ylabel,\n",
    "        tabletitle=tabletitle,\n",
    "        palette={\n",
    "            'baseline':'tab:blue',\n",
    "            'LotS':'tab:orange',\n",
    "            'LitL':'tab:green',\n",
    "        },\n",
    "        tableon=tableon,\n",
    "        style_key=style_key,\n",
    "        style_order=style_order,\n",
    "        ax=ax[i],\n",
    "        yaxis_visible = i == 0,\n",
    "        legend_visible = i == len(hans_keys['case'].unique()) - 2,\n",
    "        bbox_to_anchor=bbox_to_anchor\n",
    "    )\n",
    "    i += 1\n",
    "\n",
    "fig.tight_layout()\n",
    "if save_figs:\n",
    "    fig.savefig(os.path.join(plot_out, f'{combined}_hans.{figtype}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = pd.read_csv(os.path.join(plot_dir, 'mnli.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = plot_df.loc[plot_df['comb'] == combined, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6897b5b391fc41f98212912c1f6bd93f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ylim=[0,1]\n",
    "title=f'MNLI-mismatched'\n",
    "xlabel='Iteration'\n",
    "ylabel='Accuracy'\n",
    "tabletitle='Median'\n",
    "err_style='bars'\n",
    "tableon=False\n",
    "\n",
    "style_key='model'\n",
    "style_order=['roberta-large', 'roberta-large-mnli']\n",
    "\n",
    "fig = err_line_plots(\n",
    "    plot_df,\n",
    "    err_style=err_style,\n",
    "    ylim=ylim,\n",
    "    title=title,\n",
    "    xlabel=xlabel,\n",
    "    ylabel=ylabel,\n",
    "    tabletitle=tabletitle,\n",
    "    palette={\n",
    "        'baseline':'tab:blue',\n",
    "        'LotS':'tab:orange',\n",
    "        'LitL':'tab:green',\n",
    "    },\n",
    "    tableon=tableon,\n",
    "    style_key=style_key,\n",
    "    style_order=style_order,\n",
    ")\n",
    "\n",
    "if save_figs:\n",
    "    fig.savefig(os.path.join(plot_out, f'{combined}_mnli.{figtype}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_df = pd.read_csv(os.path.join(plot_dir, 'anli.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "breakdowns = [\n",
    "        'combined',\n",
    "        'Basic',\n",
    "        'EventCoref',\n",
    "        'Imperfection',\n",
    "        'Numerical',\n",
    "        'Reasoning',\n",
    "        'Reference',\n",
    "        'Tricky',\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = plot_df.loc[plot_df['comb'] == combined, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3f0ae00bb134d1086e33c330f95591d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Willi\\Anaconda3\\envs\\DL\\lib\\site-packages\\ipykernel_launcher.py:46: UserWarning: Tight layout not applied. tight_layout cannot make axes width small enough to accommodate all axes decorations\n"
     ]
    }
   ],
   "source": [
    "ylim=[0,1]\n",
    "title=f\"\"\n",
    "xlabel='Iteration'\n",
    "ylabel='Accuracy'\n",
    "tabletitle='median'\n",
    "err_style='bars'\n",
    "tableon=False\n",
    "\n",
    "bbox_to_anchor = (6.8, 1)\n",
    "figsize=(20, 5)\n",
    "\n",
    "style_key='model'\n",
    "style_order=['roberta-large', 'roberta-large-mnli']\n",
    "\n",
    "fig, ax = plt.subplots(1, len(breakdowns) - 1, figsize=figsize)\n",
    "\n",
    "i = 0\n",
    "for case in breakdowns:\n",
    "    if case == 'combined':\n",
    "        continue\n",
    "    \n",
    "    temp_df = plot_df.loc[plot_df['breakdown'] == case, :]\n",
    "    err_line_plots(\n",
    "        temp_df,\n",
    "        err_style=err_style,\n",
    "        ylim=ylim,\n",
    "        title=f\"{case}\",\n",
    "        xlabel=xlabel,\n",
    "        ylabel=ylabel,\n",
    "        tabletitle=tabletitle,\n",
    "        palette={\n",
    "            'baseline':'tab:blue',\n",
    "            'LotS':'tab:orange',\n",
    "            'LitL':'tab:green',\n",
    "        },\n",
    "        tableon=tableon,\n",
    "        style_key=style_key,\n",
    "        style_order=style_order,\n",
    "        ax=ax[i],\n",
    "        yaxis_visible = i == 0,\n",
    "        legend_visible = i == len(hans_keys['case'].unique()) - 2,\n",
    "        bbox_to_anchor=bbox_to_anchor\n",
    "    )\n",
    "    i += 1\n",
    "\n",
    "fig.tight_layout()\n",
    "if save_figs:\n",
    "    fig.savefig(os.path.join(plot_out, f'{combined}_anli.{figtype}'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
