{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_model = 'roberta-large' # roberta-large or roberta-large-mnli\n",
    "overwrite_plotting_data = False # Set to True if running for first time with new experiment data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import collections\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import joblib\n",
    "import pickle\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.path as pth\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import ttest_ind, f_oneway\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.set_theme(style='whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_val_summary(modifier, iteration, eval_dir, ):\n",
    "    fname = os.path.join(eval_dir, f'r{iteration}', 'tables', f'configs.{modifier}.csv')\n",
    "    summary_table = pd.read_csv(fname, index_col = 0)\n",
    "    summary_table = summary_table[[str(n) for n in range(1, iteration+1)]]\n",
    "    \n",
    "    return summary_table\n",
    "\n",
    "\n",
    "def get_itereval_summary(sub_keys, iteration, eval_dir, combined, ):\n",
    "    rep = {\n",
    "        '/': '-',\n",
    "        ';': '--',\n",
    "    }\n",
    "    \n",
    "    fname_key = '.'.join(sub_keys.values())\n",
    "    for old_char, new_char in rep.items():\n",
    "        fname_key = fname_key.replace(old_char, new_char)\n",
    "    fname = os.path.join(eval_dir, f'r{iteration}', 'tables', combined, f'iterevals.{fname_key}.csv')\n",
    "    summary_table = pd.read_csv(fname, index_col = 0)\n",
    "    summary_table = summary_table[[str(n) for n in range(1, iteration+1)]]\n",
    "    \n",
    "    return summary_table\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_mnli_tables(mnli_summary, subsetting='genre'):\n",
    "    with open(mnli_summary, 'r') as f:\n",
    "        summary = pd.DataFrame([json.loads(line) for line in f])\n",
    "    \n",
    "    mnli_tables = {}\n",
    "    for comb in summary['comb'].unique():\n",
    "        comb_sum = summary.loc[summary['comb'] == comb, :]\n",
    "\n",
    "        for subset in summary[subsetting].unique():\n",
    "            subset_sum = comb_sum.loc[comb_sum[subsetting] == subset, :]\n",
    "\n",
    "            plot_tab = []\n",
    "            for treat in subset_sum['treat'].unique():\n",
    "                treat_sum = subset_sum.loc[subset_sum['treat'] == treat, :]\n",
    "                s = treat_sum[['iter','acc']].set_index('iter').rename({'acc': treat}, axis=1).transpose()            \n",
    "                plot_tab.append(s)\n",
    "            \n",
    "            mnli_tables[(model, comb, subset)] = pd.concat(plot_tab)\n",
    "    \n",
    "    return summary, mnli_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def split_run_name(run_name, split_by='_'):\n",
    "    name_list = run_name.split(split_by)\n",
    "    if len(name_list) == 2:\n",
    "        input_type = 'full'\n",
    "        comb = 'combined'\n",
    "    elif len(name_list) == 3:\n",
    "        if name_list[-1] == 'hyp':\n",
    "            input_type = name_list[-1]\n",
    "            comb = 'combined'\n",
    "        else:\n",
    "            input_type = 'full'\n",
    "            comb = name_list[-1]\n",
    "    else:\n",
    "        input_type = name_list[-1]\n",
    "        comb = name_list[-2]\n",
    "\n",
    "    return (name_list[0], name_list[1], input_type, comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def unique_itereval(df, keys=['case', 'subcase', 'label', 'dataset', 'treat', 'iter', 'comb', 'sample_type', 'sample_partition']):\n",
    "    return df.drop_duplicates(subset=keys, ignore_index=True)\n",
    "\n",
    "def load_sampled_results(sampled_base):\n",
    "    collected = pd.read_csv(os.path.join(sampled_base, 'collected.csv'))\n",
    "    itereval = pd.read_csv(os.path.join(sampled_base, 'itereval.csv'))\n",
    "    mnli = pd.read_csv(os.path.join(sampled_base, 'mnli.csv'))\n",
    "    anli = pd.read_csv(os.path.join(sampled_base, 'anli.csv'))\n",
    "    \n",
    "    \n",
    "    # fill in keys\n",
    "    collected['treat'] = collected['run'].apply(lambda x: split_run_name(x)[0])\n",
    "    collected['iter'] = collected['run'].apply(lambda x: int(split_run_name(x)[1]))\n",
    "    collected['mod'] = collected['run'].apply(lambda x: split_run_name(x)[2])\n",
    "    collected['combined'] = collected['run'].apply(lambda x: split_run_name(x)[3])\n",
    "    \n",
    "    \n",
    "    mnli['breakdown'] = mnli['genre'].fillna('combined')\n",
    "    anli['breakdown'] = anli['tag'].fillna('combined')\n",
    "    \n",
    "    itereval = unique_itereval(itereval)\n",
    "    \n",
    "    return collected, itereval, mnli, anli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def load_all_sampled(sampled_base, upto=5):\n",
    "    loaded_keys = {'collected': 0, 'itereval':1 ,'mnli': 2, 'anli': 3}\n",
    "    results = {key: [] for key in loaded_keys.keys()}\n",
    "    \n",
    "    for r in range(1, upto + 1):\n",
    "        loaded = load_sampled_results(os.path.join(sampled_base, f'r{r}'))\n",
    "        for result_key, loaded_key in loaded_keys.items():\n",
    "            results[result_key].append(loaded[loaded_key])\n",
    "    \n",
    "    return {\n",
    "        key: pd.concat(result_list, ignore_index=True)\n",
    "        for key, result_list in results.items()\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_ttest_pvals(dist_df, verbose=True):\n",
    "    pairs = [\n",
    "        ('baseline', 'LotS'),\n",
    "        ('baseline', 'LitL'),\n",
    "        ('LotS', 'LitL'),\n",
    "    ]\n",
    "    \n",
    "    ttest_dict = {}\n",
    "    for pair in pairs:\n",
    "        a = dist_df.loc[dist_df['treat'] == pair[0], 'acc']\n",
    "        b = dist_df.loc[dist_df['treat'] == pair[1], 'acc']\n",
    "        ttest_dict[pair] = ttest_ind(a, b)\n",
    "    \n",
    "    if verbose:\n",
    "        for pair, ttest_results in ttest_dict.items():\n",
    "            print('='*45)\n",
    "            print(f\"{pair}\\nt: {ttest_results[0]:.5f} | p: {ttest_results[1]/2:.5f}\")\n",
    "    \n",
    "    return ttest_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def two_way_anova(df, f1='iter', f2='treat', acc='acc', formula=None):\n",
    "    keeps = [f1, f2, acc]\n",
    "    \n",
    "    if not formula:\n",
    "        formula = f'{acc} ~ C({f1}) + C({f2}) + C({f1}):C({f2})'\n",
    "        \n",
    "    print(formula)\n",
    "    model = ols(formula, data=df[keeps]).fit()\n",
    "    \n",
    "    return sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "def one_way_anova(df, f='iter', acc='acc', formula=None):\n",
    "    keeps = [f, acc]\n",
    "    \n",
    "    if not formula:\n",
    "        formula = f'{acc} ~ C({f})'\n",
    "        \n",
    "    print(formula)\n",
    "    model = ols(formula, data=df[keeps]).fit()\n",
    "    \n",
    "    return sm.stats.anova_lm(model, typ=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Combine Plotting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "repo = os.path.dirname(os.path.dirname(os.path.abspath('__file__')))\n",
    "sample_type = 'cross_eval'\n",
    "iteration = 5\n",
    "plot_data = os.path.join(repo, 'eval_summary', 'plot_data')\n",
    "os.makedirs(plot_data, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "models = ['roberta-large', 'roberta-large-mnli']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "distributions = {}\n",
    "\n",
    "for model in models:\n",
    "    eval_dir = os.path.join(repo, 'eval_summary', model)\n",
    "    distributions[model] = load_all_sampled(\n",
    "        os.path.join(eval_dir, 'sample', sample_type), upto=iteration\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## MNLI Only Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pred_base = os.path.join(repo, 'predictions', 'roberta-large-mnli_only')\n",
    "data_base = os.path.join(repo, 'tasks', 'data')\n",
    "best_data = os.path.join(pred_base, 'best')\n",
    "\n",
    "pred_dirs = [\n",
    "    'baseline_5',\n",
    "    'LotS_5',\n",
    "    'LitL_5',\n",
    "    'mnlieval_baseline_1',\n",
    "    'anlieval_baseline_1',\n",
    "    'eval_baseline_1',\n",
    "]\n",
    "\n",
    "data_dirs = [\n",
    "    os.path.join('baseline_5', 'val_round5_base_combined.jsonl'),\n",
    "    os.path.join('LotS_5', 'val_round5_LotS_combined.jsonl'),\n",
    "    os.path.join('LitL_5', 'val_round5_LitL_combined.jsonl'),\n",
    "    os.path.join('mnli_mismatched', 'val_mismatched_mnli.jsonl'),\n",
    "    os.path.join('anli_combined', 'val_anli.jsonl'),\n",
    "    os.path.join('iterative_eval', 'val_itercombined.jsonl'),\n",
    "]\n",
    "\n",
    "lrs = ['0.00001', '0.00002', '0.00003']\n",
    "batches = ['16', '32']\n",
    "\n",
    "n_trials = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def read_jsonl(file):\n",
    "    with open(file, 'r') as f:\n",
    "        return [json.loads(line) for line in f.readlines()]\n",
    "    \n",
    "def get_acc(\n",
    "    preds,\n",
    "    data,\n",
    "    int2pred={0:'contradiction', 1:'entailment', 2:'neutral'}\n",
    "):\n",
    "    df = pd.DataFrame(data)\n",
    "    df['preds'] = pd.Series(preds).apply(lambda x: int2pred[x])\n",
    "    df['correct'] = df['label'].eq(df['preds'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if overwrite_plotting_data:\n",
    "    preds_and_data = {}\n",
    "\n",
    "    for pred, data in zip(pred_dirs, data_dirs):\n",
    "        temp_pred = torch.load(os.path.join(pred_base, pred, 'val_preds.p'))\n",
    "        temp_data = read_jsonl(os.path.join(data_base, data))\n",
    "        preds_and_data[pred.split('_')[0]] = {'pred': temp_pred, 'data':temp_data}\n",
    "\n",
    "    accs = {\n",
    "        key: get_acc(val['pred']['mnli']['preds'], val['data']) for key, val in preds_and_data.items()\n",
    "    }\n",
    "    \n",
    "    accs['glue'] = accs['eval'].loc[accs['eval']['dataset'] == 'glue']\n",
    "    \n",
    "    hans = accs['eval'].loc[accs['eval']['dataset'] == 'hans', :]\n",
    "    tempdict = {'contradiction':'contradiction', 'neutral':'contradiction', 'entailment':'entailment'}\n",
    "    hans['preds'] = hans['preds'].apply(lambda x: tempdict[x])\n",
    "    hans['case'] = hans['case'].apply(lambda x: x[0])\n",
    "    hans['correct'] = hans['label'].eq(hans['preds'])\n",
    "    \n",
    "    accs['hans'] = hans\n",
    "    \n",
    "    with open(os.path.join(plot_data, 'mnli-only-training_accs.p'), 'wb') as f:\n",
    "        pickle.dump(accs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if overwrite_plotting_data:\n",
    "    for trial in range(1, n_trials+1):\n",
    "        preds_and_data = {}\n",
    "\n",
    "        for pred, data in zip(pred_dirs, data_dirs):\n",
    "            temp_pred = torch.load(os.path.join(best_data, pred, f'{trial}', 'val_preds.p'))\n",
    "            temp_data = read_jsonl(os.path.join(data_base, data))\n",
    "            preds_and_data[pred.split('_')[0]] = {'pred': temp_pred, 'data':temp_data}\n",
    "\n",
    "        accs = {\n",
    "            key: get_acc(val['pred']['mnli']['preds'], val['data']) for key, val in preds_and_data.items()\n",
    "        }\n",
    "\n",
    "        accs['glue'] = accs['eval'].loc[accs['eval']['dataset'] == 'glue']\n",
    "\n",
    "        hans = accs['eval'].loc[accs['eval']['dataset'] == 'hans', :]\n",
    "        tempdict = {'contradiction':'contradiction', 'neutral':'contradiction', 'entailment':'entailment'}\n",
    "        hans['preds'] = hans['preds'].apply(lambda x: tempdict[x])\n",
    "        hans['case'] = hans['case'].apply(lambda x: x[0])\n",
    "        hans['correct'] = hans['label'].eq(hans['preds'])\n",
    "\n",
    "        accs['hans'] = hans\n",
    "\n",
    "        mnli_out_dir = os.path.join(plot_data, 'mnli_restarts', 'best', f'{trial}')\n",
    "        os.makedirs(mnli_out_dir, exist_ok = True)\n",
    "        with open(os.path.join(mnli_out_dir, 'mnli-only-training_accs.p'), 'wb') as f:\n",
    "            pickle.dump(accs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Collected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "select2mod = {\n",
    "    ('combined', 'full'): 'combined',\n",
    "    ('combined', 'hyp'): 'hyp',\n",
    "    ('separate', 'full'): 'separate',\n",
    "    ('separate', 'hyp'): 'separate_hyp',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_df = []\n",
    "\n",
    "if overwrite_plotting_data:\n",
    "    for model in models:\n",
    "        collected = []\n",
    "        eval_dir = os.path.join(repo, 'eval_summary', model)\n",
    "\n",
    "        for combined, input_type in select2mod.keys():\n",
    "            mod = select2mod[(combined, input_type)]\n",
    "            temp = get_val_summary(mod, iteration, eval_dir, )\n",
    "            for idx, row in temp.iterrows():\n",
    "                df = pd.DataFrame({\n",
    "                    'acc': row,\n",
    "                    'iter': [int(x) for x in row.index.values],\n",
    "                    'treat':row.name,\n",
    "                    'mod':input_type,\n",
    "                    'combined':combined,\n",
    "                    'model':model,\n",
    "                })\n",
    "                collected.append(df)\n",
    "        collected_t = pd.concat(collected, ignore_index = True)\n",
    "        distributions[model]['collected']['model'] = model\n",
    "        all_df.append(pd.concat([distributions[model]['collected'], collected_t], ignore_index = True))\n",
    "    df = pd.concat(all_df, ignore_index = True)\n",
    "    df.to_csv(os.path.join(plot_data, 'collected.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## GLUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "glue_keys = pd.read_csv('glue_case_keys.csv')\n",
    "print(glue_keys)\n",
    "glue_labels = ['combined', 'entailment', 'neutral', 'contradiction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset = 'glue'\n",
    "\n",
    "combineds = ['combined', 'separate']\n",
    "all_df = []\n",
    "\n",
    "if overwrite_plotting_data:\n",
    "    for model in models:\n",
    "        collected = []\n",
    "        eval_dir = os.path.join(repo, 'eval_summary', model)\n",
    "\n",
    "        for idx, caserow in glue_keys.iterrows():\n",
    "            for label in glue_labels:\n",
    "                for combined in combineds:\n",
    "                    sub_keys = {\n",
    "                        'dataset': dataset,     # either hans or glue\n",
    "                        'case': caserow['case'],    # combined or specific to respective itereval set\n",
    "                        'subcase': caserow['subcase'], # combined or specific to respective itereval set\n",
    "                        'label': label,   # combined or [entailment, neutral, contradiction] for glue, [entailment, non-entailment] for hans\n",
    "                    }\n",
    "\n",
    "                    temp = get_itereval_summary(sub_keys, iteration, eval_dir, combined)\n",
    "                    for idx, row in temp.iterrows():\n",
    "                        df = pd.DataFrame({\n",
    "                            'acc': row,\n",
    "                            'iter': [int(x) for x in row.index.values],\n",
    "                            'treat':row.name,\n",
    "                            'case':sub_keys['case'],\n",
    "                            'subcase':sub_keys['subcase'],\n",
    "                            'label':sub_keys['label'],\n",
    "                            'comb':combined,\n",
    "                            'model':model,\n",
    "                        })\n",
    "                        collected.append(df)\n",
    "                collected_t = pd.concat(collected, ignore_index = True)\n",
    "\n",
    "        temp_sampled = distributions[model]['itereval']\n",
    "        temp_sampled = temp_sampled.loc[temp_sampled['dataset'] == dataset, :]\n",
    "        temp_sampled['model'] = model\n",
    "        all_df.append(pd.concat([temp_sampled, collected_t], ignore_index=True))\n",
    "    df = pd.concat(all_df, ignore_index = True)\n",
    "    df.to_csv(os.path.join(plot_data, 'glue.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## HANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "hans_keys = pd.read_csv('hans_case_keys.csv')\n",
    "print(hans_keys)\n",
    "hans_labels = ['combined', 'entailment', 'non-entailment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset = 'hans'\n",
    "\n",
    "combineds = ['combined', 'separate']\n",
    "all_df = []\n",
    "\n",
    "if overwrite_plotting_data:\n",
    "    for model in models:\n",
    "        collected = []\n",
    "        eval_dir = os.path.join(repo, 'eval_summary', model)\n",
    "\n",
    "        for idx, caserow in hans_keys.iterrows():\n",
    "            for label in hans_labels:\n",
    "                for combined in combineds:\n",
    "                    sub_keys = {\n",
    "                        'dataset': dataset,     # either glue or hans\n",
    "                        'case': caserow['case'],    # combined or specific to respective itereval set\n",
    "                        'subcase': caserow['subcase'], # combined or specific to respective itereval set\n",
    "                        'label': label,   # combined or [entailment, neutral, contradiction] for glue, [entailment, non-entailment] for hans\n",
    "                    }\n",
    "\n",
    "                    temp = get_itereval_summary(sub_keys, iteration, eval_dir, combined)\n",
    "                    for idx, row in temp.iterrows():\n",
    "                        df = pd.DataFrame({\n",
    "                            'acc': row,\n",
    "                            'iter': [int(x) for x in row.index.values],\n",
    "                            'treat':row.name,\n",
    "                            'case':sub_keys['case'],\n",
    "                            'subcase':sub_keys['subcase'],\n",
    "                            'label':sub_keys['label'],\n",
    "                            'comb':combined,\n",
    "                            'model':model,\n",
    "                        })\n",
    "                        collected.append(df)\n",
    "                collected_t = pd.concat(collected, ignore_index = True)\n",
    "\n",
    "        temp_sampled = distributions[model]['itereval']\n",
    "        temp_sampled = temp_sampled.loc[temp_sampled['dataset'] == dataset, :]\n",
    "        temp_sampled['model'] = model\n",
    "        all_df.append(pd.concat([temp_sampled, collected_t], ignore_index=True))\n",
    "    df = pd.concat(all_df, ignore_index = True)\n",
    "    df.to_csv(os.path.join(plot_data, 'hans.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## MNLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_df = []\n",
    "\n",
    "if overwrite_plotting_data:\n",
    "    for model in models:\n",
    "        eval_dir = os.path.join(repo, 'eval_summary', model)\n",
    "        mnli_summary = os.path.join(eval_dir, 'mnli_evals', 'eval_summaries.jsonl')\n",
    "\n",
    "        with open(mnli_summary, 'r') as f:\n",
    "            summary = pd.DataFrame([json.loads(line) for line in f])\n",
    "        summary['breakdown'] = summary['genre'].fillna('combined')\n",
    "        summary['iter'] = summary['iter'].apply(lambda x: int(x))\n",
    "\n",
    "        temp = pd.concat([distributions[model]['mnli'], summary], ignore_index=True)\n",
    "        temp['model'] = model\n",
    "\n",
    "        all_df.append(temp)\n",
    "    df = pd.concat(all_df, ignore_index = True)\n",
    "    df.to_csv(os.path.join(plot_data, 'mnli.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## ANLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_df = []\n",
    "\n",
    "if overwrite_plotting_data:\n",
    "    for model in models:\n",
    "        eval_dir = os.path.join(repo, 'eval_summary', model)\n",
    "        df = pd.read_csv(os.path.join(eval_dir, 'sample', sample_type, 'final', 'anli_by_annotation.csv'))\n",
    "        df['model'] = model\n",
    "\n",
    "        all_df.append(df)\n",
    "    df = pd.concat(all_df, ignore_index = True)\n",
    "    df.to_csv(os.path.join(plot_data, 'anli.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Plot Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "combined = 'combined'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "repo = os.path.dirname(os.path.dirname(os.path.abspath('__file__')))\n",
    "plot_dir = os.path.join(repo, 'eval_summary', 'plot_data')\n",
    "plot_out = os.path.join(repo, 'eval_summary', 'plots', _model)\n",
    "os.makedirs(plot_out, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "acc_name = 'Performance'\n",
    "diff_name = 'Over Baseline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "save_figs = True\n",
    "figtype='pdf'\n",
    "\n",
    "err_style='bars' # band or bars\n",
    "err_kws={'elinewidth': 2, 'capsize': 3}\n",
    "\n",
    "title_fontsize=18\n",
    "label_fontsize=16\n",
    "legend_fontsize=14\n",
    "\n",
    "err_line_offset = 4 if _model == 'roberta-large' else 5\n",
    "err_cap_offset = 0.05\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cols2plot = {'treat':'Protocol', 'model':'Model'}\n",
    "treat2plot = {'baseline':'Baseline', 'LotS':'LitL', 'LitL':'LitL Chat'}\n",
    "model2plot = {'roberta-large': r'RoBERTa$_{\\rm{Lg}}$', 'roberta-large-mnli': r'RoBERTa$_{\\rm{Lg+MNLI}}$'}\n",
    "\n",
    "hue='Protocol'\n",
    "hue_order=['Baseline', 'LitL', 'LitL Chat']\n",
    "style_key='Model'\n",
    "style_order=[\n",
    "    model2plot[_model]\n",
    "]\n",
    "\n",
    "palette={\n",
    "        'baseline':'tab:blue',\n",
    "        'LitL':'tab:orange',\n",
    "        'LitL Chat':'tab:green',\n",
    "    }\n",
    "\n",
    "xlim = [0.8, 5.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(plot_dir, 'mnli-only-training_accs.p'), 'rb') as f:\n",
    "    mnli_accs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Def plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def err_line_plots(\n",
    "    plot_df,\n",
    "    ylim=[0,1],\n",
    "    ystep=0.1,\n",
    "    xlim=[1,5],\n",
    "    title=None,\n",
    "    xlabel=None,\n",
    "    ylabel=None,\n",
    "    tabletitle=None,\n",
    "    tableon=True,\n",
    "    x='iter',\n",
    "    y='acc',\n",
    "    err_style='bars',\n",
    "    ci=95,\n",
    "    estimator='mean',\n",
    "    markers=True,\n",
    "    hue='treat',\n",
    "    hue_order=['baseline', 'LotS', 'LitL'],\n",
    "    iteration=5,\n",
    "    bbox_to_anchor=(1.01, 1),\n",
    "    palette=None,\n",
    "    style_key='combined',\n",
    "    style_order=['combined', 'separate'],\n",
    "    yaxis_visible = True,\n",
    "    xaxis_visible = True,\n",
    "    ylabel_visible = True,\n",
    "    xlabel_visible = True,\n",
    "    legend_visible = True,\n",
    "    ax=None,\n",
    "    figsize=(6.4, 4.8),\n",
    "    err_kws={'elinewidth': 1, 'capsize': 2},\n",
    "    err_alpha=0.6,\n",
    "    linewidth=2,\n",
    "    markersize=7,\n",
    "    loc='best',\n",
    "    ncol=1,\n",
    "    error_offsets = [\n",
    "        {\n",
    "            'line':-err_line_offset,\n",
    "            'cap':-err_cap_offset,\n",
    "        },\n",
    "        {\n",
    "            'line':0,\n",
    "            'cap':0,\n",
    "        },\n",
    "        {\n",
    "            'line':+err_line_offset,\n",
    "            'cap':+err_cap_offset,\n",
    "        }\n",
    "    ]\n",
    "):\n",
    "    kwargs = {}\n",
    "    no_ax = not ax\n",
    "    if not ax:\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    if len(style_order) == 1:\n",
    "        plot_df = plot_df.loc[plot_df[style_key] == style_order[0], :]\n",
    "        style_key, style_order = hue, hue_order\n",
    "    \n",
    "    g = sns.lineplot(\n",
    "        data=plot_df, x=x, y=y,\n",
    "        hue=hue, hue_order=hue_order,\n",
    "        style = style_key, style_order = style_order,\n",
    "        err_style=err_style, err_kws=err_kws,\n",
    "        ci=ci, markers=markers,\n",
    "        ax=ax, **kwargs,\n",
    "        linewidth=linewidth, markersize=markersize,\n",
    "    )\n",
    "    \n",
    "    if error_offsets:\n",
    "        assert len(g.containers) == len(error_offsets), f'{len(g.collections)}, error_offsets {len(error_offsets)}'\n",
    "        \n",
    "        for container, offsets in zip(g.containers, error_offsets):\n",
    "            # offset line\n",
    "            plt.setp(container[2][0], offsets = [offsets['line'], 0.])\n",
    "            \n",
    "            # offset caps\n",
    "            for cap in container[1]:\n",
    "                temp = cap._xy\n",
    "                temp[:, 0] = temp[:, 0] + offsets['cap']\n",
    "                cap._path = pth.Path(temp)\n",
    "        \n",
    "    plt.setp(g.containers, alpha=err_alpha)\n",
    "\n",
    "    ax.set_title(title, fontsize=title_fontsize)\n",
    "    \n",
    "    ax.set_xlabel(xlabel if xaxis_visible and xlabel_visible else '', fontsize=label_fontsize)\n",
    "    ax.set_xticks(np.arange(1, 6, 1))\n",
    "    ax.set_xlim(*xlim)\n",
    "    if not xaxis_visible:\n",
    "        ax.xaxis.set_ticklabels([])\n",
    "    \n",
    "    ax.set_ylabel(ylabel if yaxis_visible and ylabel_visible else '', fontsize=label_fontsize)\n",
    "    ax.set_yticks(np.arange(ylim[0], ylim[1]+ystep, ystep))\n",
    "    ax.set_ylim(*ylim)\n",
    "    if not yaxis_visible:\n",
    "        ax.yaxis.set_ticklabels([])\n",
    "    \n",
    "    ax.legend(\n",
    "        bbox_to_anchor=bbox_to_anchor,\n",
    "        loc=loc,\n",
    "        ncol=ncol,\n",
    "        fontsize=legend_fontsize,\n",
    "    ).set_visible(legend_visible)\n",
    "    \n",
    "    if no_ax:\n",
    "        fig.tight_layout()\n",
    "        return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Combined In-Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "indomain_l_offset = 0 if _model == 'roberta-large' else -1\n",
    "indomain_c_offset = 0\n",
    "\n",
    "error_offsets = [\n",
    "        {\n",
    "            'line':-(err_line_offset+indomain_l_offset),\n",
    "            'cap':-(err_cap_offset+indomain_c_offset),\n",
    "        },\n",
    "        {\n",
    "            'line':0,\n",
    "            'cap':0,\n",
    "        },\n",
    "        {\n",
    "            'line':+(err_line_offset+indomain_l_offset),\n",
    "            'cap':+(err_cap_offset+indomain_c_offset),\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "figsize=(7, 5)\n",
    "fig, ax = plt.subplots(2, 1, figsize=figsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### In-domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mnli_collected = []\n",
    "n_trials = 10\n",
    "\n",
    "for trial in range(1, n_trials+1):\n",
    "    with open(os.path.join(plot_dir, 'mnli_restarts', 'best', f'{trial}', 'mnli-only-training_accs.p'), 'rb') as f:\n",
    "        temp_mnli_accs = pickle.load(f)\n",
    "\n",
    "    for treat in ['baseline', 'LotS', 'LitL']:\n",
    "        temp_df = temp_mnli_accs[treat]\n",
    "        temp_df['iter'] = temp_df['round'].apply(lambda x: int(x[-1]))\n",
    "\n",
    "        for iteration in temp_df['iter'].unique():\n",
    "            temp_acc = temp_df.loc[temp_df['iter'] <= iteration, :]\n",
    "            mnli_collected.append(\n",
    "                {\n",
    "                    'treat': treat,\n",
    "                    'iter': iteration,\n",
    "                    'model': 'mnli-only',\n",
    "                    'mod': 'full',\n",
    "                    'combined': 'combined',\n",
    "                    'trial': trial,\n",
    "                    'acc': temp_acc['correct'].sum()/temp_acc.shape[0]\n",
    "                }\n",
    "            )\n",
    "\n",
    "            temp_acc = temp_df.loc[temp_df['iter'] == iteration, :]\n",
    "            mnli_collected.append(\n",
    "                {\n",
    "                    'treat': treat,\n",
    "                    'iter': iteration,\n",
    "                    'model': 'mnli-only',\n",
    "                    'mod': 'full',\n",
    "                    'combined': 'separate',\n",
    "                    'trial': trial,\n",
    "                    'acc': temp_acc['correct'].sum()/temp_acc.shape[0]\n",
    "                }\n",
    "            )\n",
    "\n",
    "mnli_df = pd.DataFrame(mnli_collected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mnli_df = mnli_df.loc[mnli_df['combined'] == 'combined', :]\n",
    "\n",
    "for treat in mnli_df['treat'].unique():\n",
    "    for iteration in mnli_df['iter'].unique():\n",
    "        temp_df = mnli_df.loc[mnli_df['treat'] == treat, :]\n",
    "        temp_df = temp_df.loc[temp_df['iter'] == iteration, :]\n",
    "        \n",
    "        print(treat, iteration, f\"acc mean: {temp_df['acc'].mean():.3f}\", f\"acc std: {temp_df['acc'].std():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 2-way ANOVA\n",
    "\n",
    "iterations = [1, 5]\n",
    "\n",
    "iter_df = mnli_df.loc[mnli_df['iter'].isin(iterations), :]\n",
    "anova_table = two_way_anova(iter_df)\n",
    "\n",
    "print(model)\n",
    "print(anova_table)\n",
    "print('-'*90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### In Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_df = pd.read_csv(os.path.join(plot_dir, 'collected.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "input_type = 'full'\n",
    "\n",
    "plot_df = plot_df.loc[plot_df['combined'] == combined, :]\n",
    "plot_df = plot_df.loc[plot_df['mod'] == input_type, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 2-way ANOVA\n",
    "\n",
    "iterations = [1, 5]\n",
    "models = ['roberta-large', 'roberta-large-mnli']\n",
    "\n",
    "for model in models:\n",
    "    iter_df = plot_df.loc[plot_df['iter'].isin(iterations), :]\n",
    "    iter_df = iter_df.loc[iter_df['model'] == model, :]\n",
    "    anova_table = two_way_anova(iter_df)\n",
    "    \n",
    "    print(model)\n",
    "    print(anova_table)\n",
    "    print('-'*90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_df['model'] = plot_df['model'].apply(lambda x: model2plot[x])\n",
    "plot_df['treat'] = plot_df['treat'].apply(lambda x: treat2plot[x])\n",
    "plot_df = plot_df.rename(columns=cols2plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ylims={\n",
    "    'roberta-large': [0.6, 0.9],\n",
    "    'roberta-large-mnli': [0.8, 1.0],\n",
    "}\n",
    "title=f'In-domain Validation'\n",
    "xlabel='Iteration'\n",
    "ylabel='Accuracy'\n",
    "tabletitle='Median'\n",
    "tableon=False\n",
    "\n",
    "err_line_plots(\n",
    "    plot_df,\n",
    "    err_style=err_style,\n",
    "    ylim=ylims[_model],\n",
    "    title=title,\n",
    "    xlabel=xlabel,\n",
    "    ylabel=ylabel,\n",
    "    tabletitle=tabletitle,\n",
    "    palette=palette,\n",
    "    tableon=tableon,\n",
    "    style_key=style_key,\n",
    "    style_order=style_order,\n",
    "    figsize=figsize,\n",
    "    hue=hue,\n",
    "    hue_order=hue_order,\n",
    "    xlim=xlim,\n",
    "    err_kws=err_kws,\n",
    "    ax=ax[0],\n",
    "    ystep=0.05 if _model == 'roberta-large-mnli' else 0.1,\n",
    "    legend_visible=True,\n",
    "    xlabel_visible=False,\n",
    "    error_offsets=error_offsets,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Hyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_df = pd.read_csv(os.path.join(plot_dir, 'collected.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "input_type = 'hyp'\n",
    "\n",
    "plot_df = plot_df.loc[plot_df['combined'] == combined, :]\n",
    "plot_df = plot_df.loc[plot_df['mod'] == input_type, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 2-way ANOVA\n",
    "\n",
    "iterations = [1, 5]\n",
    "models = ['roberta-large', 'roberta-large-mnli']\n",
    "\n",
    "for model in models:\n",
    "    iter_df = plot_df.loc[plot_df['iter'].isin(iterations), :]\n",
    "    iter_df = iter_df.loc[iter_df['model'] == model, :]\n",
    "    anova_table = two_way_anova(iter_df)\n",
    "    \n",
    "    print(model)\n",
    "    print(anova_table)\n",
    "    print('-'*90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_df['model'] = plot_df['model'].apply(lambda x: model2plot[x])\n",
    "plot_df['treat'] = plot_df['treat'].apply(lambda x: treat2plot[x])\n",
    "plot_df = plot_df.rename(columns=cols2plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ylims={\n",
    "    'roberta-large': [0.3,0.7],\n",
    "    'roberta-large-mnli': [0.3, 0.7],\n",
    "}\n",
    "title=f'Hypothesis-only Input'\n",
    "xlabel='Iteration'\n",
    "ylabel='Accuracy'\n",
    "tabletitle='Median'\n",
    "tableon=False\n",
    "\n",
    "bbox_to_anchor = (0.5, -1.2)\n",
    "\n",
    "err_line_plots(\n",
    "    plot_df,\n",
    "    err_style=err_style,\n",
    "    ylim=ylims[_model],\n",
    "    title=title,\n",
    "    xlabel=xlabel,\n",
    "    ylabel=ylabel,\n",
    "    tabletitle=tabletitle,\n",
    "    palette=palette,\n",
    "    tableon=tableon,\n",
    "    style_key=style_key,\n",
    "    style_order=style_order,\n",
    "    figsize=figsize,\n",
    "    err_kws=err_kws,\n",
    "    hue=hue,\n",
    "    hue_order=hue_order,\n",
    "    xlim=xlim,\n",
    "    xlabel_visible=True,\n",
    "    legend_visible=False,\n",
    "    ax=ax[1],\n",
    "    error_offsets=error_offsets,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get majority class baseline per protocol and round\n",
    "append = '_combined' if combined == 'combined' else ''\n",
    "nli_data = os.path.join(repo, 'NLI_data')\n",
    "protocol2dir = {\n",
    "    'base':'1_Baseline_protocol',\n",
    "    'LotS':'2_Ling_on_side_protocol',\n",
    "    'LitL':'3_Ling_in_loop_protocol',\n",
    "}\n",
    "rounds = range(1,6)\n",
    "\n",
    "majority_class = []\n",
    "\n",
    "file2plot = {'base':'Baseline', 'LotS':'LitL', 'LitL':'LitL Chat'}\n",
    "\n",
    "for protocol, protocol_dir in protocol2dir.items():\n",
    "    for r in rounds:\n",
    "        val_name = f'val_round{r}_{protocol}{append}.jsonl'\n",
    "        val_path = os.path.join(nli_data, protocol_dir, val_name)\n",
    "        \n",
    "        labels2count = collections.defaultdict(int)\n",
    "        with open(val_path, 'r') as f:\n",
    "            for example in f.readlines():\n",
    "                label = json.loads(example)['label']\n",
    "                labels2count[label] += 1\n",
    "        majority_class.append({\n",
    "            'Protocol':file2plot[protocol],\n",
    "            'Iteration':r,\n",
    "            'Majority Class':max(labels2count.values())/sum(labels2count.values())\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "avg = True\n",
    "majority_class_df = pd.DataFrame(majority_class)\n",
    "\n",
    "if avg:\n",
    "    avg_majority = majority_class_df.groupby(by='Iteration').mean()\n",
    "    plt.plot(\n",
    "        avg_majority.index.values, avg_majority['Majority Class'],\n",
    "        c='k', ls='--'\n",
    "    )\n",
    "else:\n",
    "    sns.lineplot(\n",
    "        data=majority_class_df, \n",
    "        x='Iteration', y='Majority Class', \n",
    "        hue='Protocol', style='Protocol', markers=True, ax=ax[1]\n",
    "    )\n",
    "ax[1].legend().set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig.tight_layout()\n",
    "if save_figs:\n",
    "    fig.savefig(os.path.join(plot_out, f'{combined}_indomain.{figtype}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Diagnostic Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "iterations = [1, 5]\n",
    "models = style_order\n",
    "iter_l_offset = -0.75 if _model == 'roberta-large' else -1.75\n",
    "iter_c_offset = +0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "error_offsets = [\n",
    "        {\n",
    "            'line':-(err_line_offset+iter_l_offset),\n",
    "            'cap':-(err_cap_offset+iter_c_offset),\n",
    "        },\n",
    "        {\n",
    "            'line':0,\n",
    "            'cap':0,\n",
    "        },\n",
    "        {\n",
    "            'line':+(err_line_offset+iter_l_offset),\n",
    "            'cap':+(err_cap_offset+iter_c_offset),\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "figsize = (15, 5)\n",
    "fig, ax = plt.subplots(2, 4, figsize=figsize) # top is GLUE bottom is HANS\n",
    "ax[1, 3].set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### GLUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_df = pd.read_csv(os.path.join(plot_dir, 'glue.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mnli_collected = []\n",
    "temp_df = mnli_accs['glue']\n",
    "temp_df['case_text'] = temp_df['case'].apply(lambda x: x[0] if len(x) > 0 else '')\n",
    "\n",
    "for case in temp_df['case_text'].unique():\n",
    "    temp_acc = temp_df.loc[temp_df['case_text'] == case, :]\n",
    "    mnli_collected.append({\n",
    "        'acc': temp_acc['correct'].sum()/temp_acc.shape[0],\n",
    "        'subcase': 'combined',\n",
    "        'label': 'combined',\n",
    "        'model': 'mnli-only',\n",
    "        'case': case,\n",
    "    })\n",
    "    \n",
    "    for label in temp_acc['label'].unique():\n",
    "        temptemp_acc = temp_acc.loc[temp_acc['label'] == label, :]\n",
    "        mnli_collected.append({\n",
    "            'acc': temptemp_acc['correct'].sum()/temptemp_acc.shape[0],\n",
    "            'subcase': 'combined',\n",
    "            'label': label,\n",
    "            'model': 'mnli-only',\n",
    "            'case': case,\n",
    "        })\n",
    "mnli_df = pd.DataFrame(mnli_collected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "label = 'combined'\n",
    "\n",
    "plot_df = plot_df.loc[plot_df['comb'] == combined, :]\n",
    "plot_df = plot_df.loc[plot_df['label'] == label, :]\n",
    "plot_df = plot_df.loc[plot_df['subcase'] == 'combined', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mnli_df = mnli_df.loc[mnli_df['label'] == label, :]\n",
    "mnli_df = mnli_df.loc[mnli_df['subcase'] == 'combined', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_df['model'] = plot_df['model'].apply(lambda x: model2plot[x])\n",
    "plot_df['treat'] = plot_df['treat'].apply(lambda x: treat2plot[x])\n",
    "plot_df = plot_df.rename(columns=cols2plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ylims={\n",
    "    'roberta-large':{\n",
    "        'Knowledge':[0.4,0.7],\n",
    "        'Lexical Semantics':[0.5, 0.8],\n",
    "        'Logic': [0.4,0.7],\n",
    "        'Predicate-Argument Structure':[0.5,0.8],\n",
    "    },\n",
    "    'roberta-large-mnli':{\n",
    "        'Knowledge':[0.4,0.7],\n",
    "        'Lexical Semantics':[0.5, 0.8],\n",
    "        'Logic': [0.4,0.7],\n",
    "        'Predicate-Argument Structure':[0.5,0.8],\n",
    "    },\n",
    "}\n",
    "title=f\"\"\n",
    "xlabel='Iteration'\n",
    "ylabel='GLUE'\n",
    "tabletitle='median'\n",
    "tableon=False\n",
    "\n",
    "glue_keys = pd.read_csv('glue_case_keys.csv')\n",
    "\n",
    "i = 0\n",
    "for case in glue_keys['case'].unique():\n",
    "    if case == 'combined':\n",
    "        continue\n",
    "    \n",
    "    temp_df = plot_df.loc[plot_df['case'] == case, :]\n",
    "    err_line_plots(\n",
    "        temp_df,\n",
    "        err_style=err_style,\n",
    "        ylim=ylims[_model][case],\n",
    "        title=f\"{case}\",\n",
    "        xlabel=xlabel if i == len(glue_keys['case'].unique()) - 2 else None,\n",
    "        ylabel=ylabel,\n",
    "        tabletitle=tabletitle,\n",
    "        palette=palette,\n",
    "        tableon=tableon,\n",
    "        style_key=style_key,\n",
    "        style_order=style_order,\n",
    "        ax=ax[0, i],\n",
    "        ylabel_visible = i == 0,\n",
    "        legend_visible = False,\n",
    "        err_kws=err_kws,\n",
    "        hue=hue,\n",
    "        hue_order=hue_order,\n",
    "        xlim=xlim,\n",
    "        error_offsets=error_offsets,\n",
    "    )\n",
    "    \n",
    "    if _model == 'roberta-large-mnli':\n",
    "        temp_mnli = mnli_df.loc[mnli_df['case'] == case, :]\n",
    "        ax[0, i].hlines(temp_mnli['acc'], xlim[0], xlim[1], label='mnli-only', zorder=10)\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "    for model in models:\n",
    "        iter_df = temp_df.loc[temp_df['iter'].isin(iterations), :]\n",
    "        iter_df = iter_df.loc[iter_df['Model'] == model, :]\n",
    "        anova_table = two_way_anova(iter_df, f2='Protocol')\n",
    "\n",
    "        print(model, case)\n",
    "        print(anova_table)\n",
    "        print('-'*90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### HANS non-entailment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_df = pd.read_csv(os.path.join(plot_dir, 'hans.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mnli_collected = []\n",
    "temp_df = mnli_accs['hans']\n",
    "temp_df['case_text'] = temp_df['case']\n",
    "\n",
    "for case in temp_df['case_text'].unique():\n",
    "    temp_acc = temp_df.loc[temp_df['case_text'] == case, :]\n",
    "    mnli_collected.append({\n",
    "        'acc': temp_acc['correct'].sum()/temp_acc.shape[0],\n",
    "        'subcase': 'combined',\n",
    "        'label': 'combined',\n",
    "        'model': 'mnli-only',\n",
    "        'case': case,\n",
    "    })\n",
    "    \n",
    "    for label in temp_acc['label'].unique():\n",
    "        temptemp_acc = temp_acc.loc[temp_acc['label'] == label, :]\n",
    "        mnli_collected.append({\n",
    "            'acc': temptemp_acc['correct'].sum()/temptemp_acc.shape[0],\n",
    "            'subcase': 'combined',\n",
    "            'label': 'non-entailment' if label == 'contradiction' else label,\n",
    "            'model': 'mnli-only',\n",
    "            'case': case,\n",
    "        })\n",
    "mnli_df = pd.DataFrame(mnli_collected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "label = 'non-entailment'\n",
    "\n",
    "plot_df = plot_df.loc[plot_df['comb'] == combined, :]\n",
    "plot_df = plot_df.loc[plot_df['label'] == label, :]\n",
    "plot_df = plot_df.loc[plot_df['subcase'] == 'combined', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mnli_df = mnli_df.loc[mnli_df['label'] == label, :]\n",
    "mnli_df = mnli_df.loc[mnli_df['subcase'] == 'combined', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_df['model'] = plot_df['model'].apply(lambda x: model2plot[x])\n",
    "plot_df['treat'] = plot_df['treat'].apply(lambda x: treat2plot[x])\n",
    "plot_df = plot_df.rename(columns=cols2plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ylims={\n",
    "    'roberta-large':{\n",
    "        'constituent': [0.0, 0.6],\n",
    "        'lexical_overlap': [0.0, 0.8],\n",
    "        'subsequence': [0.0, 0.6],\n",
    "    },\n",
    "    'roberta-large-mnli':{\n",
    "        'constituent': [0.1, 0.5],\n",
    "        'lexical_overlap': [0.6, 1.0],\n",
    "        'subsequence': [0.1, 0.5],\n",
    "    },\n",
    "}\n",
    "title=f\"\"\n",
    "xlabel='Iteration'\n",
    "ylabel='HANS Non-Entailment'\n",
    "tabletitle='median'\n",
    "tableon=False\n",
    "\n",
    "bbox_to_anchor = (1.15, 1)\n",
    "\n",
    "hans_keys = pd.read_csv('hans_case_keys.csv')\n",
    "\n",
    "case2title = {\n",
    "    'constituent': 'Constituent',\n",
    "    'lexical_overlap': 'Lexical Overlap',\n",
    "    'subsequence': 'Subsequence',\n",
    "}\n",
    "\n",
    "i = 0\n",
    "for case in hans_keys['case'].unique():\n",
    "    if case == 'combined':\n",
    "        continue\n",
    "    \n",
    "    temp_df = plot_df.loc[plot_df['case'] == case, :]\n",
    "    err_line_plots(\n",
    "        temp_df,\n",
    "        err_style=err_style,\n",
    "        ylim=ylims[_model][case],\n",
    "        title=f\"{case2title[case]}\",\n",
    "        xlabel=xlabel,\n",
    "        ylabel=ylabel,\n",
    "        tabletitle=tabletitle,\n",
    "        palette=palette,\n",
    "        tableon=tableon,\n",
    "        style_key=style_key,\n",
    "        style_order=style_order,\n",
    "        ax=ax[1, i],\n",
    "        ylabel_visible = i == 0,\n",
    "        legend_visible = i == len(hans_keys['case'].unique()) - 2,\n",
    "        bbox_to_anchor=bbox_to_anchor,\n",
    "        err_kws=err_kws,\n",
    "        hue=hue,\n",
    "        hue_order=hue_order,\n",
    "        xlim=xlim,\n",
    "        ystep=0.2,\n",
    "        error_offsets=error_offsets,\n",
    "    )\n",
    "    \n",
    "    if _model == 'roberta-large-mnli':\n",
    "        temp_mnli = mnli_df.loc[mnli_df['case'] == case, :]\n",
    "        ax[1, i].hlines(temp_mnli['acc'], xlim[0], xlim[1], label='mnli-only', zorder=10)\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "    for model in models:\n",
    "        iter_df = temp_df.loc[temp_df['iter'].isin(iterations), :]\n",
    "        iter_df = iter_df.loc[iter_df['Model'] == model, :]\n",
    "        anova_table = two_way_anova(iter_df, f2='Protocol')\n",
    "\n",
    "        print(model, case)\n",
    "        print(anova_table)\n",
    "        print('-'*90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig.tight_layout()\n",
    "fig.subplots_adjust(wspace=2.5e-1)\n",
    "if save_figs:\n",
    "    fig.savefig(os.path.join(plot_out, f'{combined}_itereval.{figtype}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Combined Held-out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "figsize=(7, 5)\n",
    "fig, ax = plt.subplots(2, 1, figsize=figsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "iterations = [1, 5]\n",
    "models = style_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mnli_df = mnli_accs['mnlieval']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ylims={\n",
    "    'roberta-large':{\n",
    "        'mnli':[0.6,0.9],\n",
    "        'anli':[0.2,0.5]\n",
    "    },\n",
    "    'roberta-large-mnli':{\n",
    "        'mnli':[0.8, 1.0],\n",
    "        'anli':[0.3, 0.4]\n",
    "    },\n",
    "}\n",
    "title=f\"\"\n",
    "xlabel='Iteration'\n",
    "ylabel='Accuracy'\n",
    "tabletitle='median'\n",
    "tableon=False\n",
    "\n",
    "bbox_to_anchor = (1.01, 1)\n",
    "\n",
    "case2title = {\n",
    "    'mnli': 'MNLI-mismatched',\n",
    "    'anli': 'ANLI',\n",
    "}\n",
    "\n",
    "i = 0\n",
    "for case, title_name in case2title.items():\n",
    "    plot_df = pd.read_csv(os.path.join(plot_dir, f'{case}.csv'))\n",
    "    plot_df = plot_df.loc[plot_df['comb'] == combined, :]\n",
    "    plot_df = plot_df.loc[plot_df['breakdown'] == 'combined', :]\n",
    "    mnli_df = mnli_accs[f'{case}eval']\n",
    "    \n",
    "    plot_df['model'] = plot_df['model'].apply(lambda x: model2plot[x])\n",
    "    plot_df['treat'] = plot_df['treat'].apply(lambda x: treat2plot[x])\n",
    "    plot_df = plot_df.rename(columns=cols2plot)\n",
    "    \n",
    "    err_line_plots(\n",
    "        plot_df,\n",
    "        err_style=err_style,\n",
    "        ylim=ylims[_model][case],\n",
    "        title=f\"{title_name}\",\n",
    "        xlabel=xlabel,\n",
    "        ylabel=ylabel,\n",
    "        tabletitle=tabletitle,\n",
    "        palette=palette,\n",
    "        tableon=tableon,\n",
    "        style_key=style_key,\n",
    "        style_order=style_order,\n",
    "        ax=ax[i],\n",
    "        xlabel_visible = i == 1,\n",
    "        legend_visible = i == 0,\n",
    "        bbox_to_anchor=bbox_to_anchor,\n",
    "        err_kws=err_kws,\n",
    "        hue=hue,\n",
    "        hue_order=hue_order,\n",
    "        xlim=xlim,\n",
    "        ystep=0.05 if _model == 'roberta-large-mnli' else 0.1,\n",
    "    )\n",
    "    \n",
    "    if _model == 'roberta-large-mnli':\n",
    "        ax[i].hlines(mnli_df['correct'].sum()/mnli_df.shape[0], xlim[0], xlim[1], label='mnli-only', zorder=10)\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "    for model in models:\n",
    "        iter_df = plot_df.loc[plot_df['iter'].isin(iterations), :]\n",
    "        iter_df = iter_df.loc[iter_df['Model'] == model, :]\n",
    "        anova_table = two_way_anova(iter_df, f2='Protocol')\n",
    "\n",
    "        print(model, case)\n",
    "        print(anova_table)\n",
    "        print('-'*90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig.tight_layout()\n",
    "if save_figs:\n",
    "    fig.savefig(os.path.join(plot_out, f'{combined}_val.{figtype}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## ANLI Breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "anli_l_offset = -0\n",
    "anli_c_offset = +0.075"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "error_offsets = [\n",
    "    {\n",
    "        'line':-(err_line_offset+anli_l_offset),\n",
    "        'cap':-(err_cap_offset+anli_c_offset),\n",
    "    },\n",
    "    {\n",
    "        'line':0,\n",
    "        'cap':0,\n",
    "    },\n",
    "    {\n",
    "        'line':+(err_line_offset+anli_l_offset),\n",
    "        'cap':+(err_cap_offset+anli_c_offset),\n",
    "    },\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "anli_plot_out = os.path.join(repo, 'eval_summary', 'plots')\n",
    "anli_style_order=[\n",
    "    r'RoBERTa$_{\\rm{Lg}}$', \n",
    "    r'RoBERTa$_{\\rm{Lg+MNLI}}$'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_df = pd.read_csv(os.path.join(plot_dir, 'anli.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "breakdowns = [\n",
    "        'combined',\n",
    "        'Basic',\n",
    "#         'EventCoref',\n",
    "        'Imperfection',\n",
    "        'Numerical',\n",
    "        'Reasoning',\n",
    "        'Reference',\n",
    "        'Tricky',\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mnli_df = mnli_accs['anlieval']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "repo_up = os.path.dirname(repo)\n",
    "anli_annot_fname = os.path.join(repo_up, 'anli_annot_v0.2_combined_A1A2')\n",
    "anli_annot = joblib.load(anli_annot_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_anli_breakdown_acc(pred_df, anli_annot, breakdown):\n",
    "    temp1 = anli_annot[['uid', breakdown]]\n",
    "    temp2 = pred_df[['uid', 'correct']]  \n",
    "    temp = temp1.merge(temp2, on='uid')\n",
    "    temp = temp.loc[temp[breakdown].ne('none'), :]\n",
    "    return temp['correct'].sum()/temp.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_df = plot_df.loc[plot_df['comb'] == combined, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_df['model'] = plot_df['model'].apply(lambda x: model2plot[x])\n",
    "plot_df['treat'] = plot_df['treat'].apply(lambda x: treat2plot[x])\n",
    "plot_df = plot_df.rename(columns=cols2plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if _model == 'roberta-large':\n",
    "    ylim=[0.25,0.4]\n",
    "    title=f\"\"\n",
    "    xlabel='Iteration'\n",
    "    ylabel='Accuracy'\n",
    "    tabletitle='median'\n",
    "    tableon=False\n",
    "\n",
    "    bbox_to_anchor = (1.01, 1)\n",
    "    figsize=(15, 6)\n",
    "\n",
    "    fig, ax = plt.subplots(2, len(breakdowns) - 1, figsize=figsize)\n",
    "\n",
    "    i = 0\n",
    "    for anli_model in anli_style_order:\n",
    "        temp_df = plot_df.loc[plot_df['Model'] == anli_model, :]\n",
    "        for case in breakdowns:\n",
    "            if case == 'combined':\n",
    "                continue\n",
    "            \n",
    "            print(i // (len(breakdowns) - 1), i % (len(breakdowns) - 1))\n",
    "            temp_ax = ax[i // (len(breakdowns) - 1), i%(len(breakdowns) - 1)]\n",
    "            temptemp_df = temp_df.loc[temp_df['breakdown'] == case, :]\n",
    "            err_line_plots(\n",
    "                temptemp_df,\n",
    "                err_style=err_style,\n",
    "                ylim=ylim,\n",
    "                title=f\"{case}\",\n",
    "                xlabel=xlabel,\n",
    "                ylabel=anli_model,\n",
    "                tabletitle=tabletitle,\n",
    "                palette=palette,\n",
    "                tableon=tableon,\n",
    "                style_key=style_key,\n",
    "                style_order=[anli_model],\n",
    "                ax=temp_ax,\n",
    "                yaxis_visible = i % (len(breakdowns) - 1) == 0,\n",
    "                legend_visible = i == len(breakdowns) - 2,\n",
    "                xlabel_visible = i // (len(breakdowns) - 1) == 1,\n",
    "                bbox_to_anchor=bbox_to_anchor,\n",
    "                err_kws=err_kws,\n",
    "                hue=hue,\n",
    "                hue_order=hue_order,\n",
    "                xlim=xlim,\n",
    "                error_offsets=error_offsets,\n",
    "                ystep=0.05,\n",
    "            )\n",
    "\n",
    "            temp_ax.hlines(get_anli_breakdown_acc(mnli_df, anli_annot, case), xlim[0], xlim[1], label='mnli-only', zorder=10)    \n",
    "\n",
    "            i += 1\n",
    "\n",
    "    fig.tight_layout()\n",
    "    if save_figs:\n",
    "        print(os.path.dirname(plot_out))\n",
    "        fig.savefig(os.path.join(os.path.dirname(plot_out), f'{combined}_anli_breakdown.{figtype}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## HANS Entailment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "iterations = [1, 5]\n",
    "models = style_order\n",
    "iter_l_offset = -0.75 if _model == 'roberta-large' else -1.75\n",
    "iter_c_offset = +0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "error_offsets = [\n",
    "        {\n",
    "            'line':-(err_line_offset+iter_l_offset),\n",
    "            'cap':-(err_cap_offset+iter_c_offset),\n",
    "        },\n",
    "        {\n",
    "            'line':0,\n",
    "            'cap':0,\n",
    "        },\n",
    "        {\n",
    "            'line':+(err_line_offset+iter_l_offset),\n",
    "            'cap':+(err_cap_offset+iter_c_offset),\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "title_fontsize=16\n",
    "label_fontsize=14\n",
    "legend_fontsize=12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "figsize = (15, 5)\n",
    "fig, ax = plt.subplots(2, 3, figsize=figsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### RoBERTa HANS Entailment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "combined = 'combined'\n",
    "_model = 'roberta-large'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "repo = os.path.dirname(os.path.dirname(os.path.abspath('__file__')))\n",
    "plot_dir = os.path.join(repo, 'eval_summary', 'plot_data')\n",
    "plot_out = os.path.join(repo, 'eval_summary', 'plots', _model)\n",
    "os.makedirs(plot_out, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "acc_name = 'Performance'\n",
    "diff_name = 'Over Baseline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "save_figs = True\n",
    "figtype='pdf'\n",
    "\n",
    "err_style='bars' # band or bars\n",
    "err_kws={'elinewidth': 2, 'capsize': 3}\n",
    "\n",
    "err_line_offset = 4 if _model == 'roberta-large' else 5\n",
    "err_cap_offset = 0.05\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cols2plot = {'treat':'Protocol', 'model':'Model'}\n",
    "treat2plot = {'baseline':'Baseline', 'LotS':'LitL', 'LitL':'LitL Chat'}\n",
    "model2plot = {'roberta-large': r'RoBERTa$_{\\rm{Lg}}$', 'roberta-large-mnli': r'RoBERTa$_{\\rm{Lg+MNLI}}$'}\n",
    "\n",
    "hue='Protocol'\n",
    "hue_order=['Baseline', 'LitL', 'LitL Chat']\n",
    "style_key='Model'\n",
    "style_order=[\n",
    "    model2plot[_model]\n",
    "]\n",
    "\n",
    "palette={\n",
    "        'baseline':'tab:blue',\n",
    "        'LitL':'tab:orange',\n",
    "        'LitL Chat':'tab:green',\n",
    "    }\n",
    "\n",
    "xlim = [0.8, 5.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(plot_dir, 'mnli-only-training_accs.p'), 'rb') as f:\n",
    "    mnli_accs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "iterations = [1, 5]\n",
    "models = style_order\n",
    "iter_l_offset = -0.75 if _model == 'roberta-large' else -1.75\n",
    "iter_c_offset = +0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "error_offsets = [\n",
    "        {\n",
    "            'line':-(err_line_offset+iter_l_offset),\n",
    "            'cap':-(err_cap_offset+iter_c_offset),\n",
    "        },\n",
    "        {\n",
    "            'line':0,\n",
    "            'cap':0,\n",
    "        },\n",
    "        {\n",
    "            'line':+(err_line_offset+iter_l_offset),\n",
    "            'cap':+(err_cap_offset+iter_c_offset),\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_df = pd.read_csv(os.path.join(plot_dir, 'hans.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mnli_collected = []\n",
    "temp_df = mnli_accs['hans']\n",
    "temp_df['case_text'] = temp_df['case']\n",
    "\n",
    "for case in temp_df['case_text'].unique():\n",
    "    temp_acc = temp_df.loc[temp_df['case_text'] == case, :]\n",
    "    mnli_collected.append({\n",
    "        'acc': temp_acc['correct'].sum()/temp_acc.shape[0],\n",
    "        'subcase': 'combined',\n",
    "        'label': 'combined',\n",
    "        'model': 'mnli-only',\n",
    "        'case': case,\n",
    "    })\n",
    "    \n",
    "    for label in temp_acc['label'].unique():\n",
    "        temptemp_acc = temp_acc.loc[temp_acc['label'] == label, :]\n",
    "        mnli_collected.append({\n",
    "            'acc': temptemp_acc['correct'].sum()/temptemp_acc.shape[0],\n",
    "            'subcase': 'combined',\n",
    "            'label': 'non-entailment' if label == 'contradiction' else label,\n",
    "            'model': 'mnli-only',\n",
    "            'case': case,\n",
    "        })\n",
    "mnli_df = pd.DataFrame(mnli_collected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "label = 'entailment'\n",
    "\n",
    "plot_dff = plot_df.loc[plot_df['comb'] == combined, :]\n",
    "plot_dff = plot_dff.loc[plot_dff['label'] == label, :]\n",
    "plot_dff = plot_dff.loc[plot_dff['subcase'] == 'combined', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mnli_df = mnli_df.loc[mnli_df['label'] == label, :]\n",
    "mnli_df = mnli_df.loc[mnli_df['subcase'] == 'combined', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_dff['model'] = plot_dff['model'].apply(lambda x: model2plot[x])\n",
    "plot_dff['treat'] = plot_dff['treat'].apply(lambda x: treat2plot[x])\n",
    "plot_dff = plot_dff.rename(columns=cols2plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ylims={\n",
    "    'roberta-large':{\n",
    "        'constituent': [0.6, 1.05],\n",
    "        'lexical_overlap': [0.6, 1.05],\n",
    "        'subsequence': [0.6, 1.05],\n",
    "    },\n",
    "    'roberta-large-mnli':{\n",
    "        'constituent': [0.6, 1.05],\n",
    "        'lexical_overlap': [0.6, 1.05],\n",
    "        'subsequence': [0.6, 1.05],\n",
    "    },\n",
    "}\n",
    "title=f\"\"\n",
    "xlabel='Iteration'\n",
    "ylabel= r'RoBERTa$_{\\rm{Lg}}$'\n",
    "tabletitle='median'\n",
    "tableon=False\n",
    "\n",
    "bbox_to_anchor = (1.055, 1)\n",
    "\n",
    "hans_keys = pd.read_csv('hans_case_keys.csv')\n",
    "\n",
    "case2title = {\n",
    "    'constituent': 'Constituent',\n",
    "    'lexical_overlap': 'Lexical Overlap',\n",
    "    'subsequence': 'Subsequence',\n",
    "}\n",
    "\n",
    "i = 0\n",
    "for case in hans_keys['case'].unique():\n",
    "    if case == 'combined':\n",
    "        continue\n",
    "    \n",
    "    temp_df = plot_dff.loc[plot_dff['case'] == case, :]\n",
    "    err_line_plots(\n",
    "        temp_df,\n",
    "        err_style=err_style,\n",
    "        ylim=ylims[_model][case],\n",
    "        title=f\"{case2title[case]}\",\n",
    "        xlabel=xlabel,\n",
    "        ylabel=ylabel,\n",
    "        tabletitle=tabletitle,\n",
    "        palette=palette,\n",
    "        tableon=tableon,\n",
    "        style_key=style_key,\n",
    "        style_order=style_order,\n",
    "        ax=ax[0, i],\n",
    "        ylabel_visible = i == 0,\n",
    "        legend_visible = False,\n",
    "        bbox_to_anchor=bbox_to_anchor,\n",
    "        err_kws=err_kws,\n",
    "        hue=hue,\n",
    "        hue_order=hue_order,\n",
    "        xlim=xlim,\n",
    "        ystep=0.2,\n",
    "        error_offsets=error_offsets,\n",
    "    )\n",
    "    \n",
    "    if _model == 'roberta-large-mnli':\n",
    "        temp_mnli = mnli_df.loc[mnli_df['case'] == case, :]\n",
    "        ax[1, i].hlines(temp_mnli['acc'], xlim[0], xlim[1], label='mnli-only', zorder=10)\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "    for model in models:\n",
    "        iter_df = temp_df.loc[temp_df['iter'].isin(iterations), :]\n",
    "        iter_df = iter_df.loc[iter_df['Model'] == model, :]\n",
    "        anova_table = two_way_anova(iter_df, f2='Protocol')\n",
    "\n",
    "        print(model, case)\n",
    "        print(anova_table)\n",
    "        print('-'*90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### RoBERTa MNLI HANS Entailment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "combined = 'combined'\n",
    "_model = 'roberta-large-mnli'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "repo = os.path.dirname(os.path.dirname(os.path.abspath('__file__')))\n",
    "plot_dir = os.path.join(repo, 'eval_summary', 'plot_data')\n",
    "plot_out = os.path.join(repo, 'eval_summary', 'plots', _model)\n",
    "os.makedirs(plot_out, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "acc_name = 'Performance'\n",
    "diff_name = 'Over Baseline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "save_figs = True\n",
    "figtype='pdf'\n",
    "\n",
    "err_style='bars' # band or bars\n",
    "err_kws={'elinewidth': 2, 'capsize': 3}\n",
    "\n",
    "err_line_offset = 4 if _model == 'roberta-large' else 5\n",
    "err_cap_offset = 0.05\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cols2plot = {'treat':'Protocol', 'model':'Model'}\n",
    "treat2plot = {'baseline':'Baseline', 'LotS':'LitL', 'LitL':'LitL Chat'}\n",
    "model2plot = {'roberta-large': r'RoBERTa$_{\\rm{Lg}}$', 'roberta-large-mnli': r'RoBERTa$_{\\rm{Lg+MNLI}}$'}\n",
    "\n",
    "hue='Protocol'\n",
    "hue_order=['Baseline', 'LitL', 'LitL Chat']\n",
    "style_key='Model'\n",
    "style_order=[\n",
    "    model2plot[_model]\n",
    "]\n",
    "\n",
    "palette={\n",
    "        'baseline':'tab:blue',\n",
    "        'LitL':'tab:orange',\n",
    "        'LitL Chat':'tab:green',\n",
    "    }\n",
    "\n",
    "xlim = [0.8, 5.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(plot_dir, 'mnli-only-training_accs.p'), 'rb') as f:\n",
    "    mnli_accs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "iterations = [1, 5]\n",
    "models = style_order\n",
    "iter_l_offset = -0.75 if _model == 'roberta-large' else -1.75\n",
    "iter_c_offset = +0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "error_offsets = [\n",
    "        {\n",
    "            'line':-(err_line_offset+iter_l_offset),\n",
    "            'cap':-(err_cap_offset+iter_c_offset),\n",
    "        },\n",
    "        {\n",
    "            'line':0,\n",
    "            'cap':0,\n",
    "        },\n",
    "        {\n",
    "            'line':+(err_line_offset+iter_l_offset),\n",
    "            'cap':+(err_cap_offset+iter_c_offset),\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_df = pd.read_csv(os.path.join(plot_dir, 'hans.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mnli_collected = []\n",
    "temp_df = mnli_accs['hans']\n",
    "temp_df['case_text'] = temp_df['case']\n",
    "\n",
    "for case in temp_df['case_text'].unique():\n",
    "    temp_acc = temp_df.loc[temp_df['case_text'] == case, :]\n",
    "    mnli_collected.append({\n",
    "        'acc': temp_acc['correct'].sum()/temp_acc.shape[0],\n",
    "        'subcase': 'combined',\n",
    "        'label': 'combined',\n",
    "        'model': 'mnli-only',\n",
    "        'case': case,\n",
    "    })\n",
    "    \n",
    "    for label in temp_acc['label'].unique():\n",
    "        temptemp_acc = temp_acc.loc[temp_acc['label'] == label, :]\n",
    "        mnli_collected.append({\n",
    "            'acc': temptemp_acc['correct'].sum()/temptemp_acc.shape[0],\n",
    "            'subcase': 'combined',\n",
    "            'label': 'non-entailment' if label == 'contradiction' else label,\n",
    "            'model': 'mnli-only',\n",
    "            'case': case,\n",
    "        })\n",
    "mnli_df = pd.DataFrame(mnli_collected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "label = 'entailment'\n",
    "\n",
    "plot_dff = plot_df.loc[plot_df['comb'] == combined, :]\n",
    "plot_dff = plot_dff.loc[plot_dff['label'] == label, :]\n",
    "plot_dff = plot_dff.loc[plot_dff['subcase'] == 'combined', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mnli_df = mnli_df.loc[mnli_df['label'] == label, :]\n",
    "mnli_df = mnli_df.loc[mnli_df['subcase'] == 'combined', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_dff['model'] = plot_dff['model'].apply(lambda x: model2plot[x])\n",
    "plot_dff['treat'] = plot_dff['treat'].apply(lambda x: treat2plot[x])\n",
    "plot_dff = plot_dff.rename(columns=cols2plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ylims={\n",
    "    'roberta-large':{\n",
    "        'constituent': [0.6, 1.05],\n",
    "        'lexical_overlap': [0.6, 1.05],\n",
    "        'subsequence': [0.6, 1.05],\n",
    "    },\n",
    "    'roberta-large-mnli':{\n",
    "        'constituent': [0.6, 1.05],\n",
    "        'lexical_overlap': [0.6, 1.05],\n",
    "        'subsequence': [0.6, 1.05],\n",
    "    },\n",
    "}\n",
    "title=f\"\"\n",
    "xlabel='Iteration'\n",
    "ylabel=r'RoBERTa$_{\\rm{Lg+MNLI}}$'\n",
    "tabletitle='median'\n",
    "tableon=False\n",
    "\n",
    "bbox_to_anchor = (-.75, -1)\n",
    "\n",
    "hans_keys = pd.read_csv('hans_case_keys.csv')\n",
    "\n",
    "case2title = {\n",
    "    'constituent': 'Constituent',\n",
    "    'lexical_overlap': 'Lexical Overlap',\n",
    "    'subsequence': 'Subsequence',\n",
    "}\n",
    "\n",
    "i = 0\n",
    "for case in hans_keys['case'].unique():\n",
    "    if case == 'combined':\n",
    "        continue\n",
    "    \n",
    "    temp_df = plot_dff.loc[plot_dff['case'] == case, :]\n",
    "    err_line_plots(\n",
    "        temp_df,\n",
    "        err_style=err_style,\n",
    "        ylim=ylims[_model][case],\n",
    "        title=f\"{case2title[case]}\",\n",
    "        xlabel=xlabel,\n",
    "        ylabel=ylabel,\n",
    "        tabletitle=tabletitle,\n",
    "        palette=palette,\n",
    "        tableon=tableon,\n",
    "        style_key=style_key,\n",
    "        style_order=style_order,\n",
    "        ax=ax[1, i],\n",
    "        ylabel_visible = i == 0,\n",
    "        legend_visible = i == len(hans_keys['case'].unique())-2,\n",
    "        loc='lower center',\n",
    "        ncol=len(hans_keys['case'].unique()),\n",
    "        bbox_to_anchor=bbox_to_anchor,\n",
    "        err_kws=err_kws,\n",
    "        hue=hue,\n",
    "        hue_order=hue_order,\n",
    "        xlim=xlim,\n",
    "        ystep=0.2,\n",
    "        error_offsets=error_offsets,\n",
    "    )\n",
    "    \n",
    "    if _model == 'roberta-large-mnli':\n",
    "        temp_mnli = mnli_df.loc[mnli_df['case'] == case, :]\n",
    "        ax[1, i].hlines(temp_mnli['acc'], xlim[0], xlim[1], label='mnli-only', zorder=10)\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "    for model in models:\n",
    "        iter_df = temp_df.loc[temp_df['iter'].isin(iterations), :]\n",
    "        iter_df = iter_df.loc[iter_df['Model'] == model, :]\n",
    "        anova_table = two_way_anova(iter_df, f2='Protocol')\n",
    "\n",
    "        print(model, case)\n",
    "        print(anova_table)\n",
    "        print('-'*90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_out = os.path.join(repo, 'eval_summary', 'plots', 'HANS_entailment')\n",
    "os.makedirs(plot_out, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig.tight_layout()\n",
    "fig.subplots_adjust(wspace=2e-1)\n",
    "if save_figs:\n",
    "    fig.savefig(os.path.join(plot_out, f'{combined}_HANS_entailment.pdf'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
